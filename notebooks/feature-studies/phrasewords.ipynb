{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img src=\"files/images/laf-fabric-small.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img src=\"files/images/DANS-small.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img src=\"files/images/TLA-small.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img src=\"files/images/VU-ETCBC-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Phrase Words"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How to list the words in a phrase"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "import laf\n",
      "from laf.notebook import Notebook\n",
      "processor = Notebook()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "This is LAF-Fabric 3.5.1\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.init('bhs3.txt.hdr', '--', 'phrasewords', {\n",
      "    \"primary\": False,\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype\",\n",
      "                \"ft.text,suffix\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "                \"parents.\",\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "}, force_compile_source=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN COMPILE source: bhs3.txt.hdr\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOGFILE=/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/bin/__log__compile__bhs3.txt.hdr.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s PARSING ANNOTATION FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.75s parsing bhs3_regions.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s parsing bhs3_monads.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    56s parsing bhs3_lingo.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 27s parsing bhs3_sections.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 39s parsing bhs3_monads.bhs.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 55s parsing bhs3_monads.gmorfo.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 3m 24s parsing bhs3_monads.graphical.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 3m 50s parsing bhs3_monads.lang.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 4m 11s parsing bhs3_monads.morpho.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 4m 51s parsing bhs3_monads.order.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 5m 10s parsing bhs3_monads.paradigmatic.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 5m 48s parsing bhs3_monads.plain.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 6m 27s parsing bhs3_monads.pos.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 6m 53s parsing bhs3_monads.suffix.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 7m 16s parsing bhs3_monads.text.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 7m 46s parsing bhs3_monads.utf8.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 8m 17s parsing bhs3_lingo.c.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 8m 42s parsing bhs3_lingo.p.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 9m 09s parsing bhs3_lingo.pa.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 9m 36s parsing bhs3_lingo.s.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 9m 44s parsing bhs3_lingo.subp.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 9m 53s parsing bhs3_lingo.w.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "10m 05s END PARSING\n",
        "    800087 good   regions  and     0 faulty ones\n",
        "   1453175 linked nodes    and     0 unlinked ones\n",
        "   1524637 good   edges    and     0 faulty ones\n",
        "   9053651 good   annots   and     0 faulty ones\n",
        "  33491841 good   features and     0 faulty ones\n",
        "  12831550 distinct xml identifiers\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "10m 05s MODELING RESULT FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "10m 05s NODES AND REGIONS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "10m 05s NODES ANCHOR BOUNDARIES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "10m 41s NODES SORTING BY REGIONS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "10m 43s NODES EVENTS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 23s NODES AND EDGES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 29s PLAIN EDGES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 29s WRITING RESULT FILES for source\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 29s writing common: node_anchor_min ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 30s writing common: node_anchor_max ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 30s writing common: node_events ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 33s writing common: node_events_n ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 34s writing common: node_events_k ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 35s writing common: node_sort ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 35s writing common: node_out ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 36s writing common: node_in ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 37s writing common: edges_from ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 38s writing common: edges_to ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 38s writing primary: data ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 38s writing primary: node_anchor ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 41s writing xmlids: xid ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 41s writing xmlids: xid edge ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 44s writing xmlids: xid node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 47s writing feature: feature ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 47s writing feature: feature shebanq_ft_lexeme_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 48s writing feature: feature shebanq_ft_graphical_lexeme_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 49s writing feature: feature shebanq_ft_noun_type_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 50s writing feature: feature shebanq_ft_suffix_number_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 51s writing feature: feature shebanq_ft_locative_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 51s writing feature: feature shebanq_ft_paradigmatic_pron_suffix_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 52s writing feature: feature shebanq_ft_phrase_atom_relation_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 53s writing feature: feature shebanq_ft_graphical_root_formation_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 53s writing feature: feature shebanq_ft_graphical_nominal_ending_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 53s writing feature: feature shebanq_ft_paradigmatic_nominal_ending_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 54s writing feature: feature shebanq_ft_aramaic_definite_article_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 54s writing feature: feature shebanq_ft_vocalized_lexeme_utf8_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 55s writing feature: feature shebanq_ft_clause_atom_relation_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 56s writing feature: feature shebanq_ft_gender_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 56s writing feature: feature shebanq_db_oid_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 59s writing feature: feature shebanq_ft_subphrase_type_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 59s writing feature: feature shebanq_mother__edge ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 59s writing feature: feature shebanq_ft_clause_atom_number_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "11m 59s writing feature: feature shebanq_db_minmonad_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 01s writing feature: feature shebanq_ft_tense_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 02s writing feature: feature shebanq_ft_vocalized_lexeme_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 03s writing feature: feature shebanq_ft_graphical_preformative_plain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 03s writing feature: feature shebanq_ft_phrase_atom_type_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 03s writing feature: feature shebanq_ft_indentation_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 04s writing feature: feature shebanq_ft_graphical_verbal_ending_plain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 04s writing feature: feature shebanq_ft_graphical_aramaic_definite_article_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 04s writing feature: feature shebanq_ft_clause_atom_relation_mother_tense_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 04s writing feature: feature shebanq_ft_graphical_preformative_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 04s writing feature: feature shebanq_ft_graphical_lexeme_utf8_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 05s writing feature: feature shebanq_ft_clause_constituent_relation_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 06s writing feature: feature shebanq_ft_lexical_set_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 06s writing feature: feature shebanq_ft_suffix_person_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 07s writing feature: feature shebanq_ft_clause_type_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 07s writing feature: feature shebanq_ft_language_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 08s writing feature: feature shebanq_ft_surface_consonants_utf8_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 09s writing feature: feature shebanq_ft_domain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 09s writing feature: feature shebanq_ft_graphical_nominal_ending_plain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 09s writing feature: feature shebanq_ft_paradigmatic_root_formation_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 10s writing feature: feature shebanq_ft_graphical_pron_suffix_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 10s writing feature: feature shebanq_db_maxmonad_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 12s writing feature: feature shebanq_ft_part_of_speech_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 13s writing feature: feature shebanq_ft_old_lexeme_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 14s writing feature: feature shebanq_ft_number_within_sentence_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 14s writing feature: feature shebanq_ft_number_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 14s writing feature: feature shebanq_ft_surface_consonants_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 15s writing feature: feature shebanq_ft_levels_of_embedding_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 15s writing feature: feature shebanq_ft_graphical_locative_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 15s writing feature: feature shebanq_ft_graphical_verbal_ending_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 15s writing feature: feature shebanq_ft_number_within_chapter_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 16s writing feature: feature shebanq_ft_phrase_dependent_part_of_speech_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 16s writing feature: feature shebanq_ft_old_lexeme_utf8_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 17s writing feature: feature shebanq_ft_is_apposition_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 18s writing feature: feature shebanq_db_otype_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 20s writing feature: feature shebanq_ft_graphical_word_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 21s writing feature: feature shebanq_ft_text_plain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 22s writing feature: feature shebanq_ft_paradigmatic_verbal_ending_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 22s writing feature: feature shebanq_ft_graphical_locative_plain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 22s writing feature: feature shebanq_ft_phrase_atom_number_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 23s writing feature: feature shebanq_ft_pronoun_type_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 23s writing feature: feature shebanq_parents__edge ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 24s writing feature: feature shebanq_ft_phrase_type_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 24s writing feature: feature shebanq_ft_text_type_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 24s writing feature: feature shebanq_ft_paradigmatic_preformative_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 25s writing feature: feature shebanq_ft_clause_atom_relation_kind_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 25s writing feature: feature shebanq_ft_lexeme_utf8_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 26s writing feature: feature shebanq_sft_verse_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 26s writing feature: feature shebanq_ft_phrase_function_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 26s writing feature: feature shebanq_sft_chapter_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 26s writing feature: feature shebanq_ft_state_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 27s writing feature: feature shebanq_ft_sentence_atom_number_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 27s writing feature: feature shebanq_sft_verse_label_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 27s writing feature: feature shebanq_ft_graphical_aramaic_definite_article_plain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 27s writing feature: feature shebanq_ft_subphrase_kind_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 27s writing feature: feature shebanq_db_monads_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 31s writing feature: feature shebanq_ft_determination_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 32s writing feature: feature shebanq_ft_suffix_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 32s writing feature: feature shebanq_ft_stem_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 33s writing feature: feature shebanq_ft_graphical_root_formation_plain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 33s writing feature: feature shebanq_ft_embedding_domain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 34s writing feature: feature shebanq_ft_graphical_pron_suffix_plain_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 34s writing feature: feature shebanq_ft_clause_atom_relation_preposition_class_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 34s writing feature: feature shebanq_ft_clause_atom_type_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 34s writing feature: feature shebanq_sft_half_verse_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 34s writing feature: feature shebanq_ft_word_number_within_book_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 35s writing feature: feature shebanq_sft_book_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 35s writing feature: feature shebanq_ft_suffix_gender_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 36s writing feature: feature shebanq_ft_number_within_clause_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 36s writing feature: feature shebanq_ft_clause_atom_relation_daughter_tense_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 36s writing feature: feature shebanq_ft_text_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 37s writing feature: feature shebanq_ft_person_node ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 38s FINALIZATION\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 38s END COMPILE source: bhs3.txt.hdr\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "12m 38s COMPILING annox: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING DATA: please wait ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s clearing primary: node_anchor ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.57s LOADING DATA: DONE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOGFILE=/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/phrasewords/__log__phrasewords.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN TASK=phrasewords SOURCE=bhs3.txt.hdr\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = processor.API()\n",
      "F = API['F']\n",
      "BF = API['BF']\n",
      "NN = API['NN']\n",
      "C = API['C']\n",
      "Ci = API['Ci']\n",
      "infile = API['infile']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "msg = API['msg']\n",
      "\n",
      "def show(n):\n",
      "    i = 0\n",
      "    for node in NN(test=F.shebanq_db_otype.v, value='phrase'):\n",
      "        i += 1\n",
      "        if i > n:\n",
      "            break\n",
      "        print(\"{:>3} {}\".format(\n",
      "            i,\n",
      "            ''.join(\n",
      "                [\"{}{}\".format(\n",
      "                        F.shebanq_ft_text.v(t),\n",
      "                        F.shebanq_ft_suffix.v(t)\n",
      "                    ) for t in phrase_words[node]\n",
      "                ])\n",
      "        ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    15s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    23s LOADING API: DONE\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The wrong way"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "cur_phrase = None\n",
      "\n",
      "msg(\"start walking through partially-ordered node set\")\n",
      "for node in NN(test=F.shebanq_db_otype.v, values=['phrase', 'word']):\n",
      "    if F.shebanq_db_otype.v(node) == 'phrase':\n",
      "        cur_phrase = node\n",
      "    else:\n",
      "        phrase_words[cur_phrase].append(node)\n",
      "\n",
      "msg(\"end walking through partially-ordered node set\")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    20s start walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    20s Sort order of nodes back to original\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    21s end walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  2 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  3 \n",
        "  4 \u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\u05d5\u05b0\n",
        "  5 \n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  7 \n",
        "  8 \u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d5\u05b8\u05d1\u05b9\u0594\u05d4\u05d5\u05bc \u05d5\u05b0\n",
        "  9 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 10 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \u05d5\u05b0\n",
        " 12 \n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 14 \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\u05d5\u05b7\n",
        " 16 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 17 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 18 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 19 \u05d0\u05b9\u0591\u05d5\u05e8 \n",
        " 20 \u05d5\u05b7\u05bd\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Why is this wrong?**\n",
      "\n",
      "Note the \"empty\" phrases. These things happen because the ``NN()`` operator delivers the nodes in a certain order.\n",
      "When a phrase is bigger than one word, the phrase is guaranteed to appear before each of its words.\n",
      "But when a phrase coincides with just one word, the ordering cannot know that the phrase should come first.\n",
      "\n",
      "The ordering is done by LAF Fabric and does not use any knowledge about the data except what can be known from the structure of the LAF data model.\n",
      "\n",
      "Only nodes that are attached to *region*s of *primary data* are ordered, and their order is based on the key $(x, -y)$, where $x$ is the leftmost anchor in the primary data of a node, and $y$ the rightmost anchor.\n",
      "\n",
      "This is a partial ordering. If two nodes have the same $x$ and $y$, there is no order defined between them."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Right ways"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several ways to do it right.\n",
      "\n",
      "* apply additional ordering\n",
      "* use the *parents* relation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Additional ordering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a new API method ``BF`` (*before*) to check whether a node comes before or after another node. When neither is the case, ``BF``returns ``None``. So we have to apply an additional ordering to the nodes for which ``BF(node_a, node_b) == None``.\n",
      "\n",
      "However, as this is a generic and recurring problem, \n",
      "LAF-Fabric 3.5.2 comes with a new ordering facility within ``NN()`` and here is how to use it.\n",
      "\n",
      "### Pros\n",
      "\n",
      "* This solution is fairly generic\n",
      "* You do not have to load extra features, especially not the costly edge features.\n",
      "* You do not have to use the Connectivity API\n",
      "* Your code remains simple and clean\n",
      "\n",
      "### Cons\n",
      "\n",
      "* Reordering is a bit costly, but you have to do it only once"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "object_rank = {\n",
      "    'book': -4,\n",
      "    'chapter': -3,\n",
      "    'verse': -2,\n",
      "    'half_verse': -1,\n",
      "    'sentence': 1,\n",
      "    'sentence_atom': 2,\n",
      "    'clause': 3,\n",
      "    'clause_atom': 4,\n",
      "    'phrase': 5,\n",
      "    'phrase_atom': 6,\n",
      "    'subphrase': 7,\n",
      "    'word': 8,\n",
      "}\n",
      "\n",
      "def hierarchy(node):\n",
      "    return object_rank[F.shebanq_db_otype.v(node)]\n",
      "\n",
      "for node in NN(extrakey=hierarchy):\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s Resorting 1453175 nodes...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Done\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "cur_phrase = None\n",
      "\n",
      "msg(\"start walking through well-ordered node set\")\n",
      "for node in NN(test=F.shebanq_db_otype.v, values=['phrase', 'word']):\n",
      "    if F.shebanq_db_otype.v(node) == 'phrase':\n",
      "        cur_phrase = node\n",
      "    else:\n",
      "        phrase_words[cur_phrase].append(node)\n",
      "\n",
      "msg(\"end walking through well-ordered node set\")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    45s start walking through well-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s end walking through well-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \n",
        "  2 \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  3 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  4 \u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\n",
        "  5 \u05d5\u05b0\n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \n",
        "  7 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  8 \u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d5\u05b8\u05d1\u05b9\u0594\u05d4\u05d5\u05bc \n",
        "  9 \u05d5\u05b0\n",
        " 10 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \n",
        " 12 \u05d5\u05b0\n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \n",
        " 14 \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\n",
        " 16 \u05d5\u05b7\n",
        " 17 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 18 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 19 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 20 \u05d0\u05b9\u0591\u05d5\u05e8 \n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using parents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An other way is to use the parents relation. Going from a phrase, follow the parents edges in opposite direction\n",
      "until you get to the words. Those words belong to that phrase.\n",
      "\n",
      "### Pros\n",
      "\n",
      "* If the *parents* feature has the right semantics, the correctness of this method is easiest to show.\n",
      "\n",
      "### Cons\n",
      "\n",
      "* This solution depends on the semantics of an extra feature.\n",
      "* Loading an edge feature is a bit costly, but you have to do it only once\n",
      "* You have to use the Connectivity API\n",
      "* your code is more complex, because of the tree walking"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "\n",
      "msg(\"start walking with parents ... \")\n",
      "for phrase in NN(test=F.shebanq_db_otype.v, value='phrase'):\n",
      "    children = []\n",
      "    visited = set()\n",
      "    next_list = [phrase]\n",
      "    while next_list:\n",
      "        new_next_list = []\n",
      "        for node in next_list:\n",
      "            visited.add(node)\n",
      "            next_nodes = Ci.shebanq_parents_[''][node]\n",
      "            for next_node in next_nodes:\n",
      "                if next_node in visited: continue\n",
      "                if F.shebanq_db_otype.v(next_node) == 'word':\n",
      "                    phrase_words[phrase].append(next_node)\n",
      "                else:\n",
      "                    new_next_list.append(next_node)\n",
      "        next_list = new_next_list\n",
      "\n",
      "msg(\"end walking with parents ... \")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    54s start walking with parents ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    56s end walking withparents ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \n",
        "  2 \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  3 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  4 \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \n",
        "  5 \u05d5\u05b0\n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \n",
        "  7 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  8 \u05d5\u05b8\u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d1\u05b9\u0594\u05d4\u05d5\u05bc \n",
        "  9 \u05d5\u05b0\n",
        " 10 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \n",
        " 12 \u05d5\u05b0\n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \n",
        " 14 \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \n",
        " 16 \u05d5\u05b7\n",
        " 17 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 18 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 19 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 20 \u05d0\u05b9\u0591\u05d5\u05e8 \n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.final()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 07s END TASK phrasewords\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 07s Results directory:\n",
        "/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/phrasewords\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "__log__phrasewords.txt                  628 Thu Mar  6 12:56:01 2014\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}