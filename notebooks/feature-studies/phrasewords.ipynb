{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img src=\"files/images/laf-fabric-small.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img src=\"files/images/DANS-small.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img src=\"files/images/TLA-small.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img src=\"files/images/VU-ETCBC-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Phrase Words"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How to list the words in a phrase"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "import laf\n",
      "\n",
      "from laf.notebook import Notebook\n",
      "from etcbc import preprocess\n",
      "\n",
      "processor = Notebook()\n",
      "\n",
      "def show(n):\n",
      "    i = 0\n",
      "    for node in NN(test=F.shebanq_db_otype.v, value='phrase'):\n",
      "        i += 1\n",
      "        if i > n:\n",
      "            break\n",
      "        print(\"{:>3} {}\".format(\n",
      "            i,\n",
      "            ''.join(\n",
      "                [\"{}{}\".format(\n",
      "                        F.shebanq_ft_text.v(t),\n",
      "                        F.shebanq_ft_suffix.v(t)\n",
      "                    ) for t in phrase_words[node]\n",
      "                ])\n",
      "        ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "This is LAF-Fabric 3.6.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Based on the order of nodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.init('bhs3.txt.hdr', '--', 'phrasewords', {\n",
      "    \"primary\": False,\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype\",\n",
      "                \"ft.text,suffix\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "})\n",
      "\n",
      "API = processor.API()\n",
      "F = API['F']\n",
      "BF = API['BF']\n",
      "NN = API['NN']\n",
      "C = API['C']\n",
      "Ci = API['Ci']\n",
      "infile = API['infile']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "msg = API['msg']\n",
      "\n",
      "preprocess.check(API)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING source: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING annox: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING DATA: please wait ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.91s LOADING DATA: DONE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOGFILE=/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/phrasewords/__log__phrasewords.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN TASK=phrasewords SOURCE=bhs3.txt.hdr\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.13s LOADING API: DONE\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "cur_phrase = None\n",
      "\n",
      "msg(\"start walking through partially-ordered node set\")\n",
      "for node in NN(test=F.shebanq_db_otype.v, values=['phrase', 'word']):\n",
      "    if F.shebanq_db_otype.v(node) == 'phrase':\n",
      "        cur_phrase = node\n",
      "    else:\n",
      "        phrase_words[cur_phrase].append(node)\n",
      "\n",
      "msg(\"end walking through partially-ordered node set\")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.58s start walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s end walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \n",
        "  2 \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  3 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  4 \u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\n",
        "  5 \u05d5\u05b0\n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \n",
        "  7 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  8 \u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d5\u05b8\u05d1\u05b9\u0594\u05d4\u05d5\u05bc \n",
        "  9 \u05d5\u05b0\n",
        " 10 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \n",
        " 12 \u05d5\u05b0\n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \n",
        " 14 \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\n",
        " 16 \u05d5\u05b7\n",
        " 17 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 18 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 19 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 20 \u05d0\u05b9\u0591\u05d5\u05e8 \n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Why does this work?**\n",
      "\n",
      "LAF-Fabric has ordered the nodes in a crude way, such that nodes that are linked to the primary data are ordered nicely.\n",
      "A node that starts earlier in the primary data comes before a node that starts later.\n",
      "If two nodes start at the same place in the primary data, then the one that ends *later* comes before the other one.\n",
      "If two nodes start at the same point and end at the same point, their order is undetermined. \n",
      "Note that nodes may be linked to non-contiguous portions of the data. \n",
      "This ordering does not look at gaps, only at starting points and end points.\n",
      "\n",
      "Now, with the ETCBC data we know more.\n",
      "The *etcbc* package has a module *Preprocess* which defines an extra ordering on top of the LAF-Fabric ordering.\n",
      "If two nodes start and end equally, the object type (feature *shebanq_db_otype* is taken into account.\n",
      "There is a hierarchy of object types, and this will be used to resolve those cases.\n",
      "\n",
      "**N.B.** The results of theis reordering are stored on disk.\n",
      "Whenever you call\n",
      "\n",
      "    Prep(API).check()\n",
      "\n",
      "LAF-Fabric looks whether the saved data is still up to date. \n",
      "If not, the data will be (re)computed and saved to disk."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Using parents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An other way is to use the parents relation. Going from a phrase, follow the parents edges in opposite direction\n",
      "until you get to the words. Those words belong to that phrase.\n",
      "\n",
      "### Pros\n",
      "\n",
      "* If the *parents* feature has the right semantics, the correctness of this method is easiest to show.\n",
      "\n",
      "### Cons\n",
      "\n",
      "* This solution depends on the semantics of an extra feature.\n",
      "* Loading an edge feature is a costly\n",
      "* your code is more complex, because of the tree walking"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.init('bhs3.txt.hdr', '--', 'phrasewords', {\n",
      "    \"primary\": False,\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype\",\n",
      "                \"ft.text,suffix\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "                \"parents.\",\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "})\n",
      "\n",
      "API = processor.API()\n",
      "F = API['F']\n",
      "BF = API['BF']\n",
      "NN = API['NN']\n",
      "C = API['C']\n",
      "Ci = API['Ci']\n",
      "infile = API['infile']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "msg = API['msg']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING source: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING annox: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING DATA: please wait ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.24s LOADING DATA: DONE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOGFILE=/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/phrasewords/__log__phrasewords.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN TASK=phrasewords SOURCE=bhs3.txt.hdr\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.03s LOADING API: DONE\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "\n",
      "msg(\"start walking with parents ... \")\n",
      "for phrase in NN(test=F.shebanq_db_otype.v, value='phrase'):\n",
      "    children = []\n",
      "    visited = set()\n",
      "    next_list = [phrase]\n",
      "    while next_list:\n",
      "        new_next_list = []\n",
      "        for node in next_list:\n",
      "            visited.add(node)\n",
      "            next_nodes = Ci.shebanq_parents_[''][node]\n",
      "            for next_node in next_nodes:\n",
      "                if next_node in visited: continue\n",
      "                if F.shebanq_db_otype.v(next_node) == 'word':\n",
      "                    phrase_words[phrase].append(next_node)\n",
      "                else:\n",
      "                    new_next_list.append(next_node)\n",
      "        next_list = new_next_list\n",
      "\n",
      "msg(\"end walking with parents ... \")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.58s start walking with parents ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    13s end walking with parents ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \n",
        "  2 \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  3 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  4 \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \n",
        "  5 \u05d5\u05b0\n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \n",
        "  7 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  8 \u05d5\u05b8\u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d1\u05b9\u0594\u05d4\u05d5\u05bc \n",
        "  9 \u05d5\u05b0\n",
        " 10 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \n",
        " 12 \u05d5\u05b0\n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \n",
        " 14 \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \n",
        " 16 \u05d5\u05b7\n",
        " 17 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 18 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 19 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 20 \u05d0\u05b9\u0591\u05d5\u05e8 \n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.final()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 07s END TASK phrasewords\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 07s Results directory:\n",
        "/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/phrasewords\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "__log__phrasewords.txt                  628 Thu Mar  6 12:56:01 2014\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}