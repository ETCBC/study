{
 "metadata": {
  "name": "",
  "signature": "sha256:22556e13a23872e594c4889b2983ac1bb934b9bdc2dd55554c2e392453fc9c64"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "fabric = LafFabric()\n",
      "from etcbc.preprocess import prepare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.1.4\n",
        "http://laf-fabric.readthedocs.org/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('bhs3.txt.hdr', '--', 'dataprep',\n",
      "        {\n",
      "            \"xmlids\": {\n",
      "                \"node\": True,\n",
      "                \"edge\": True,\n",
      "            },\n",
      "            \"features\": {\n",
      "                \"shebanq\": {\n",
      "                    \"node\": [\n",
      "                        \"db.otype,monads\",\n",
      "                        \"ft.text,surface_consonants\",\n",
      "                        \"ft.phrase_function,locative\",\n",
      "                        \"sft.book,chapter,verse_label,verse\",\n",
      "                    ],\n",
      "                    \"edge\": [\n",
      "                    ],\n",
      "                },\n",
      "            },\n",
      "            'prepare': prepare,\n",
      "        },\n",
      "        compile_main=False, compile_annox=False,\n",
      "        verbose='DETAIL',\n",
      "    )\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s INFO: DATA COMPILED AT: 2014-04-05T09-12-34\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.12s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.23s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.33s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.87s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.96s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.06s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.26s DETAIL: load main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.59s DETAIL: load main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.46s DETAIL: load main: X. [e]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.36s DETAIL: load main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.50s DETAIL: load main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.72s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.75s DETAIL: load main: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.29s DETAIL: load main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.67s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.56s DETAIL: load main: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.50s DETAIL: load main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.53s DETAIL: load main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.54s DETAIL: load main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.57s LOGFILE=/Users/judith/laf-fabric-data/bhs3.txt.hdr/tasks/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.57s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.69s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.28s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = open('CorrectionsFJM.txt', encoding=\"utf8\")\n",
      "lines = [line for line in handle]\n",
      "handle.close()\n",
      "lines[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "'JES 41,19\\t[>FJM <Pr>]\\t[B <RBH <Lo>]\\t[BRWC TDHR W T>CWR <Ob>]\\t[JXDW <Mo>]\\t:CHANGESTO:\\t[B <RBH <Co>]\\n'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "code_def = {\n",
      " '..': '..',\n",
      " 'Aj': 'Adju',\n",
      " 'Cj': 'Conj',\n",
      " 'Co': 'Cmpl',\n",
      " 'Lo': 'Loca',\n",
      " 'Mo': 'Modi',\n",
      " 'Ob': 'Objc',\n",
      " 'PO': 'PreO',\n",
      " 'Pr': 'Pred',\n",
      " 'Ps': 'PreS',\n",
      " 'Su': 'Subj',\n",
      " 'Ti': 'Time',\n",
      " 'sc': 'Supp',\n",
      "}\n",
      "\n",
      "book_def = {\n",
      "    'GEN': 'Genesis',\n",
      "    'EXO': 'Exodus',\n",
      "    'LEV': 'Leviticus',\n",
      "    'NUM': 'Numbers',\n",
      "    'DEU': 'Deuteronomy',\n",
      "    'JOS': 'Joshua',\n",
      "    'JUD': 'Judges',\n",
      "    'ISAM': 'I_Samuel',\n",
      "    'IISA': 'II_Samuel',\n",
      "    'IKON': 'I_Kings',\n",
      "    'IIKON': 'II_Kings',\n",
      "    'JES': 'Isaiah',\n",
      "    'JER': 'Jeremiah',\n",
      "    'EZE': 'Ezekiel',\n",
      "    'HOS': 'Hosea',\n",
      "    'JOE': 'Joel',\n",
      "    'AMO': 'Amos',\n",
      "    'OBA': 'Obadiah',\n",
      "    'JON': 'Jonah',\n",
      "    'MICH': 'Micah',\n",
      "    'NAH': 'Nahum',\n",
      "    'HAB': 'Habakkuk',\n",
      "    'ZEP': 'Zephaniah',\n",
      "    'HAG': 'Haggai',\n",
      "    'ZEC': 'Zechariah',\n",
      "    'MAL': 'Malachi',\n",
      "    'PS': 'Psalms',\n",
      "    'IOB': 'Job',\n",
      "    'PRO': 'Proverbs',\n",
      "    'RUT': 'Ruth',\n",
      "    'CAN': 'Canticles',\n",
      "    'ECC': 'Ecclesiastes',\n",
      "    'LAM': 'Lamentations',\n",
      "    'EST': 'Esther',\n",
      "    'DAN': 'Daniel',\n",
      "    'EZR': 'Ezra',\n",
      "    'NEH': 'Nehemiah',\n",
      "    'I_c': 'I_Chronicles',\n",
      "    'Ii_': 'II_Chronicles',    \n",
      "}\n",
      "\n",
      "def compile_rules(lines):\n",
      "    rules = []\n",
      "    for line in lines:\n",
      "        line = line.strip()\n",
      "        raw_all_fields = line.split('\\t')\n",
      "        passage = raw_all_fields[0]\n",
      "        p_comp = re.findall('^([A-Z]+)\\s*0*([0-9]+)\\s*,\\s*0*([0-9]+)\\s*$', passage)[0]\n",
      "        raw_fields = raw_all_fields[1:-2] + [raw_all_fields[-1]]\n",
      "        string_fields = [f.strip('[]') for f in raw_fields]\n",
      "        fields = [f.rsplit('<', 1) for f in string_fields]\n",
      "        new_fields = [(re.sub('\\s*\\+', '', f[0].rstrip()), code_def[f[1].rstrip('>')]) for f in fields]\n",
      "        rules.append([(book_def[p_comp[0]], p_comp[1], p_comp[2]), new_fields[-1], tuple(new_fields[0:-1])])\n",
      "    \n",
      "    for (i, rule) in enumerate(rules):\n",
      "        (passage, target, context) = rule\n",
      "        (target_words, target_code) = target\n",
      "        hits = []\n",
      "        the_hit = -1\n",
      "        for (n, cw) in enumerate(context):\n",
      "            if cw[0] == target_words: hits.append(n)\n",
      "        if not hits:\n",
      "            msg(\"WARNING: Rule {} [{}]: Nothing fits {} in context {}\".format(i+1, passage, target_words, context))\n",
      "        elif len(hits) > 1:\n",
      "            msg(\"WARNING: Rule {} [{}]: More than one phrase fit {} in context {}\".format(i+1, passage, target_words, context))\n",
      "            the_hit = hits[-1]\n",
      "        else: the_hit = hits[-1]\n",
      "        rule.append(the_hit)\n",
      "    return rules"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_passage(passages):\n",
      "    '''Given a list of passages, look up relevant information for all those passages.\n",
      "    \n",
      "    Do this in one pass over all the nodes.\n",
      "    '''\n",
      "    cur_book = None\n",
      "    cur_chapter = None\n",
      "    cur_passage = None\n",
      "    cur_phrase = [None, []]\n",
      "    verse_phrases = []\n",
      "    \n",
      "    passages_dict = {}\n",
      "    inpassage = False\n",
      "    msg('Look for passages')\n",
      "    for n in NN():\n",
      "        otype = F.otype.v(n)\n",
      "        if otype == 'book':\n",
      "            cur_book = F.book.v(n)\n",
      "        elif otype == 'chapter':\n",
      "            cur_chapter = F.chapter.v(n)\n",
      "        elif otype == 'verse':\n",
      "            cur_verse = F.verse.v(n)\n",
      "            # finish pending phrase\n",
      "            if cur_phrase[0] != None: verse_phrases.append(cur_phrase)  \n",
      "            cur_phrase = [None, []]\n",
      "            # finish pending verse\n",
      "            if verse_phrases:\n",
      "                passages_dict[cur_passage] = {\n",
      "                    'elems': [\n",
      "                        (' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0]), X.r(x[0])) for x in verse_phrases\n",
      "                    ],\n",
      "                    'text': [\n",
      "                        [(F.text.v(y), F.monads.v(y)) for y in x[1]] for x in verse_phrases\n",
      "                    ],\n",
      "                }\n",
      "            verse_phrases = []\n",
      "            if (cur_book, cur_chapter, cur_verse) in passages: \n",
      "                cur_passage = (cur_book, cur_chapter, cur_verse)\n",
      "                inpassage = True\n",
      "                cur_phrase = [None, []]\n",
      "                verse_phrases = []\n",
      "            else: inpassage = False\n",
      "        elif inpassage:\n",
      "            if otype == 'word': cur_phrase[1].append(n)\n",
      "            elif otype == 'phrase':\n",
      "                if cur_phrase[0] != None: verse_phrases.append(cur_phrase)\n",
      "                cur_phrase = [n, []]\n",
      "    # finish pending phrase\n",
      "    if cur_phrase[0] != None: verse_phrases.append(cur_phrase)   \n",
      "    # finish pending verse\n",
      "    if verse_phrases:\n",
      "        passages_dict[cur_passage] = {\n",
      "            'elems': [\n",
      "                (' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0]), X.r(x[0])) for x in verse_phrases\n",
      "            ],\n",
      "            'text': [\n",
      "                [(F.text.v(y), F.monads.v(y)) for y in x[1]] for x in verse_phrases\n",
      "            ],\n",
      "        }\n",
      "    msg(\"End walk\")\n",
      "    return passages_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rules = compile_rules(lines)\n",
      "show = 1\n",
      "rule = rules[show]\n",
      "(passage, target, context, offset) = rule\n",
      "verse = get_passage({passage})[passage]\n",
      "print(\"RULE {}=\\n{}\\nVERSE ELEMS:{}\\nVERSE TEXT={}\".format(show, rule, verse['elems'], verse['text']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    12s Look for passages\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    13s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RULE 1=\n",
        "[('Exodus', '40', '8'), ('SBJB', 'Cmpl'), (('W', 'Conj'), ('FMT', 'Pred'), ('>T H XYR', 'Objc'), ('SBJB', 'Modi')), 3]\n",
        "VERSE ELEMS:[('W', 'Conj', 'n157276'), ('FMT', 'Pred', 'n157277'), ('>T H XYR', 'Objc', 'n157278'), ('SBJB', 'Modi', 'n157279'), ('W', 'Conj', 'n157280'), ('NTT', 'Pred', 'n157281'), ('>T MSK', 'Objc', 'n157282'), ('C<R H XYR', 'Cmpl', 'n157283')]\n",
        "VERSE TEXT=[[('\u05d5\u05b0', '52004')], [('\u05e9\u05b7\u05c2\u05de\u05b0\u05ea\u05b8\u05bc\u05a5', '52005')], [('\u05d0\u05b6\u05ea', '52006'), ('\u05d4\u05b6', '52007'), ('\u05d7\u05b8\u05e6\u05b5\u0596\u05e8', '52008')], [('\u05e1\u05b8\u05d1\u05b4\u0591\u05d9\u05d1', '52009')], [('\u05d5\u05b0', '52010')], [('\u05e0\u05b8\u05a3\u05ea\u05b7\u05ea\u05b8\u05bc\u0594', '52011')], [('\u05d0\u05b6\u05ea', '52012'), ('\u05de\u05b8\u05e1\u05b7\u0596\u05da\u05b0', '52013')], [('\u05e9\u05b7\u05c1\u05a5\u05e2\u05b7\u05e8', '52014'), ('\u05d4\u05b6', '52015'), ('\u05d7\u05b8\u05e6\u05b5\u05bd\u05e8', '52016')]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def match_elem(context, elements):\n",
      "    matches = []\n",
      "    for (e, elem) in enumerate(elements):\n",
      "        equal = True\n",
      "        for (c, cont) in enumerate(context):\n",
      "            if len(elements) < e + c + 1 or cont[0] != elements[e + c][0]:\n",
      "                equal = False\n",
      "                break\n",
      "        if equal: matches.append(e)\n",
      "    return matches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msg(\"Getting the passages material\")\n",
      "elements_dict = get_passage({r[0] for r in rules})\n",
      "msg(\"Done\")\n",
      "annox_list_small = ()\n",
      "data = []\n",
      "\n",
      "for (r, rule) in enumerate(rules):\n",
      "    (passage, target, context, offset) = rule\n",
      "    verse = elements_dict[passage]\n",
      "    verse_elems = verse['elems']\n",
      "    verse_text = verse['text']\n",
      "    matches = match_elem(context, verse_elems)\n",
      "    nm = len(matches)\n",
      "    print('{}: {} matches: {}'.format(passage, nm, matches))\n",
      "    if nm == 0:\n",
      "        print(\"NO MATCH in RULE {}: '{}' versus {}\\n{}\".format(\n",
      "            r, [t[0] for t in context], [\"{} - {}\".format(t[0][0], ','.join([w[1] for w in t[1]])) for t in zip(verse_elems, verse_text)], lines[r],\n",
      "        ))\n",
      "    cut = []\n",
      "    match = matches[0]\n",
      "    cut = verse_elems[match:]\n",
      "    value = cut[offset]\n",
      "    print(\"MATCH\")\n",
      "    print(value)\n",
      "    annox_target = rule[1][1]\n",
      "    nodeid = value[2]\n",
      "    \n",
      "    #WEITER MIT N BEI NODE ID ABSCHNEIDEN!!!\n",
      "    feat = \"phrase_function\"\n",
      "    annox_list_small = (nodeid, annox_target, feat)\n",
      "    data.insert(r, annox_list_small)\n",
      "    annox_list_small= ()\n",
      "    \n",
      "    \n",
      "msg(\"Done\")\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "37m 05s Getting the passages material\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "37m 05s Look for passages\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "37m 06s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "37m 06s Done\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Exodus', '15', '25'): 1 matches: [13]\n",
        "MATCH\n",
        "('CM', 'Loca', 'n149427')\n",
        "n149427\n",
        "('Exodus', '40', '8'): 1 matches: [0]\n",
        "MATCH\n",
        "('SBJB', 'Modi', 'n157279')\n",
        "n157279\n",
        "('Leviticus', '6', '3'): 1 matches: [16]\n",
        "MATCH\n",
        "('>YL H MZBX', 'Adju', 'n209203')\n",
        "n209203\n",
        "('Isaiah', '41', '19'): 0 matches: []\n",
        "NO MATCH in RULE 3: '['>FJM', 'B <RBH', 'BRWC TDHR W T>CWR', 'JXDW']' versus ['>TN - 227281', 'B . MDBR - 227282,227283,227284', '>RZ CVH W HDS W <Y CMN - 227285,227286,227287,227288,227289,227290,227291', '>FJM - 227292', 'B . <RBH - 227293,227294,227295', 'BRWC TDHR W T>CWR - 227296,227297,227298,227299', 'JXDW - 227300']\n",
        "JES 41,19\t[>FJM <Pr>]\t[B <RBH <Lo>]\t[BRWC TDHR W T>CWR <Ob>]\t[JXDW <Mo>]\t:CHANGESTO:\t[B <RBH <Co>]\n",
        "\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-36-0f03d91be85a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         ))\n\u001b[1;32m     19\u001b[0m     \u001b[0mcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverse_elems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_annots(API, data):\n",
      "    \n",
      "    result = []\n",
      "    result.append('''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<graph xmlns=\"http://www.xces.org/ns/GrAF/1.0/\" xmlns:graf=\"http://www.xces.org/ns/GrAF/1.0/\">\n",
      "<graphHeader>\n",
      "    <labelsDecl/>\n",
      "    <dependencies/>\n",
      "    <annotationSpaces/>\n",
      "</graphHeader>''')\n",
      "    aid = 0\n",
      "    features = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: {})))\n",
      "    \n",
      "    for line in data:\n",
      "        node = line[0]\n",
      "        value = line[1]\n",
      "        feat = line[2]\n",
      "        if len(line) > 3:\n",
      "            feat = \"{}.{}\".format(line[3], feat)\n",
      "        if len(line) > 4:\n",
      "            feat = \"{}:{}\".format(line[4], feat)\n",
      "        (aspace, alabel, fname) = API['fabric'].resolve_feature('node', feat)\n",
      "        xml_id = API['X'].r(node)\n",
      "        features[aspace][alabel][xml_id][fname] = value\n",
      "        \n",
      "    for aspace in features:\n",
      "        for alabel in features[aspace]:\n",
      "            for xml_id in features[aspace][alabel]:\n",
      "                aid += 1\n",
      "                result.append('<a xml:id=\"a{}\" as=\"{}\" label=\"{}\" ref=\"{}\"><fs>'.format(aid, aspace, alabel, xml_id))\n",
      "                for fname in features[aspace][alabel][xml_id]:\n",
      "                    value = features[aspace][alabel][xml_id][fname]\n",
      "                    result.append('\\t<f name=\"{}\" value=\"{}\"/>'.format(fname, value))\n",
      "                result.append('</fs></a>')\n",
      "    result.append(\"</graph>\")\n",
      "    return '\\n'.join(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annots = create_annots(API, data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(annots)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<graph xmlns=\"http://www.xces.org/ns/GrAF/1.0/\" xmlns:graf=\"http://www.xces.org/ns/GrAF/1.0/\">\n",
        "<graphHeader>\n",
        "    <labelsDecl/>\n",
        "    <dependencies/>\n",
        "    <annotationSpaces/>\n",
        "</graphHeader>\n",
        "<a xml:id=\"a1\" as=\"shebanq\" label=\"ft\" ref=\"n473280\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"SBJB\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a2\" as=\"shebanq\" label=\"ft\" ref=\"n397114\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"CNJ YBRJM\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a3\" as=\"shebanq\" label=\"ft\" ref=\"n841251\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"B >RY\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a4\" as=\"shebanq\" label=\"ft\" ref=\"n845034\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\">XR H DLT W H MZWZH\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a5\" as=\"shebanq\" label=\"ft\" ref=\"n721821\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"L >JCJ\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a6\" as=\"shebanq\" label=\"ft\" ref=\"n733425\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"K Y>N BYRH\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a7\" as=\"shebanq\" label=\"ft\" ref=\"n844370\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"NPCW\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a8\" as=\"shebanq\" label=\"ft\" ref=\"n836218\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"LJ\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a9\" as=\"shebanq\" label=\"ft\" ref=\"n75277\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"LK\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a10\" as=\"shebanq\" label=\"ft\" ref=\"n1308609\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"MSPR XYWT JRWCLM\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a11\" as=\"shebanq\" label=\"ft\" ref=\"n398163\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"K <PR\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a12\" as=\"shebanq\" label=\"ft\" ref=\"n841734\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"B MDBR\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a13\" as=\"shebanq\" label=\"ft\" ref=\"n601494\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"K MDBR\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a14\" as=\"shebanq\" label=\"ft\" ref=\"n816279\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"B MRWM\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a15\" as=\"shebanq\" label=\"ft\" ref=\"n648441\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\">YL H MZBX\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a16\" as=\"shebanq\" label=\"ft\" ref=\"n388195\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"CM\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a17\" as=\"shebanq\" label=\"ft\" ref=\"n1259485\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"MR>CTJW\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a18\" as=\"shebanq\" label=\"ft\" ref=\"n841075\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"B <RBH\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a19\" as=\"shebanq\" label=\"ft\" ref=\"n733185\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"CMMH\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a20\" as=\"shebanq\" label=\"ft\" ref=\"n1306509\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"L <D\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a21\" as=\"shebanq\" label=\"ft\" ref=\"n394047\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"LW\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a22\" as=\"shebanq\" label=\"ft\" ref=\"n1151357\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"LK\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a23\" as=\"shebanq\" label=\"ft\" ref=\"n845024\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"<L HR GBH W NF>\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a24\" as=\"shebanq\" label=\"ft\" ref=\"n465415\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"CM\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a25\" as=\"shebanq\" label=\"ft\" ref=\"n387676\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"KPJR\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a26\" as=\"shebanq\" label=\"ft\" ref=\"n952639\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"B FWMJ\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a27\" as=\"shebanq\" label=\"ft\" ref=\"n386883\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"YPYPH\"/>\n",
        "</fs></a>\n",
        "</graph>\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}