{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img src=\"files/images/laf-fabric-small.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img src=\"files/images/DANS-small.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img src=\"files/images/TLA-small.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img src=\"files/images/VU-ETCBC-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Phrase Words"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How to list the words in a phrase"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "processor = LafFabric()\n",
      "\n",
      "def show(n):\n",
      "    i = 0\n",
      "    for node in NN(test=F.shebanq_db_otype.v, value='phrase'):\n",
      "        i += 1\n",
      "        if i > n:\n",
      "            break\n",
      "        print(\"{:>3} {}\".format(\n",
      "            i,\n",
      "            ''.join(\n",
      "                [\"{}{}\".format(\n",
      "                        F.shebanq_ft_text.v(t),\n",
      "                        F.shebanq_ft_suffix.v(t)\n",
      "                    ) for t in phrase_words[node]\n",
      "                ])\n",
      "        ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 3.7.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Based on the order of nodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = processor.load('bhs3.txt.hdr', '--', 'phrasewords', {\n",
      "    \"primary\": False,\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype\",\n",
      "                \"ft.text,suffix\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "    'prepare': prepare\n",
      "}, verbose='DETAIL')\n",
      "\n",
      "F = API['F']\n",
      "BF = API['BF']\n",
      "NN = API['NN']\n",
      "C = API['C']\n",
      "Ci = API['Ci']\n",
      "infile = API['infile']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "msg = API['msg']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.16s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.30s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.42s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.07s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.18s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.30s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.25s DETAIL: load main: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.75s DETAIL: load main: F.shebanq_ft_suffix [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.91s DETAIL: load annox: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.91s DETAIL: load annox: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.91s DETAIL: load annox: F.shebanq_ft_suffix [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.91s LOGFILE=/Users/dirk/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/phrasewords/__log__phrasewords.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.92s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.09s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.87s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK phrasewords\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "cur_phrase = None\n",
      "\n",
      "msg(\"start walking through partially-ordered node set\")\n",
      "for node in NN(test=F.shebanq_db_otype.v, values=['phrase', 'word']):\n",
      "    if F.shebanq_db_otype.v(node) == 'phrase':\n",
      "        cur_phrase = node\n",
      "    else:\n",
      "        phrase_words[cur_phrase].append(node)\n",
      "\n",
      "msg(\"end walking through partially-ordered node set\")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.86s start walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.37s end walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \n",
        "  2 \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  3 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  4 \u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\n",
        "  5 \u05d5\u05b0\n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \n",
        "  7 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  8 \u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d5\u05b8\u05d1\u05b9\u0594\u05d4\u05d5\u05bc \n",
        "  9 \u05d5\u05b0\n",
        " 10 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \n",
        " 12 \u05d5\u05b0\n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \n",
        " 14 \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\n",
        " 16 \u05d5\u05b7\n",
        " 17 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 18 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 19 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 20 \u05d0\u05b9\u0591\u05d5\u05e8 \n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Why does this work?**\n",
      "\n",
      "LAF-Fabric has ordered the nodes in a crude way, such that nodes that are linked to the primary data are ordered nicely.\n",
      "A node that starts earlier in the primary data comes before a node that starts later.\n",
      "If two nodes start at the same place in the primary data, then the one that ends *later* comes before the other one.\n",
      "If two nodes start at the same point and end at the same point, their order is undetermined. \n",
      "Note that nodes may be linked to non-contiguous portions of the data. \n",
      "This ordering does not look at gaps, only at starting points and end points.\n",
      "\n",
      "Now, with the ETCBC data we know more.\n",
      "The *etcbc* package has a module *Preprocess* which defines an extra ordering on top of the LAF-Fabric ordering.\n",
      "If two nodes start and end equally, the object type (feature *shebanq_db_otype* is taken into account.\n",
      "There is a hierarchy of object types, and this will be used to resolve those cases.\n",
      "\n",
      "**N.B.** The results of this reordering are stored on disk.\n",
      "Whenever you have\n",
      "\n",
      "    'prepare': *preparation dictionary*\n",
      "\n",
      "in your load dictionary LAF-Fabric looks whether the saved data is still up to date. \n",
      "If not, the data will be (re)computed and saved to disk.\n",
      "The preparation dictionary specifies what should be loaded and how it can be computed.\n",
      "The details of this process are relevant to module developers, not to end users."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Using parents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An other way is to use the parents relation. Going from a phrase, follow the parents edges in opposite direction\n",
      "until you get to the words. Those words belong to that phrase.\n",
      "\n",
      "### Pros\n",
      "\n",
      "* If the *parents* feature has the right semantics, the correctness of this method is easiest to show.\n",
      "\n",
      "### Cons\n",
      "\n",
      "* This solution depends on the semantics of an extra feature.\n",
      "* Loading an edge feature is a costly\n",
      "* your code is more complex, because of the tree walking"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = processor.load('bhs3.txt.hdr', '--', 'phrasewords', {\n",
      "    \"primary\": False,\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype\",\n",
      "                \"ft.text,suffix\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "                \"parents.\",\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "})\n",
      "\n",
      "F = API['F']\n",
      "BF = API['BF']\n",
      "NN = API['NN']\n",
      "C = API['C']\n",
      "Ci = API['Ci']\n",
      "infile = API['infile']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "msg = API['msg']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: keep main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: keep main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: keep main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_ft_suffix [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep annox: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep annox: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep annox: F.shebanq_ft_suffix [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: load main: F.shebanq_parents_ [e] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.43s DETAIL: load main: C.shebanq_parents_ -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.77s DETAIL: load main: C.shebanq_parents_ <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    12s DETAIL: load annox: F.shebanq_parents_ [e] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    12s DETAIL: load annox: C.shebanq_parents_ -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    12s DETAIL: load annox: C.shebanq_parents_ <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    12s LOGFILE=/Users/dirk/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/phrasewords/__log__phrasewords.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    12s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK phrasewords\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "\n",
      "msg(\"start walking with parents ... \")\n",
      "for phrase in NN(test=F.shebanq_db_otype.v, value='phrase'):\n",
      "    children = []\n",
      "    visited = set()\n",
      "    next_list = [phrase]\n",
      "    while next_list:\n",
      "        new_next_list = []\n",
      "        for node in next_list:\n",
      "            visited.add(node)\n",
      "            next_nodes = Ci.shebanq_parents_.v(node)\n",
      "            for next_node in next_nodes:\n",
      "                if next_node in visited: continue\n",
      "                if F.shebanq_db_otype.v(next_node) == 'word':\n",
      "                    phrase_words[phrase].append(next_node)\n",
      "                else:\n",
      "                    new_next_list.append(next_node)\n",
      "        next_list = new_next_list\n",
      "\n",
      "msg(\"end walking with parents ... \")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.67s start walking with parents ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    19s end walking with parents ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \n",
        "  2 \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  3 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  4 \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\n",
        "  5 \u05d5\u05b0\n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \n",
        "  7 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  8 \u05d5\u05b8\u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d1\u05b9\u0594\u05d4\u05d5\u05bc \n",
        "  9 \u05d5\u05b0\n",
        " 10 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \n",
        " 12 \u05d5\u05b0\n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \n",
        " 14 \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\n",
        " 16 \u05d5\u05b7\n",
        " 17 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 18 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 19 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 20 \u05d0\u05b9\u0591\u05d5\u05e8 \n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API['close']()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    27s Results directory:\n",
        "/Users/dirk/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/phrasewords\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "__log__phrasewords.txt                 1388 Fri Mar 21 17:51:00 2014\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}