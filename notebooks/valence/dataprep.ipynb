{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "fabric = LafFabric()\n",
      "from etcbc.preprocess import prepare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.0.5\n",
        "http://laf-fabric.readthedocs.org/texts/API-reference.html\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('bhs3.txt.hdr', '--', 'dataprep',\n",
      "        {\n",
      "            \"xmlids\": {\n",
      "                \"node\": False,\n",
      "                \"edge\": False,\n",
      "            },\n",
      "            \"features\": {\n",
      "                \"shebanq\": {\n",
      "                    \"node\": [\n",
      "                        \"db.otype\",\n",
      "                        \"ft.surface_consonants\",\n",
      "                        \"ft.phrase_function,locative\",\n",
      "                        \"sft.book,verse_label,verse\",\n",
      "                    ],\n",
      "                    \"edge\": [\n",
      "                    ],\n",
      "                },\n",
      "            },\n",
      "            'prepare': prepare,\n",
      "        },\n",
      "        compile_main=False, compile_annox=False,\n",
      "        verbose='DETAIL',\n",
      "    )\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.15s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.28s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.41s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.07s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.18s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.30s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.24s DETAIL: load main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.56s DETAIL: load main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.74s DETAIL: load main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.05s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.07s DETAIL: load main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.10s DETAIL: load main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.12s LOGFILE=/Users/dirk/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.13s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.26s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.98s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Specification of steps ahead\n",
      "\n",
      "1. In the file, find out which of the phrases before :CHANGESTO: has to receive a modified phrase function. This is the target phrase.\n",
      "2. Match the target phrase with a phrase occurrence in the indicated passage in the database.\n",
      "3. Produce an annoting input file, tab separated, 2 columns: the oid of the target phrase, the modified phrase_function.\n",
      "   The name of this column should be shebanq:ft.phrase_function\n",
      "4. Use the module etcbc.annotating (and the method make_form to produce a file of annotations\n",
      "5. put the file of annotations in a new annox (in the annotations directory)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Implementing Flow Charts\n",
      "\n",
      "1. Pick one or two flow charts by Janet.\n",
      "2. translate them in a model.\n",
      "3. Use the model to analyse relevant occurrences of phrases with verbs\n",
      "4. Produce the output of the analysis.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inpassage = False\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() == 'JES 43,19':\n",
      "            inpassage = True\n",
      "        else:\n",
      "            if inpassage == True: break\n",
      "    elif inpassage:\n",
      "        if otype == 'word' or otype == 'phrase':\n",
      "            msg(\"{} ({})\".format(otype, n))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737651)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227161)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737652)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227162)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737653)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227163)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737654)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227164)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737655)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227165)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737656)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227166)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737657)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227167)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737658)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227168)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737659)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227169)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737660)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227170)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737661)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227171)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227173)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227172)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737662)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227174)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737663)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227175)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227176)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s phrase (737664)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s word (227177)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_verse = None\n",
      "cur_phrase = [None, []]\n",
      "phrases = []\n",
      "words = []\n",
      "inpassage = False\n",
      "msg('Look for passage')\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() == 'JES 57,07':\n",
      "            inpassage = True\n",
      "        else:\n",
      "            if inpassage == True: break\n",
      "    elif inpassage:\n",
      "        if otype == 'word':\n",
      "            print('APPEND to {} <{}> : WORD {}'.format(cur_phrase[0], F.phrase_function.v(cur_phrase[0]), F.surface_consonants.v(n)))\n",
      "            cur_phrase[1].append(n)\n",
      "        elif otype == 'phrase':\n",
      "            if cur_phrase[0] != None:\n",
      "                phrases.append(cur_phrase)\n",
      "            cur_phrase = [n, []]\n",
      "if cur_phrase[0] != None:\n",
      "    phrases.append(cur_phrase)\n",
      "\n",
      "msg(\"End walk\")\n",
      "\n",
      "print(' '.join('[{} <{}>]'.format(' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0])) for x in phrases))\n",
      "\n",
      "print(phrases)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s Look for passage\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "APPEND to 740943 <Loca> : WORD <L\n",
        "APPEND to 740943 <Loca> : WORD HR\n",
        "APPEND to 740943 <Loca> : WORD GBH\n",
        "APPEND to 740943 <Loca> : WORD W\n",
        "APPEND to 740943 <Loca> : WORD NF>\n",
        "APPEND to 740944 <Pred> : WORD FMT\n",
        "APPEND to 740945 <Objc> : WORD MCKBK\n",
        "APPEND to 740946 <Modi> : WORD GM\n",
        "APPEND to 740947 <Loca> : WORD CM\n",
        "APPEND to 740948 <Pred> : WORD <LJT\n",
        "APPEND to 740949 <Pred> : WORD L\n",
        "APPEND to 740949 <Pred> : WORD ZBX\n",
        "APPEND to 740950 <Objc> : WORD ZBX\n",
        "[<L HR GBH W NF> <Loca>] [FMT <Pred>] [MCKBK <Objc>] [GM <Modi>] [CM <Loca>] [<LJT <Pred>] [L ZBX <Pred>] [ZBX <Objc>]\n",
        "[[740943, [231588, 231589, 231590, 231591, 231592]], [740944, [231593]], [740945, [231594]], [740946, [231595]], [740947, [231596]], [740948, [231597]], [740949, [231598, 231599]], [740950, [231600]]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = open'CorrectionsFJM.txt')\n",
      "\n",
      "oldlable = re.compile('<([^> ]*)>')\n",
      "changematch = re.compile('') \n",
      "rget = [] \n",
      "targetlist = []\n",
      "\n",
      "for line in handle: \n",
      "    #matches = oldlable.findall(line) \n",
      "    #if matches: \n",
      "        #for match in matches: \n",
      "         #   matchset.add(match) \n",
      "    target = line.split('\\t') \n",
      "    targetlist.append(target)\n",
      "    \n",
      "handle.close()\n",
      "    \n",
      "bad_chars = ']['\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "replacelist = []\n",
      "\n",
      "for element in targetlist: \n",
      "    target = element[-1]\n",
      "    newtarget = rgx.findall(target)\n",
      "    stringtar = ''.join(newtarget)\n",
      "    finaltarget = stringtar.rsplit('<', 1)\n",
      "    needs_to_be_replaced = finaltarget[0]\n",
      "    replacelist.append(needs_to_be_replaced)\n",
      "    \n",
      "targetindex = 0\n",
      "\n",
      "handle = open('CorrectionsFJM.txt')\n",
      "\n",
      "bad_chars = ']['\n",
      "plusw = '\\+$'\n",
      "\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "rgxw = re.compile('[%s]' % plusw)\n",
      "check = 0\n",
      "chunk = collections.defaultdict(list)\n",
      "positions = []\n",
      "\n",
      "for line in handle:\n",
      "    newline = line.split('\\t')\n",
      "    replacement = replacelist[targetindex]\n",
      "    for element in newline:\n",
      "        if rgxw.search(element):\n",
      "            newelement = element.rsplit(' +',1)\n",
      "            correction = ''.join(newelement)\n",
      "            newline = [w.replace(element, correction) for w in newline]\n",
      "        newelement = rgx.findall(element)\n",
      "        finalelement = ''.join(newelement)\n",
      "        result = finalelement.rsplit('<', 1)\n",
      "        if result[0] == replacement and check < 1:\n",
      "            check += 1\n",
      "            #print(result[0])\n",
      "            target = result[0]\n",
      "    checkline = newline[1:-2]\n",
      "    positions.append(newline[0])\n",
      "    checkline = ' '.join(checkline)\n",
      "    chunk[target].append(checkline)\n",
      "    check = 0\n",
      "    targetindex += 1\n",
      "\n",
      "handle.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_verse = None\n",
      "cur_phrase = [None, []]\n",
      "phrases = []\n",
      "words = []\n",
      "inpassage = False\n",
      "msg('Look for passage')\n",
      "\n",
      "count = 1\n",
      "length = len(positions)\n",
      "\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if count < length:\n",
      "            if F.verse_label.v(n).strip() == positions[count]:\n",
      "                inpassage = True\n",
      "                count += 1\n",
      "            else:\n",
      "               inpassage = False\n",
      "    elif inpassage:\n",
      "        if otype == 'word':\n",
      "            cur_phrase[1].append(n)\n",
      "        elif otype == 'phrase':\n",
      "            if cur_phrase[0] != None:\n",
      "                phrases.append(cur_phrase)\n",
      "            cur_phrase = [n, []]\n",
      "\n",
      "\n",
      "print(' '.join('[{} <{}>]'.format(' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0])) for x in phrases))\n",
      "     \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "17m 38s Look for passage\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "EXO 40,08\n",
        "LEV 06,03\n",
        "JES 41,19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "JES 42,04\n",
        "JES 43,19\n",
        "JES 57,07\n",
        "JES 57,08\n",
        "EZE 20,28"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "HAB 02,09"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "PS081,006"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[W <Conj>] [FMT <Pred>] [>T H XYR <Objc>] [SBJB <Modi>] [W <Conj>] [NTT <Pred>] [>T MSK <Objc>] [C<R H XYR <Cmpl>] [W <Conj>] [LBC <Pred>] [H KHN <Subj>] [MDW BD <Objc>] [W <Conj>] [MKNSJ BD <Objc>] [JLBC <Pred>] [<L BFRW <Cmpl>] [W <Conj>] [HRJM <Pred>] [>T H DCN <Objc>] [>CR <Rela>] [T>KL <Pred>] [H >C <Subj>] [>T H <LH <Objc>] [<L H MZBX <Loca>] [W <Conj>] [FMW <PreO>] [>YL H MZBX <Adju>] [>TN <Pred>] [B MDBR . <Loca>] [>RZ CVH W HDS W <Y CMN <Objc>] [>FJM <Pred>] [B <RBH . <Loca>] [BRWC TDHR W T>CWR <Objc>] [JXDW <Modi>] [L> <Nega>] [JKHH <Pred>] [W <Conj>] [L> <Nega>] [JRWY <Pred>] [<D <Conj>] [JFJM <Pred>] [B >RY . <Loca>] [MCPV <Objc>] [W <Conj>] [L TWRTW <Cmpl>] [>JJM <Subj>] [JJXJLW <Pred>] [HNNJ <IntS>] [<FH <PreC>] [XDCH <Objc>] [<TH <Time>] [TYMX <Pred>] [H <Ques>] [LW> <Nega>] [TD<WH <PreO>] [>P <Modi>] [>FJM <Pred>] [B MDBR . <Loca>] [DRK <Objc>] [B JCMWN <Loca>] [NHRWT <Objc>] [<L HR GBH W NF> <Loca>] [FMT <Pred>] [MCKBK <Objc>] [GM <Modi>] [CM <Loca>] [<LJT <Pred>] [L ZBX <Pred>] [ZBX <Objc>] [W <Conj>] [>XR H DLT W H MZWZH <Loca>] [FMT <Pred>] [ZKRWNK <Objc>] [KJ <Conj>] [M >TJ <Adju>] [GLJT <Pred>] [W <Conj>] [T<LJ <Pred>] [HRXBT <Pred>] [MCKBK <Objc>] [W <Conj>] [TKRT <Pred>] [LK <Supp>] [MHM <Cmpl>] [>HBT <Pred>] [MCKBM <Objc>] [JD <Objc>] [XZJT <Pred>] [W <Conj>] [>BJ>M <PreO>] [>L H >RY <Cmpl>] [>CR <Rela>] [NF>TJ <Pred>] [>T JDJ <Objc>] [L TT <Pred>] [>WTH <Objc>] [LHM <Cmpl>] [W <Conj>] [JR>W <Pred>] [KL GB<H RMH W KL <Y <BT <Objc>] [W <Conj>] [JZBXW <Pred>] [CM <Modi>] [>T ZBXJHM <Objc>] [W <Conj>] [JTNW <Pred>] [CM <Modi>] [K<S QRBNM <Objc>] [W <Conj>] [JFJMW <Pred>] [CM <Modi>] [RJX NJXWXJHM <Objc>] [W <Conj>] [JSJKW <Pred>] [CM <Modi>] [>T NSKJHM <Objc>] [HWJ <Intj>] [BY< <Pred>] [BY< R< <Objc>] [L BJTW <Adju>] [L FWM <Pred>] [B MRWM . <Loca>] [QNW <Objc>] [L HNYL <Pred>] [M KP R< <Cmpl>] [<DWT <Unkn>] [B JHWSP <Unkn>] [FMW <PreO>] [B Y>TW <PreO>] [<L >RY MYRJM <Unkn>] [FPT <Unkn>] [L> <Unkn>] [JD<TJ <Pred>]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}