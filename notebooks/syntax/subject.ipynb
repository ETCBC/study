{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "import laf\n",
      "\n",
      "from laf.notebook import Notebook\n",
      "from etcbc import preprocess\n",
      "\n",
      "processor = Notebook()\n",
      "\n",
      "def show(n):\n",
      "    i = 0\n",
      "    for node in NN(test=F.shebanq_db_otype.v, value='phrase'):\n",
      "        i += 1\n",
      "        if i > n:\n",
      "            break\n",
      "        print(\"{:>3} {}\".format(\n",
      "            i,\n",
      "            ''.join(\n",
      "                [\"{}{}\".format(\n",
      "                        F.shebanq_ft_text.v(t),\n",
      "                        F.shebanq_ft_suffix.v(t)\n",
      "                    ) for t in phrase_words[node]\n",
      "                ])\n",
      "        ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "FileNotFoundError",
       "evalue": "[Errno 2] No such file or directory: 'laf-fabric.cfg'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-ed11355f3b1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0metcbc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/judith/miniconda3/lib/python3.3/site-packages/laf/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m         '''\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaftask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLafTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/judith/miniconda3/lib/python3.3/site-packages/laf/settings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem_settings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mmain_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAIN_CFG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nb'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'notebooks/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAIN_CFG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'wb'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'laf_dir'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'locations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'locations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'laf_dir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'locations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'work_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'locations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'laf_subdir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'laf-fabric.cfg'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "This is LAF-Fabric 3.7.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.init('bhs3.txt.hdr', '--', 'subject', {\n",
      "    \"primary\": False,\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype\",\n",
      "                \"ft.text,suffix\",\n",
      "                \"ft.phrase_function\",\n",
      "                \"ft.surface_consonants\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "})\n",
      "\n",
      "API = processor.API()\n",
      "F = API['F']\n",
      "BF = API['BF']\n",
      "NN = API['NN']\n",
      "C = API['C']\n",
      "Ci = API['Ci']\n",
      "infile = API['infile']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "msg = API['msg']\n",
      "\n",
      "preprocess.check(API)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING source: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING annox: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING DATA: please wait ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.31s LOADING DATA: DONE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOGFILE=/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/subject/__log__subject.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN TASK=subject SOURCE=bhs3.txt.hdr\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.17s LOADING API: DONE\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "cur_phrase = None\n",
      "\n",
      "msg(\"start walking through partially-ordered node set\")\n",
      "for node in NN(test=F.shebanq_db_otype.v, values=['phrase', 'word']):\n",
      "    if F.shebanq_db_otype.v(node) == 'phrase':\n",
      "        cur_phrase = node\n",
      "    else:\n",
      "        phrase_words[cur_phrase].append(node)\n",
      "\n",
      "msg(\"end walking through partially-ordered node set\")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.02s start walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 5m 12s END\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.80s end walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \n",
        "  2 \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  3 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  4 \u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\n",
        "  5 \u05d5\u05b0\n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \n",
        "  7 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  8 \u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d5\u05b8\u05d1\u05b9\u0594\u05d4\u05d5\u05bc \n",
        "  9 \u05d5\u05b0\n",
        " 10 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \n",
        " 12 \u05d5\u05b0\n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \n",
        " 14 \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\n",
        " 16 \u05d5\u05b7\n",
        " 17 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 18 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 19 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 20 \u05d0\u05b9\u0591\u05d5\u05e8 \n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "out_handle = outfile(\"output.txt\")\n",
      "\n",
      "def incorrect():\n",
      "    for key in phrase_words:\n",
      "        i = i + 1\n",
      "        #if i > 50:\n",
      "         #   break\n",
      "        if F.shebanq_ft_phrase_function.v(key) == \"Subj\":\n",
      "            words = phrase_words[key] # you never use the variable words again\n",
      "            text = F.shebanq_ft_surface_consonants.v(i)    # wrong: i is just a counter for the number of iterations\n",
      "            out_handle.write(text)\n",
      "            out_handle.write(\"\\n\")\n",
      "            \n",
      "            \n",
      "    # you give the consonantal texts of nodes 0, 1, 2 etc. \n",
      "\n",
      "def dirk():\n",
      "    for key in phrase_words:\n",
      "        if F.shebanq_ft_phrase_function.v(key) == \"Subj\":\n",
      "            words = phrase_words[key] # you never use the variable words again\n",
      "            consonant_reps = [F.shebanq_ft_surface_consonants.v(word) for word in words]\n",
      "            text = ' '.join(consonant_reps)\n",
      "            out_handle.write(\"Subject: {}\\n\".format(text))\n",
      "\n",
      "dirk()\n",
      "            \n",
      "        \n",
      "        \n",
      "            \n",
      "        \n",
      "       \n",
      "        \n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "        \n",
      "        \n",
      "\n",
      "\n",
      "        \n",
      "        \n",
      "    \n",
      "      \n",
      "\t\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}