{
 "metadata": {
  "name": "",
  "signature": "sha256:a8a976fdf62f84df2af280857a08ae456905d17e1af716c28bfb04168d668223"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "fabric = LafFabric()\n",
      "from etcbc.preprocess import prepare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.1.4\n",
        "http://laf-fabric.readthedocs.org/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('bhs3.txt.hdr', '--', 'dataprep',\n",
      "        {\n",
      "            \"xmlids\": {\n",
      "                \"node\": True,\n",
      "                \"edge\": True,\n",
      "            },\n",
      "            \"features\": {\n",
      "                \"shebanq\": {\n",
      "                    \"node\": [\n",
      "                        \"db.otype,monads\",\n",
      "                        \"ft.text,surface_consonants\",\n",
      "                        \"ft.phrase_function,locative\",\n",
      "                        \"sft.book,chapter,verse_label,verse\",\n",
      "                    ],\n",
      "                    \"edge\": [\n",
      "                    ],\n",
      "                },\n",
      "            },\n",
      "            'prepare': prepare,\n",
      "        },\n",
      "        compile_main=False, compile_annox=False,\n",
      "        verbose='DETAIL',\n",
      "    )\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: DATA COMPILED AT: 2014-04-05T09-12-34\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.11s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.20s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.30s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.82s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.91s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.01s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.17s DETAIL: load main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.39s DETAIL: load main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.25s DETAIL: load main: X. [e]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.12s DETAIL: load main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.13s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.15s DETAIL: load main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.17s DETAIL: load main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.39s DETAIL: load main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.65s DETAIL: load main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.67s DETAIL: load main: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.89s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.67s DETAIL: load main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.80s DETAIL: load main: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.23s LOGFILE=/Users/judith/laf-fabric-data/bhs3.txt.hdr/tasks/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.24s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.34s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.92s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = open('/Users/judith/ETCBC/CorrectionsFJM.txt', encoding=\"utf8\")\n",
      "lines = [line for line in handle]\n",
      "handle.close()\n",
      "lines[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "'JES 41,19\\t[>FJM <Pr>]\\t[B <RBH <Lo>]\\t[BRWC TDHR W T>CWR <Ob>]\\t[JXDW <Mo>]\\t:CHANGESTO:\\t[B <RBH <Co>]\\n'"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "code_def = {\n",
      " '..': '..',\n",
      " 'Aj': 'Adju',\n",
      " 'Cj': 'Conj',\n",
      " 'Co': 'Cmpl',\n",
      " 'Lo': 'Loca',\n",
      " 'Mo': 'Modi',\n",
      " 'Ob': 'Objc',\n",
      " 'PO': 'PreO',\n",
      " 'Pr': 'Pred',\n",
      " 'Ps': 'PreS',\n",
      " 'Su': 'Subj',\n",
      " 'Ti': 'Time',\n",
      " 'sc': 'Supp',\n",
      "}\n",
      "\n",
      "book_def = {\n",
      "    'GEN': 'Genesis',\n",
      "    'EXO': 'Exodus',\n",
      "    'LEV': 'Leviticus',\n",
      "    'NUM': 'Numbers',\n",
      "    'DEU': 'Deuteronomy',\n",
      "    'JOS': 'Joshua',\n",
      "    'JUD': 'Judges',\n",
      "    'ISAM': 'I_Samuel',\n",
      "    'IISA': 'II_Samuel',\n",
      "    'IKON': 'I_Kings',\n",
      "    'IIKON': 'II_Kings',\n",
      "    'JES': 'Isaiah',\n",
      "    'JER': 'Jeremiah',\n",
      "    'EZE': 'Ezekiel',\n",
      "    'HOS': 'Hosea',\n",
      "    'JOE': 'Joel',\n",
      "    'AMO': 'Amos',\n",
      "    'OBA': 'Obadiah',\n",
      "    'JON': 'Jonah',\n",
      "    'MICH': 'Micah',\n",
      "    'NAH': 'Nahum',\n",
      "    'HAB': 'Habakkuk',\n",
      "    'ZEP': 'Zephaniah',\n",
      "    'HAG': 'Haggai',\n",
      "    'ZEC': 'Zechariah',\n",
      "    'MAL': 'Malachi',\n",
      "    'PS': 'Psalms',\n",
      "    'IOB': 'Job',\n",
      "    'PRO': 'Proverbs',\n",
      "    'RUT': 'Ruth',\n",
      "    'CAN': 'Canticles',\n",
      "    'ECC': 'Ecclesiastes',\n",
      "    'LAM': 'Lamentations',\n",
      "    'EST': 'Esther',\n",
      "    'DAN': 'Daniel',\n",
      "    'EZR': 'Ezra',\n",
      "    'NEH': 'Nehemiah',\n",
      "    'I_c': 'I_Chronicles',\n",
      "    'Ii_': 'II_Chronicles',    \n",
      "}\n",
      "\n",
      "def compile_rules(lines):\n",
      "    rules = []\n",
      "    for line in lines:\n",
      "        line = line.strip()\n",
      "        raw_all_fields = line.split('\\t')\n",
      "        passage = raw_all_fields[0]\n",
      "        p_comp = re.findall('^([A-Z]+)\\s*0*([0-9]+)\\s*,\\s*0*([0-9]+)\\s*$', passage)[0]\n",
      "        raw_fields = raw_all_fields[1:-2] + [raw_all_fields[-1]]\n",
      "        string_fields = [f.strip('[]') for f in raw_fields]\n",
      "        fields = [f.rsplit('<', 1) for f in string_fields]\n",
      "        new_fields = [(re.sub('\\s*\\+', '', f[0].rstrip()), code_def[f[1].rstrip('>')]) for f in fields]\n",
      "        rules.append([(book_def[p_comp[0]], p_comp[1], p_comp[2]), new_fields[-1], tuple(new_fields[0:-1])])\n",
      "    \n",
      "    for (i, rule) in enumerate(rules):\n",
      "        (passage, target, context) = rule\n",
      "        (target_words, target_code) = target\n",
      "        hits = []\n",
      "        the_hit = -1\n",
      "        for (n, cw) in enumerate(context):\n",
      "            if cw[0] == target_words: hits.append(n)\n",
      "        if not hits:\n",
      "            msg(\"WARNING: Rule {} [{}]: Nothing fits {} in context {}\".format(i+1, passage, target_words, context))\n",
      "        elif len(hits) > 1:\n",
      "            msg(\"WARNING: Rule {} [{}]: More than one phrase fit {} in context {}\".format(i+1, passage, target_words, context))\n",
      "            the_hit = hits[-1]\n",
      "        else: the_hit = hits[-1]\n",
      "        rule.append(the_hit)\n",
      "    return rules"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_passage(passages):\n",
      "    '''Given a list of passages, look up relevant information for all those passages.\n",
      "    \n",
      "    Do this in one pass over all the nodes.\n",
      "    '''\n",
      "    cur_book = None\n",
      "    cur_chapter = None\n",
      "    cur_passage = None\n",
      "    cur_phrase = [None, []]\n",
      "    verse_phrases = []\n",
      "    \n",
      "    passages_dict = {}\n",
      "    inpassage = False\n",
      "    msg('Look for passages')\n",
      "    for n in NN():\n",
      "        otype = F.otype.v(n)\n",
      "        if otype == 'book':\n",
      "            cur_book = F.book.v(n)\n",
      "        elif otype == 'chapter':\n",
      "            cur_chapter = F.chapter.v(n)\n",
      "        elif otype == 'verse':\n",
      "            cur_verse = F.verse.v(n)\n",
      "            # finish pending phrase\n",
      "            if cur_phrase[0] != None: verse_phrases.append(cur_phrase)  \n",
      "            cur_phrase = [None, []]\n",
      "            # finish pending verse\n",
      "            if verse_phrases:\n",
      "                passages_dict[cur_passage] = {\n",
      "                    'elems': [\n",
      "                        (' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0]), X.r(x[0])) for x in verse_phrases\n",
      "                    ],\n",
      "                    'text': [\n",
      "                        [(F.text.v(y), F.monads.v(y)) for y in x[1]] for x in verse_phrases\n",
      "                    ],\n",
      "                }\n",
      "            verse_phrases = []\n",
      "            if (cur_book, cur_chapter, cur_verse) in passages: \n",
      "                cur_passage = (cur_book, cur_chapter, cur_verse)\n",
      "                inpassage = True\n",
      "                cur_phrase = [None, []]\n",
      "                verse_phrases = []\n",
      "            else: inpassage = False\n",
      "        elif inpassage:\n",
      "            if otype == 'word': cur_phrase[1].append(n)\n",
      "            elif otype == 'phrase':\n",
      "                if cur_phrase[0] != None: verse_phrases.append(cur_phrase)\n",
      "                cur_phrase = [n, []]\n",
      "    # finish pending phrase\n",
      "    if cur_phrase[0] != None: verse_phrases.append(cur_phrase)   \n",
      "    # finish pending verse\n",
      "    if verse_phrases:\n",
      "        passages_dict[cur_passage] = {\n",
      "            'elems': [\n",
      "                (' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0]), X.r(x[0])) for x in verse_phrases\n",
      "            ],\n",
      "            'text': [\n",
      "                [(F.text.v(y), F.monads.v(y)) for y in x[1]] for x in verse_phrases\n",
      "            ],\n",
      "        }\n",
      "    msg(\"End walk\")\n",
      "    return passages_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rules = compile_rules(lines)\n",
      "show = 1\n",
      "rule = rules[show]\n",
      "(passage, target, context, offset) = rule\n",
      "verse = get_passage({passage})[passage]\n",
      "print(\"RULE {}=\\n{}\\nVERSE ELEMS:{}\\nVERSE TEXT={}\".format(show, rule, verse['elems'], verse['text']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.66s Look for passages\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RULE 1=\n",
        "[('Exodus', '40', '8'), ('SBJB', 'Cmpl'), (('W', 'Conj'), ('FMT', 'Pred'), ('>T H XYR', 'Objc'), ('SBJB', 'Modi')), 3]\n",
        "VERSE ELEMS:[('W', 'Conj', 'n157276'), ('FMT', 'Pred', 'n157277'), ('>T H XYR', 'Objc', 'n157278'), ('SBJB', 'Modi', 'n157279'), ('W', 'Conj', 'n157280'), ('NTT', 'Pred', 'n157281'), ('>T MSK', 'Objc', 'n157282'), ('C<R H XYR', 'Cmpl', 'n157283')]\n",
        "VERSE TEXT=[[('\u05d5\u05b0', '52004')], [('\u05e9\u05b7\u05c2\u05de\u05b0\u05ea\u05b8\u05bc\u05a5', '52005')], [('\u05d0\u05b6\u05ea', '52006'), ('\u05d4\u05b6', '52007'), ('\u05d7\u05b8\u05e6\u05b5\u0596\u05e8', '52008')], [('\u05e1\u05b8\u05d1\u05b4\u0591\u05d9\u05d1', '52009')], [('\u05d5\u05b0', '52010')], [('\u05e0\u05b8\u05a3\u05ea\u05b7\u05ea\u05b8\u05bc\u0594', '52011')], [('\u05d0\u05b6\u05ea', '52012'), ('\u05de\u05b8\u05e1\u05b7\u0596\u05da\u05b0', '52013')], [('\u05e9\u05b7\u05c1\u05a5\u05e2\u05b7\u05e8', '52014'), ('\u05d4\u05b6', '52015'), ('\u05d7\u05b8\u05e6\u05b5\u05bd\u05e8', '52016')]]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def match_elem(context, elements):\n",
      "    matches = []\n",
      "    for (e, elem) in enumerate(elements):\n",
      "        equal = True\n",
      "        for (c, cont) in enumerate(context):\n",
      "            if len(elements) < e + c + 1 or cont[0] != elements[e + c][0]:\n",
      "                equal = False\n",
      "                break\n",
      "        if equal: matches.append(e)\n",
      "    return matches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msg(\"Getting the passages material\")\n",
      "elements_dict = get_passage({r[0] for r in rules})\n",
      "msg(\"Done\")\n",
      "annox_list_small = ()\n",
      "data = []\n",
      "\n",
      "for (r, rule) in enumerate(rules):\n",
      "    (passage, target, context, offset) = rule\n",
      "    verse = elements_dict[passage]\n",
      "    verse_elems = verse['elems']\n",
      "    verse_text = verse['text']\n",
      "    matches = match_elem(context, verse_elems)\n",
      "    nm = len(matches)\n",
      "    print('{}: {} matches: {}'.format(passage, nm, matches))\n",
      "    if nm == 0:\n",
      "        print(\"NO MATCH in RULE {}: '{}' versus {}\\n{}\".format(\n",
      "            r, [t[0] for t in context], [\"{} - {}\".format(t[0][0], ','.join([w[1] for w in t[1]])) for t in zip(verse_elems, verse_text)], lines[r],\n",
      "        ))\n",
      "        \n",
      "    cut = []\n",
      "    if len(matches) > 0: \n",
      "        match = matches[0]\n",
      "        cut = verse_elems[match:]\n",
      "        value = cut[offset]\n",
      "        #print(\"MATCH\")\n",
      "        #print(value)\n",
      "        annox_target = rule[1][1]\n",
      "        nodeid = value[2]\n",
      "        xmlid = nodeid[1:]\n",
      "        feat = \"phrase_function\"\n",
      "        annox_list_small = (xmlid, annox_target, feat)\n",
      "        data.insert(r, annox_list_small)\n",
      "        annox_list_small= ()\n",
      "        \n",
      "msg(\"Done\")\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    19s Getting the passages material\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    19s Look for passages\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    21s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    21s Done\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    21s Done\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Exodus', '15', '25'): 1 matches: [13]\n",
        "('Exodus', '40', '8'): 1 matches: [0]\n",
        "('Leviticus', '6', '3'): 1 matches: [16]\n",
        "('Isaiah', '41', '19'): 0 matches: []\n",
        "NO MATCH in RULE 3: '['>FJM', 'B <RBH', 'BRWC TDHR W T>CWR', 'JXDW']' versus ['>TN - 227281', 'B . MDBR - 227282,227283,227284', '>RZ CVH W HDS W <Y CMN - 227285,227286,227287,227288,227289,227290,227291', '>FJM - 227292', 'B . <RBH - 227293,227294,227295', 'BRWC TDHR W T>CWR - 227296,227297,227298,227299', 'JXDW - 227300']\n",
        "JES 41,19\t[>FJM <Pr>]\t[B <RBH <Lo>]\t[BRWC TDHR W T>CWR <Ob>]\t[JXDW <Mo>]\t:CHANGESTO:\t[B <RBH <Co>]\n",
        "\n",
        "('Isaiah', '42', '4'): 0 matches: []\n",
        "NO MATCH in RULE 4: '['<D', 'JFJM', 'B >RY', 'MCPV']' versus ['L> - 227499', 'JKHH - 227500', 'W - 227501', 'L> - 227502', 'JRWY - 227503', '<D - 227504', 'JFJM - 227505', 'B . >RY - 227506,227507,227508', 'MCPV - 227509', 'W - 227510', 'L TWRTW - 227511,227512', '>JJM - 227513', 'JJXJLW - 227514']\n",
        "JES 42,04\t[<D <Cj>]\t[JFJM <Pr>]\t[B >RY <Lo>]\t[MCPV <Ob>]\t:CHANGESTO:\t[B >RY <Co>]\n",
        "\n",
        "('Isaiah', '43', '19'): 0 matches: []\n",
        "NO MATCH in RULE 5: '['>P', '>FJM', 'B MDBR', 'DRK']' versus ['HNNJ - 228150', '<FH - 228151', 'XDCH - 228152', '<TH - 228153', 'TYMX - 228154', 'H - 228155', 'LW> - 228156', 'TD<WH - 228157', '>P - 228158', '>FJM - 228159', 'B . MDBR - 228160,228161,228162', 'DRK - 228163', 'B JCMWN - 228164,228165', 'NHRWT - 228166']\n",
        "JES 43,19\t[>P <Mo>]\t[>FJM <Pr>]\t[B MDBR <Lo>]\t[DRK <Ob>]\t:CHANGESTO:\t[B MDBR <Co>]\n",
        "\n",
        "('Isaiah', '57', '7'): 1 matches: [0]\n",
        "('Isaiah', '57', '8'): 1 matches: [0]\n",
        "('Ezekiel', '20', '28'): 1 matches: [20]\n",
        "('Habakkuk', '2', '9'): 0 matches: []\n",
        "NO MATCH in RULE 9: '['L FWM', 'B MRWM', 'QNW']' versus ['HWJ - 304435', 'BY< - 304436', 'BY< R< - 304437,304438', 'L BJTW - 304439,304440', 'L FWM - 304441,304442', 'B . MRWM - 304443,304444,304445', 'QNW - 304446', 'L HNYL - 304447,304448', 'M KP R< - 304449,304450,304451']\n",
        "HAB 02,09\t[L FWM <Pr>]\t[B MRWM <Lo>]\t[QN +W <Ob>]\t:CHANGESTO:\t[B MRWM <Co>]\n",
        "\n",
        "('I_Samuel', '2', '20'): 1 matches: [6]\n",
        "('II_Samuel', '14', '7'): 0 matches: []\n",
        "NO MATCH in RULE 11: '['L BLTJ FWM', 'L >JCJ', 'CM W C>RJT', '<L PNJ H >DMH']' versus ['W - 168779', 'HNH - 168780', 'QMH - 168781', 'KL H MCPXH - 168782,168783,168784', '<L CPXTK - 168785,168786', 'W - 168787', 'J>MRW - 168788', 'TNJ - 168789', '>T MKH >XJW - 168790,168791,168792', 'W - 168793', 'NMTHW - 168794', 'B NPC >XJW - 168795,168796,168797', '>CR - 168798', 'HRG - 168799', 'W - 168800', 'NCMJDH - 168801', 'GM - 168802', '>T H JWRC - 168803,168804,168805', 'W - 168806', 'KBW - 168807', '>T GXLTJ - 168808,168809', '>CR - 168810', 'NC>RH - 168811', 'L BLTJ - 168812,168813', 'FWM - 168814', 'L >JCJ - 168815,168816', 'CM W C>RJT - 168817,168818,168819', '<L PNJ H >DMH - 168820,168821,168822,168823']\n",
        "IISA 14,07\t[L BLTJ FWM <Pr>]\t[L >JC +J <sc>]\t[CM W C>RJT <Ob>]\t[<L PNJ H >DMH <Co>]\t:CHANGESTO:\t[L >JC +J <Aj>]\n",
        "\n",
        "('I_Kings', '20', '34'): 1 matches: [9]\n",
        "('II_Kings', '4', '10'): 1 matches: [3]\n",
        "('Isaiah', '21', '4'): 1 matches: [4]\n",
        "('I_Samuel', '19', '13'): 1 matches: [7]\n",
        "('II_Kings', '10', '8'): 1 matches: [11]\n",
        "('II_Kings', '13', '7'): 0 matches: []\n",
        "NO MATCH in RULE 17: '['W', 'JFMM', 'K <PR']' versus ['KJ - 204042', 'L> - 204043', 'HC>JR - 204044', 'L JHW>XZ - 204045,204046', '<M - 204047', 'KJ >M - 204048,204049', 'XMCJM PRCJM W <FRH RKB W <FRT >LPJM RGLJ - 204050,204051,204052,204053,204054,204055,204056,204057,204058', 'KJ - 204059', '>BDM - 204060', 'MLK >RM - 204061,204062', 'W - 204063', 'JFMM - 204064', 'K . <PR - 204065,204066,204067', 'L DC - 204068,204069']\n",
        "IIKON13,07\t[W <Cj>]\t[JFM +M <PO>]\t[K <PR <Aj>]\t:CHANGESTO:\t[K <PR <Co>]\n",
        "\n",
        "('Isaiah', '53', '10'): 1 matches: [5]\n",
        "('Jeremiah', '11', '13'): 0 matches: []\n",
        "NO MATCH in RULE 19: '['W', 'MSPR XYWT JRWCLM', 'FMTM', 'MZBXWT', 'L BCT']' versus ['KJ - 241612', 'MSPR <RJK - 241613,241614', 'HJW - 241615', '>LHJK - 241616', 'JHWDH - 241617', 'W - 241618', 'MSPR XYWT JRWCLM - 241619,241620,241621', 'FMTM - 241622', 'MZBXWT - 241623', 'L . BCT - 241624,241625,241626', 'MZBXWT - 241627', 'L QVR - 241628,241629', 'L . B<L - 241630,241631,241632']\n",
        "JER 11,13\t[W <Cj>]\t[MSPR XYWT JRWCLM <Su>]\t[FMTM <Pr>]\t[MZBXWT <Ob>]\t[L BCT <Co>]\t:CHANGESTO:\t[MSPR XYWT JRWCLM <Ob>]\n",
        "\n",
        "('Ezekiel', '17', '5'): 1 matches: [8]\n",
        "('Ezekiel', '19', '5'): 1 matches: [10]\n",
        "('Hosea', '2', '5'): 0 matches: []\n",
        "NO MATCH in RULE 22: '['W', 'FMTJH', 'K MDBR']' versus ['PN - 292357', '>PCJVNH - 292358', '<RMH - 292359', 'W - 292360', 'HYGTJH - 292361', 'K JWM - 292362,292363', 'HWLDH - 292364', 'W - 292365', 'FMTJH - 292366', 'K . MDBR - 292367,292368,292369', 'W - 292370', 'CTH - 292371', 'K >RY YJH - 292372,292373,292374', 'W - 292375', 'HMTJH - 292376', 'B . YM> - 292377,292378,292379']\n",
        "HOS 02,05\t[W <Cj>]\t[FMTJ +H <PO>]\t[K MDBR <Aj>]\t:CHANGESTO:\t[K MDBR <Co>]\n",
        "\n",
        "('Micah', '1', '7'): 1 matches: [7]\n",
        "('Micah', '2', '12'): 0 matches: []\n",
        "NO MATCH in RULE 24: '['JXD', '>FJMNW', 'K Y>N BYRH']' versus ['>SP - 301667', '>>SP - 301668', 'J<QB - 301669', 'KLK - 301670', 'QBY - 301671', '>QBY - 301672', 'C>RJT JFR>L - 301673,301674', 'JXD - 301675', '>FJMNW - 301676', 'K Y>N - 301677,301678', 'BYRH - 301679', 'K <DR - 301680,301681', 'B TWK H DBRW - 301682,301683,301684,301685', 'THJMNH - 301686', 'M >DM - 301687,301688']\n",
        "MICH02,12\t[JXD <Mo>]\t[>FJMN +W <PO>]\t[K Y>N BYRH <Aj>]\t:CHANGESTO:\t[K Y>N BYRH <Co>]\n",
        "\n",
        "('Psalms', '89', '30'): 1 matches: [0]\n",
        "('Job', '38', '9'): 1 matches: [0]\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Hier weiter: Die Annotations muessen angepasst werden!!!\n",
      "\n",
      "def create_annots(API, data):\n",
      "    \n",
      "    result = []\n",
      "    result.append('''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<graph xmlns=\"http://www.xces.org/ns/GrAF/1.0/\" xmlns:graf=\"http://www.xces.org/ns/GrAF/1.0/\">\n",
      "<graphHeader>\n",
      "    <labelsDecl/>\n",
      "    <dependencies/>\n",
      "    <annotationSpaces/>\n",
      "</graphHeader>''')\n",
      "    aid = 0\n",
      "    features = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: {})))\n",
      "    \n",
      "    for line in data:\n",
      "        node = line[0]\n",
      "        value = line[1]\n",
      "        feat = line[2]\n",
      "        if len(line) > 3:\n",
      "            feat = \"{}.{}\".format(line[1], feat)\n",
      "        if len(line) > 4:\n",
      "            feat = \"{}:{}\".format(line[2], feat)\n",
      "        (aspace, alabel, fname) = API['fabric'].resolve_feature('node', feat)\n",
      "        xml_id = \"n\" + node\n",
      "        aspace = \"jj\"\n",
      "        features[aspace][alabel][xml_id][fname] = value\n",
      "        \n",
      "    for aspace in features:\n",
      "        for alabel in features[aspace]:\n",
      "            for xml_id in features[aspace][alabel]:\n",
      "                aid += 1\n",
      "                result.append('''<a xml:id=\"a{}\" as=\"{}\" label=\"{}\" ref=\"{}\"><fs>'''.format(aid, aspace, alabel, xml_id))\n",
      "                for fname in features[aspace][alabel][xml_id]:\n",
      "                    value = features[aspace][alabel][xml_id][fname]\n",
      "                    result.append('\\t<f name=\"{}\" value=\"{}\"/>'.format(fname, value))\n",
      "                result.append('</fs></a>')\n",
      "    result.append(\"</graph>\")\n",
      "    return '\\n'.join(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annots = create_annots(API, data)\n",
      "\n",
      "print(annots)\n",
      "\n",
      "fobj = open(\"/Users/judith/laf-fabric-data/bhs3.txt.hdr/annotations/dataprep/annots_judith.xml\", \"w\") \n",
      "\n",
      "fobj.write(annots) \n",
      "fobj.close()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<graph xmlns=\"http://www.xces.org/ns/GrAF/1.0/\" xmlns:graf=\"http://www.xces.org/ns/GrAF/1.0/\">\n",
        "<graphHeader>\n",
        "    <labelsDecl/>\n",
        "    <dependencies/>\n",
        "    <annotationSpaces/>\n",
        "</graphHeader>\n",
        "<a xml:id=\"a1\" as=\"jj\" label=\"ft\" ref=\"n673384\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a2\" as=\"jj\" label=\"ft\" ref=\"n149427\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a3\" as=\"jj\" label=\"ft\" ref=\"n620677\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Adju\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a4\" as=\"jj\" label=\"ft\" ref=\"n753891\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a5\" as=\"jj\" label=\"ft\" ref=\"n1000148\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a6\" as=\"jj\" label=\"ft\" ref=\"n753900\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a7\" as=\"jj\" label=\"ft\" ref=\"n157279\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a8\" as=\"jj\" label=\"ft\" ref=\"n497714\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Adju\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a9\" as=\"jj\" label=\"ft\" ref=\"n670313\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Adju\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a10\" as=\"jj\" label=\"ft\" ref=\"n932843\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a11\" as=\"jj\" label=\"ft\" ref=\"n209203\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a12\" as=\"jj\" label=\"ft\" ref=\"n745089\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Adju\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a13\" as=\"jj\" label=\"ft\" ref=\"n1105969\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Time\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a14\" as=\"jj\" label=\"ft\" ref=\"n504507\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a15\" as=\"jj\" label=\"ft\" ref=\"n932314\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a16\" as=\"jj\" label=\"ft\" ref=\"n931519\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a17\" as=\"jj\" label=\"ft\" ref=\"n753242\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a18\" as=\"jj\" label=\"ft\" ref=\"n1171627\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"PreS\"/>\n",
        "</fs></a>\n",
        "</graph>\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('bhs3.txt.hdr', 'dataprep', 'dataprep', {\n",
      "    \"primary\": True,\n",
      "    \"xmlids\": {\n",
      "        \"node\": True,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype,monads\",\n",
      "                \"ft.text,surface_consonants\",\n",
      "                \"ft.phrase_function,locative\",\n",
      "                \"sft.book,chapter,verse_label,verse\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "            ],\n",
      "        },\n",
      "        \"jj\": {\n",
      "            \"node\": [\n",
      "                \"ft.phrase_function\",\n",
      "            ],\n",
      "        }\n",
      "    },\n",
      "})\n",
      "    \n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: DATA COMPILED AT: 2014-04-05T09-12-34\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN COMPILE a: dataprep\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.15s DETAIL: load main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.39s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.49s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.59s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.69s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.24s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.33s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.44s LOGFILE=/Users/judith/laf-fabric-data/bhs3.txt.hdr/bin/A/dataprep/__log__compile__.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.44s PARSING ANNOTATION FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.45s INFO: parsing annots_judith.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.45s INFO: END PARSING\n",
        "         0 good   regions  and     0 faulty ones\n",
        "         0 linked nodes    and     0 unlinked ones\n",
        "         0 good   edges    and     0 faulty ones\n",
        "        18 good   annots   and     0 faulty ones\n",
        "        18 good   features and     0 faulty ones\n",
        "        18 distinct xml identifiers\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.45s MODELING RESULT FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.45s INFO: CONNECTIVITY\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.58s WRITING RESULT FILES for a\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.58s DETAIL: write annox: F.jj_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.59s END   COMPILE a: dataprep\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.59s INFO: DATA COMPILED AT: 2014-06-03T15-46-45\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.59s DETAIL: keep main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.59s DETAIL: keep main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: keep main: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: clear main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: clear main: X. [e]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.60s DETAIL: load main: P.node_anchor\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.71s DETAIL: load main: P.node_anchor_items\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.13s DETAIL: load main: P.node_events\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.33s DETAIL: load main: P.node_events_items\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.91s DETAIL: load main: P.node_events_k\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.11s DETAIL: load main: P.node_events_n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.44s DETAIL: load main: P.primary_data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.55s DETAIL: load main: F.jj_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.55s DETAIL: load annox: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.55s DETAIL: load annox: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.55s DETAIL: load annox: F.jj_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.55s DETAIL: load annox: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.55s DETAIL: load annox: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s DETAIL: load annox: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s DETAIL: load annox: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s DETAIL: load annox: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s DETAIL: load annox: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s DETAIL: load annox: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s DETAIL: load annox: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s LOGFILE=/Users/judith/laf-fabric-data/bhs3.txt.hdr/tasks/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s INFO: Feature ft_phrase_function refers to shebanq_ft_phrase_function, not to jj_ft_phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s INFO: Feature phrase_function refers to shebanq_ft_phrase_function, not to jj_ft_phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.56s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX dataprep FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for element in NN():\n",
      "    otype = otype = F.shebanq_db_otype.v(node)\n",
      "    jjphrasefunc = F.jj_ft_phrase_function.v(element)\n",
      "    if jjphrasefunc:\n",
      "        xml_id = X.r(element)\n",
      "        valuejj = F.jj_ft_phrase_function.v(element)\n",
      "        valueshebanq = F.shebanq_ft_phrase_function.v(element)\n",
      "        print(\"xml_id={} value jj correction={} value shebanq={}\".format(xml_id, valuejj, valueshebanq))           "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "xml_id=n149427 value jj correction=Cmpl value shebanq=Loca\n",
        "xml_id=n157279 value jj correction=Cmpl value shebanq=Modi"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n209203 value jj correction=Cmpl value shebanq=Adju\n",
        "xml_id=n497714 value jj correction=Adju value shebanq=Supp"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n504507 value jj correction=Objc value shebanq=Cmpl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n620677 value jj correction=Adju value shebanq=Supp"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n670313 value jj correction=Adju value shebanq=Supp\n",
        "xml_id=n673384 value jj correction=Objc value shebanq=Adju\n",
        "xml_id=n745089 value jj correction=Adju value shebanq=Supp"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n753242 value jj correction=Objc value shebanq=Subj"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n753891 value jj correction=Cmpl value shebanq=Loca\n",
        "xml_id=n753900 value jj correction=Cmpl value shebanq=Loca\n",
        "xml_id=n931519 value jj correction=Objc value shebanq=Unkn"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n932314 value jj correction=Objc value shebanq=Unkn\n",
        "xml_id=n932843 value jj correction=Cmpl value shebanq=Modi\n",
        "xml_id=n1000148 value jj correction=Objc value shebanq=Unkn"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n1105969 value jj correction=Time value shebanq=Unkn"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n1171627 value jj correction=PreS value shebanq=PreO"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}