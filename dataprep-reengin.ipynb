{
 "metadata": {
  "name": "",
  "signature": "sha256:acb00594ccfb1d570684f16b0ab4837058954e7e755b2b3fc2637e04d143a1bc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Programming is not a spectator sport! \u2013 Internship report at the Eep Talstra Center for Bible and Computer:  Towards a persuasive valence dictionary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goals of this research internship have been clearly defined: to develop a program supporting the researchers of the Data & Tradition project at the ETCBC  to correct parsing mistakes in a database of the full Hebrew Bible; as an extension of this tool I should list single representatives of diverse valence patterns in a digital dictionary format and extent it to a full-fledged implementation of a mental lexicon as specified in Gottschalk (2010, 2012a, 2014) to develop a valence dictionary\n",
      "\n",
      "Such a valency dictionary is a kind of flow chart by which it is possible to determine verb meanings based on the number and nature of the complements they take. With the valence dictionary we want to be able to automatically match contexts against flow charts. The work in this notebook consists of two parts: applying corrections to the data and implementing flow charts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "fabric = LafFabric()\n",
      "from etcbc.preprocess import prepare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.1.4\n",
        "http://laf-fabric.readthedocs.org/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('bhs3.txt.hdr', '--', 'dataprep',\n",
      "        {\n",
      "            \"xmlids\": {\n",
      "                \"node\": True,\n",
      "                \"edge\": True,\n",
      "            },\n",
      "            \"features\": {\n",
      "                \"shebanq\": {\n",
      "                    \"node\": [\n",
      "                        \"db.otype,monads\",\n",
      "                        \"ft.text,surface_consonants\",\n",
      "                        \"ft.phrase_function,locative\",\n",
      "                        \"sft.book,chapter,verse_label,verse\",\n",
      "                    ],\n",
      "                    \"edge\": [\n",
      "                    ],\n",
      "                },\n",
      "            },\n",
      "            'prepare': prepare,\n",
      "        },\n",
      "        compile_main=False, compile_annox=False,\n",
      "        verbose='DETAIL',\n",
      "    )\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: DATA COMPILED AT: 2014-04-05T09-12-34\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.11s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.19s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.29s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.84s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.93s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.02s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.55s DETAIL: load main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.00s DETAIL: load main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.99s DETAIL: load main: X. [e]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.00s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.83s DETAIL: load main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.85s DETAIL: load main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.88s DETAIL: load main: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.32s DETAIL: load main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.59s DETAIL: load main: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.86s DETAIL: load main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.02s DETAIL: load main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.35s DETAIL: load main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.38s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.40s LOGFILE=/Users/judith/laf-fabric-data/bhs3.txt.hdr/tasks/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.40s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.53s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = open('CorrectionsFJM.txt', encoding=\"utf8\")\n",
      "lines = [line for line in handle]\n",
      "handle.close()\n",
      "lines[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "'JES 41,19\\t[>FJM <Pr>]\\t[B <RBH <Lo>]\\t[BRWC TDHR W T>CWR <Ob>]\\t[JXDW <Mo>]\\t:CHANGESTO:\\t[B <RBH <Co>]\\n'"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "code_def = {\n",
      " '..': '..',\n",
      " 'Aj': 'Adju',\n",
      " 'Cj': 'Conj',\n",
      " 'Co': 'Cmpl',\n",
      " 'Lo': 'Loca',\n",
      " 'Mo': 'Modi',\n",
      " 'Ob': 'Objc',\n",
      " 'PO': 'PreO',\n",
      " 'Pr': 'Pred',\n",
      " 'Ps': 'PreS',\n",
      " 'Su': 'Subj',\n",
      " 'Ti': 'Time',\n",
      " 'sc': 'Supp',\n",
      "}\n",
      "\n",
      "book_def = {\n",
      "    'GEN': 'Genesis',\n",
      "    'EXO': 'Exodus',\n",
      "    'LEV': 'Leviticus',\n",
      "    'NUM': 'Numbers',\n",
      "    'DEU': 'Deuteronomy',\n",
      "    'JOS': 'Joshua',\n",
      "    'JUD': 'Judges',\n",
      "    'ISAM': 'I_Samuel',\n",
      "    'IISA': 'II_Samuel',\n",
      "    'IKON': 'I_Kings',\n",
      "    'IIKON': 'II_Kings',\n",
      "    'JES': 'Isaiah',\n",
      "    'JER': 'Jeremiah',\n",
      "    'EZE': 'Ezekiel',\n",
      "    'HOS': 'Hosea',\n",
      "    'JOE': 'Joel',\n",
      "    'AMO': 'Amos',\n",
      "    'OBA': 'Obadiah',\n",
      "    'JON': 'Jonah',\n",
      "    'MICH': 'Micah',\n",
      "    'NAH': 'Nahum',\n",
      "    'HAB': 'Habakkuk',\n",
      "    'ZEP': 'Zephaniah',\n",
      "    'HAG': 'Haggai',\n",
      "    'ZEC': 'Zechariah',\n",
      "    'MAL': 'Malachi',\n",
      "    'PS': 'Psalms',\n",
      "    'IOB': 'Job',\n",
      "    'PRO': 'Proverbs',\n",
      "    'RUT': 'Ruth',\n",
      "    'CAN': 'Canticles',\n",
      "    'ECC': 'Ecclesiastes',\n",
      "    'LAM': 'Lamentations',\n",
      "    'EST': 'Esther',\n",
      "    'DAN': 'Daniel',\n",
      "    'EZR': 'Ezra',\n",
      "    'NEH': 'Nehemiah',\n",
      "    'I_c': 'I_Chronicles',\n",
      "    'Ii_': 'II_Chronicles',    \n",
      "}\n",
      "\n",
      "def compile_rules(lines):\n",
      "    rules = []\n",
      "    for line in lines:\n",
      "        line = line.strip()\n",
      "        raw_all_fields = line.split('\\t')\n",
      "        passage = raw_all_fields[0]\n",
      "        p_comp = re.findall('^([A-Z]+)\\s*0*([0-9]+)\\s*,\\s*0*([0-9]+)\\s*$', passage)[0]\n",
      "        raw_fields = raw_all_fields[1:-2] + [raw_all_fields[-1]]\n",
      "        string_fields = [f.strip('[]') for f in raw_fields]\n",
      "        fields = [f.rsplit('<', 1) for f in string_fields]\n",
      "        new_fields = [(re.sub('\\s*\\+', '', f[0].rstrip()), code_def[f[1].rstrip('>')]) for f in fields]\n",
      "        rules.append([(book_def[p_comp[0]], p_comp[1], p_comp[2]), new_fields[-1], tuple(new_fields[0:-1])])\n",
      "    \n",
      "    for (i, rule) in enumerate(rules):\n",
      "        (passage, target, context) = rule\n",
      "        (target_words, target_code) = target\n",
      "        hits = []\n",
      "        the_hit = -1\n",
      "        for (n, cw) in enumerate(context):\n",
      "            if cw[0] == target_words: hits.append(n)\n",
      "        if not hits:\n",
      "            msg(\"WARNING: Rule {} [{}]: Nothing fits {} in context {}\".format(i+1, passage, target_words, context))\n",
      "        elif len(hits) > 1:\n",
      "            msg(\"WARNING: Rule {} [{}]: More than one phrase fit {} in context {}\".format(i+1, passage, target_words, context))\n",
      "            the_hit = hits[-1]\n",
      "        else: the_hit = hits[-1]\n",
      "        rule.append(the_hit)\n",
      "    return rules"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_passage(passages):\n",
      "    '''Given a list of passages, look up relevant information for all those passages.\n",
      "    \n",
      "    Do this in one pass over all the nodes.\n",
      "    '''\n",
      "    cur_book = None\n",
      "    cur_chapter = None\n",
      "    cur_passage = None\n",
      "    cur_phrase = [None, []]\n",
      "    verse_phrases = []\n",
      "    \n",
      "    passages_dict = {}\n",
      "    inpassage = False\n",
      "    msg('Look for passages')\n",
      "    for n in NN():\n",
      "        otype = F.otype.v(n)\n",
      "        if otype == 'book':\n",
      "            cur_book = F.book.v(n)\n",
      "        elif otype == 'chapter':\n",
      "            cur_chapter = F.chapter.v(n)\n",
      "        elif otype == 'verse':\n",
      "            cur_verse = F.verse.v(n)\n",
      "            # finish pending phrase\n",
      "            if cur_phrase[0] != None: verse_phrases.append(cur_phrase)  \n",
      "            cur_phrase = [None, []]\n",
      "            # finish pending verse\n",
      "            if verse_phrases:\n",
      "                passages_dict[cur_passage] = {\n",
      "                    'elems': [\n",
      "                        (' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0]), x[0]) for x in verse_phrases\n",
      "                    ],\n",
      "                    'text': [\n",
      "                        [(F.text.v(y), F.monads.v(y)) for y in x[1]] for x in verse_phrases\n",
      "                    ],\n",
      "                }\n",
      "            verse_phrases = []\n",
      "            if (cur_book, cur_chapter, cur_verse) in passages: \n",
      "                cur_passage = (cur_book, cur_chapter, cur_verse)\n",
      "                inpassage = True\n",
      "                cur_phrase = [None, []]\n",
      "                verse_phrases = []\n",
      "            else: inpassage = False\n",
      "        elif inpassage:\n",
      "            if otype == 'word': cur_phrase[1].append(n)\n",
      "            elif otype == 'phrase':\n",
      "                if cur_phrase[0] != None: verse_phrases.append(cur_phrase)\n",
      "                cur_phrase = [n, []]\n",
      "    # finish pending phrase\n",
      "    if cur_phrase[0] != None: verse_phrases.append(cur_phrase)   \n",
      "    # finish pending verse\n",
      "    if verse_phrases:\n",
      "        passages_dict[cur_passage] = {\n",
      "            'elems': [\n",
      "                (' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0]), x[0]) for x in verse_phrases\n",
      "            ],\n",
      "            'text': [\n",
      "                [(F.text.v(y), F.monads.v(y)) for y in x[1]] for x in verse_phrases\n",
      "            ],\n",
      "        }\n",
      "    msg(\"End walk\")\n",
      "    return passages_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rules = compile_rules(lines)\n",
      "show = 1\n",
      "rule = rules[show]\n",
      "(passage, target, context, offset) = rule\n",
      "verse = get_passage({passage})[passage]\n",
      "print(\"RULE {}=\\n{}\\nVERSE ELEMS:{}\\nVERSE TEXT={}\".format(show, rule, verse['elems'], verse['text']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Look for passages\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RULE 1=\n",
        "[('Exodus', '40', '8'), ('SBJB', 'Cmpl'), (('W', 'Conj'), ('FMT', 'Pred'), ('>T H XYR', 'Objc'), ('SBJB', 'Modi')), 3]\n",
        "VERSE ELEMS:[('W', 'Conj', 636037), ('FMT', 'Pred', 636038), ('>T H XYR', 'Objc', 636039), ('SBJB', 'Modi', 636040), ('W', 'Conj', 636041), ('NTT', 'Pred', 636042), ('>T MSK', 'Objc', 636043), ('C<R H XYR', 'Cmpl', 636044)]\n",
        "VERSE TEXT=[[('\u05d5\u05b0', '52004')], [('\u05e9\u05b7\u05c2\u05de\u05b0\u05ea\u05b8\u05bc\u05a5', '52005')], [('\u05d0\u05b6\u05ea', '52006'), ('\u05d4\u05b6', '52007'), ('\u05d7\u05b8\u05e6\u05b5\u0596\u05e8', '52008')], [('\u05e1\u05b8\u05d1\u05b4\u0591\u05d9\u05d1', '52009')], [('\u05d5\u05b0', '52010')], [('\u05e0\u05b8\u05a3\u05ea\u05b7\u05ea\u05b8\u05bc\u0594', '52011')], [('\u05d0\u05b6\u05ea', '52012'), ('\u05de\u05b8\u05e1\u05b7\u0596\u05da\u05b0', '52013')], [('\u05e9\u05b7\u05c1\u05a5\u05e2\u05b7\u05e8', '52014'), ('\u05d4\u05b6', '52015'), ('\u05d7\u05b8\u05e6\u05b5\u05bd\u05e8', '52016')]]\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def match_elem(context, elements):\n",
      "    matches = []\n",
      "    for (e, elem) in enumerate(elements):\n",
      "        equal = True\n",
      "        for (c, cont) in enumerate(context):\n",
      "            if len(elements) < e + c + 1 or cont[0] != elements[e + c][0]:\n",
      "                equal = False\n",
      "                break\n",
      "        if equal: matches.append(e)\n",
      "    return matches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msg(\"Getting the passages material\")\n",
      "elements_dict = get_passage({r[0] for r in rules})\n",
      "msg(\"Done\")\n",
      "annox_list_small = ()\n",
      "data = []\n",
      "\n",
      "for (r, rule) in enumerate(rules):\n",
      "    (passage, target, context, offset) = rule\n",
      "    verse = elements_dict[passage]\n",
      "    verse_elems = verse['elems']\n",
      "    verse_text = verse['text']\n",
      "    matches = match_elem(context, verse_elems)\n",
      "    nm = len(matches)\n",
      "    print('{}: {} matches: {}'.format(passage, nm, matches))\n",
      "    if nm == 0:\n",
      "        print(\"NO MATCH in RULE {}: '{}' versus {}\\n{}\".format(\n",
      "            r, [t[0] for t in context], [\"{} - {}\".format(t[0][0], ','.join([w[1] for w in t[1]])) for t in zip(verse_elems, verse_text)], lines[r],\n",
      "        ))\n",
      "        \n",
      "    cut = []\n",
      "    if len(matches) > 0: \n",
      "        match = matches[0]\n",
      "        cut = verse_elems[match:]\n",
      "        value = cut[offset]\n",
      "        #print(\"MATCH\")\n",
      "        #print(value)\n",
      "        annox_target = rule[1][1]\n",
      "        nodeid = value[2]\n",
      "        xmlid = nodeid\n",
      "        feat = \"phrase_function\"\n",
      "        annox_list_small = (xmlid, annox_target, feat)\n",
      "        data.insert(r, annox_list_small)\n",
      "        annox_list_small= ()\n",
      "        \n",
      "msg(\"Done\")\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 31s Getting the passages material\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 31s Look for passages\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 32s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 32s Done\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 32s Done\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Exodus', '15', '25'): 1 matches: [13]\n",
        "('Exodus', '40', '8'): 1 matches: [0]\n",
        "('Leviticus', '6', '3'): 1 matches: [16]\n",
        "('Isaiah', '41', '19'): 0 matches: []\n",
        "NO MATCH in RULE 3: '['>FJM', 'B <RBH', 'BRWC TDHR W T>CWR', 'JXDW']' versus ['>TN - 227281', 'B . MDBR - 227282,227283,227284', '>RZ CVH W HDS W <Y CMN - 227285,227286,227287,227288,227289,227290,227291', '>FJM - 227292', 'B . <RBH - 227293,227294,227295', 'BRWC TDHR W T>CWR - 227296,227297,227298,227299', 'JXDW - 227300']\n",
        "JES 41,19\t[>FJM <Pr>]\t[B <RBH <Lo>]\t[BRWC TDHR W T>CWR <Ob>]\t[JXDW <Mo>]\t:CHANGESTO:\t[B <RBH <Co>]\n",
        "\n",
        "('Isaiah', '42', '4'): 0 matches: []\n",
        "NO MATCH in RULE 4: '['<D', 'JFJM', 'B >RY', 'MCPV']' versus ['L> - 227499', 'JKHH - 227500', 'W - 227501', 'L> - 227502', 'JRWY - 227503', '<D - 227504', 'JFJM - 227505', 'B . >RY - 227506,227507,227508', 'MCPV - 227509', 'W - 227510', 'L TWRTW - 227511,227512', '>JJM - 227513', 'JJXJLW - 227514']\n",
        "JES 42,04\t[<D <Cj>]\t[JFJM <Pr>]\t[B >RY <Lo>]\t[MCPV <Ob>]\t:CHANGESTO:\t[B >RY <Co>]\n",
        "\n",
        "('Isaiah', '43', '19'): 0 matches: []\n",
        "NO MATCH in RULE 5: '['>P', '>FJM', 'B MDBR', 'DRK']' versus ['HNNJ - 228150', '<FH - 228151', 'XDCH - 228152', '<TH - 228153', 'TYMX - 228154', 'H - 228155', 'LW> - 228156', 'TD<WH - 228157', '>P - 228158', '>FJM - 228159', 'B . MDBR - 228160,228161,228162', 'DRK - 228163', 'B JCMWN - 228164,228165', 'NHRWT - 228166']\n",
        "JES 43,19\t[>P <Mo>]\t[>FJM <Pr>]\t[B MDBR <Lo>]\t[DRK <Ob>]\t:CHANGESTO:\t[B MDBR <Co>]\n",
        "\n",
        "('Isaiah', '57', '7'): 1 matches: [0]\n",
        "('Isaiah', '57', '8'): 1 matches: [0]\n",
        "('Ezekiel', '20', '28'): 1 matches: [20]\n",
        "('Habakkuk', '2', '9'): 0 matches: []\n",
        "NO MATCH in RULE 9: '['L FWM', 'B MRWM', 'QNW']' versus ['HWJ - 304435', 'BY< - 304436', 'BY< R< - 304437,304438', 'L BJTW - 304439,304440', 'L FWM - 304441,304442', 'B . MRWM - 304443,304444,304445', 'QNW - 304446', 'L HNYL - 304447,304448', 'M KP R< - 304449,304450,304451']\n",
        "HAB 02,09\t[L FWM <Pr>]\t[B MRWM <Lo>]\t[QN +W <Ob>]\t:CHANGESTO:\t[B MRWM <Co>]\n",
        "\n",
        "('I_Samuel', '2', '20'): 1 matches: [6]\n",
        "('II_Samuel', '14', '7'): 0 matches: []\n",
        "NO MATCH in RULE 11: '['L BLTJ FWM', 'L >JCJ', 'CM W C>RJT', '<L PNJ H >DMH']' versus ['W - 168779', 'HNH - 168780', 'QMH - 168781', 'KL H MCPXH - 168782,168783,168784', '<L CPXTK - 168785,168786', 'W - 168787', 'J>MRW - 168788', 'TNJ - 168789', '>T MKH >XJW - 168790,168791,168792', 'W - 168793', 'NMTHW - 168794', 'B NPC >XJW - 168795,168796,168797', '>CR - 168798', 'HRG - 168799', 'W - 168800', 'NCMJDH - 168801', 'GM - 168802', '>T H JWRC - 168803,168804,168805', 'W - 168806', 'KBW - 168807', '>T GXLTJ - 168808,168809', '>CR - 168810', 'NC>RH - 168811', 'L BLTJ - 168812,168813', 'FWM - 168814', 'L >JCJ - 168815,168816', 'CM W C>RJT - 168817,168818,168819', '<L PNJ H >DMH - 168820,168821,168822,168823']\n",
        "IISA 14,07\t[L BLTJ FWM <Pr>]\t[L >JC +J <sc>]\t[CM W C>RJT <Ob>]\t[<L PNJ H >DMH <Co>]\t:CHANGESTO:\t[L >JC +J <Aj>]\n",
        "\n",
        "('I_Kings', '20', '34'): 1 matches: [9]\n",
        "('II_Kings', '4', '10'): 1 matches: [3]\n",
        "('Isaiah', '21', '4'): 1 matches: [4]\n",
        "('I_Samuel', '19', '13'): 1 matches: [7]\n",
        "('II_Kings', '10', '8'): 1 matches: [11]\n",
        "('II_Kings', '13', '7'): 0 matches: []\n",
        "NO MATCH in RULE 17: '['W', 'JFMM', 'K <PR']' versus ['KJ - 204042', 'L> - 204043', 'HC>JR - 204044', 'L JHW>XZ - 204045,204046', '<M - 204047', 'KJ >M - 204048,204049', 'XMCJM PRCJM W <FRH RKB W <FRT >LPJM RGLJ - 204050,204051,204052,204053,204054,204055,204056,204057,204058', 'KJ - 204059', '>BDM - 204060', 'MLK >RM - 204061,204062', 'W - 204063', 'JFMM - 204064', 'K . <PR - 204065,204066,204067', 'L DC - 204068,204069']\n",
        "IIKON13,07\t[W <Cj>]\t[JFM +M <PO>]\t[K <PR <Aj>]\t:CHANGESTO:\t[K <PR <Co>]\n",
        "\n",
        "('Isaiah', '53', '10'): 1 matches: [5]\n",
        "('Jeremiah', '11', '13'): 0 matches: []\n",
        "NO MATCH in RULE 19: '['W', 'MSPR XYWT JRWCLM', 'FMTM', 'MZBXWT', 'L BCT']' versus ['KJ - 241612', 'MSPR <RJK - 241613,241614', 'HJW - 241615', '>LHJK - 241616', 'JHWDH - 241617', 'W - 241618', 'MSPR XYWT JRWCLM - 241619,241620,241621', 'FMTM - 241622', 'MZBXWT - 241623', 'L . BCT - 241624,241625,241626', 'MZBXWT - 241627', 'L QVR - 241628,241629', 'L . B<L - 241630,241631,241632']\n",
        "JER 11,13\t[W <Cj>]\t[MSPR XYWT JRWCLM <Su>]\t[FMTM <Pr>]\t[MZBXWT <Ob>]\t[L BCT <Co>]\t:CHANGESTO:\t[MSPR XYWT JRWCLM <Ob>]\n",
        "\n",
        "('Ezekiel', '17', '5'): 1 matches: [8]\n",
        "('Ezekiel', '19', '5'): 1 matches: [10]\n",
        "('Hosea', '2', '5'): 0 matches: []\n",
        "NO MATCH in RULE 22: '['W', 'FMTJH', 'K MDBR']' versus ['PN - 292357', '>PCJVNH - 292358', '<RMH - 292359', 'W - 292360', 'HYGTJH - 292361', 'K JWM - 292362,292363', 'HWLDH - 292364', 'W - 292365', 'FMTJH - 292366', 'K . MDBR - 292367,292368,292369', 'W - 292370', 'CTH - 292371', 'K >RY YJH - 292372,292373,292374', 'W - 292375', 'HMTJH - 292376', 'B . YM> - 292377,292378,292379']\n",
        "HOS 02,05\t[W <Cj>]\t[FMTJ +H <PO>]\t[K MDBR <Aj>]\t:CHANGESTO:\t[K MDBR <Co>]\n",
        "\n",
        "('Micah', '1', '7'): 1 matches: [7]\n",
        "('Micah', '2', '12'): 0 matches: []\n",
        "NO MATCH in RULE 24: '['JXD', '>FJMNW', 'K Y>N BYRH']' versus ['>SP - 301667', '>>SP - 301668', 'J<QB - 301669', 'KLK - 301670', 'QBY - 301671', '>QBY - 301672', 'C>RJT JFR>L - 301673,301674', 'JXD - 301675', '>FJMNW - 301676', 'K Y>N - 301677,301678', 'BYRH - 301679', 'K <DR - 301680,301681', 'B TWK H DBRW - 301682,301683,301684,301685', 'THJMNH - 301686', 'M >DM - 301687,301688']\n",
        "MICH02,12\t[JXD <Mo>]\t[>FJMN +W <PO>]\t[K Y>N BYRH <Aj>]\t:CHANGESTO:\t[K Y>N BYRH <Co>]\n",
        "\n",
        "('Psalms', '89', '30'): 1 matches: [0]\n",
        "('Job', '38', '9'): 1 matches: [0]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Hier weiter: Die Annotations muessen angepasst werden!!!\n",
      "\n",
      "def create_annots(API, data):\n",
      "    \n",
      "    result = []\n",
      "    result.append('''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<graph xmlns=\"http://www.xces.org/ns/GrAF/1.0/\" xmlns:graf=\"http://www.xces.org/ns/GrAF/1.0/\">\n",
      "<graphHeader>\n",
      "    <labelsDecl/>\n",
      "    <dependencies/>\n",
      "    <annotationSpaces/>\n",
      "</graphHeader>''')\n",
      "    aid = 0\n",
      "    features = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: {})))\n",
      "    \n",
      "    for line in data:\n",
      "        node = line[0]\n",
      "        value = line[1]\n",
      "        feat = line[2]\n",
      "        if len(line) > 3:\n",
      "            feat = \"{}.{}\".format(line[1], feat)\n",
      "        if len(line) > 4:\n",
      "            feat = \"{}:{}\".format(line[2], feat)\n",
      "        (aspace, alabel, fname) = API['fabric'].resolve_feature('node', feat)\n",
      "        xml_id = X.r(node)\n",
      "        aspace = \"jj\"\n",
      "        features[aspace][alabel][xml_id][fname] = value\n",
      "        \n",
      "    for aspace in features:\n",
      "        for alabel in features[aspace]:\n",
      "            for xml_id in features[aspace][alabel]:\n",
      "                aid += 1\n",
      "                result.append('''<a xml:id=\"a{}\" as=\"{}\" label=\"{}\" ref=\"{}\"><fs>'''.format(aid, aspace, alabel, xml_id))\n",
      "                for fname in features[aspace][alabel][xml_id]:\n",
      "                    value = features[aspace][alabel][xml_id][fname]\n",
      "                    result.append('\\t<f name=\"{}\" value=\"{}\"/>'.format(fname, value))\n",
      "                result.append('</fs></a>')\n",
      "    result.append(\"</graph>\")\n",
      "    return '\\n'.join(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annots = create_annots(API, data)\n",
      "\n",
      "print(annots)\n",
      "\n",
      "fobj = open(\"/Users/judith/laf-fabric-data/bhs3.txt.hdr/annotations/dataprep/annots_judith.xml\", \"w\") \n",
      "\n",
      "fobj.write(annots) \n",
      "fobj.close()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s INFO: Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<graph xmlns=\"http://www.xces.org/ns/GrAF/1.0/\" xmlns:graf=\"http://www.xces.org/ns/GrAF/1.0/\">\n",
        "<graphHeader>\n",
        "    <labelsDecl/>\n",
        "    <dependencies/>\n",
        "    <annotationSpaces/>\n",
        "</graphHeader>\n",
        "<a xml:id=\"a1\" as=\"jj\" label=\"ft\" ref=\"n157279\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a2\" as=\"jj\" label=\"ft\" ref=\"n931519\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a3\" as=\"jj\" label=\"ft\" ref=\"n753891\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a4\" as=\"jj\" label=\"ft\" ref=\"n497714\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Adju\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a5\" as=\"jj\" label=\"ft\" ref=\"n673384\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a6\" as=\"jj\" label=\"ft\" ref=\"n620677\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Adju\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a7\" as=\"jj\" label=\"ft\" ref=\"n932843\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a8\" as=\"jj\" label=\"ft\" ref=\"n1105969\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Time\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a9\" as=\"jj\" label=\"ft\" ref=\"n670313\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Adju\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a10\" as=\"jj\" label=\"ft\" ref=\"n504507\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a11\" as=\"jj\" label=\"ft\" ref=\"n209203\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a12\" as=\"jj\" label=\"ft\" ref=\"n1171627\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"PreS\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a13\" as=\"jj\" label=\"ft\" ref=\"n753900\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a14\" as=\"jj\" label=\"ft\" ref=\"n932314\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a15\" as=\"jj\" label=\"ft\" ref=\"n753242\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a16\" as=\"jj\" label=\"ft\" ref=\"n745089\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Adju\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a17\" as=\"jj\" label=\"ft\" ref=\"n1000148\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Objc\"/>\n",
        "</fs></a>\n",
        "<a xml:id=\"a18\" as=\"jj\" label=\"ft\" ref=\"n149427\"><fs>\n",
        "\t<f name=\"phrase_function\" value=\"Cmpl\"/>\n",
        "</fs></a>\n",
        "</graph>\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('bhs3.txt.hdr', 'dataprep', 'dataprep', {\n",
      "    \"primary\": True,\n",
      "    \"xmlids\": {\n",
      "        \"node\": True,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype,monads\",\n",
      "                \"ft.text,surface_consonants\",\n",
      "                \"ft.phrase_function,locative\",\n",
      "                \"sft.book,chapter,verse_label,verse\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "            ],\n",
      "        },\n",
      "        \"jj\": {\n",
      "            \"node\": [\n",
      "                \"ft.phrase_function\",\n",
      "            ],\n",
      "        }\n",
      "    },\n",
      "})\n",
      "    \n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: DATA COMPILED AT: 2014-04-05T09-12-34\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: DATA COMPILED AT:  Feature phrase_function may mean any of jj:ft.phrase_function, shebanq:ft.phrase_function. Choosing shebanq:ft.phrase_function\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: keep main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: clear main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: clear main: X. [e]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: load main: P.node_anchor\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.11s DETAIL: load main: P.node_anchor_items\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.56s DETAIL: load main: P.node_events\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.76s DETAIL: load main: P.node_events_items\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.36s DETAIL: load main: P.node_events_k\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.57s DETAIL: load main: P.node_events_n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.89s DETAIL: load main: P.primary_data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load main: F.jj_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load annox: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load annox: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load annox: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load annox: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load annox: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load annox: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load annox: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.97s DETAIL: load annox: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.98s DETAIL: load annox: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.98s DETAIL: load annox: F.jj_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.98s DETAIL: load annox: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.98s LOGFILE=/Users/judith/laf-fabric-data/bhs3.txt.hdr/tasks/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.98s INFO: Feature phrase_function refers to shebanq_ft_phrase_function, not to jj_ft_phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.98s INFO: Feature ft_phrase_function refers to shebanq_ft_phrase_function, not to jj_ft_phrase_function\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.98s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX dataprep FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for element in NN():\n",
      "    jjphrasefunc = F.jj_ft_phrase_function.v(element)\n",
      "    if jjphrasefunc:\n",
      "        otype = otype = F.shebanq_db_otype.v(element)\n",
      "        xml_id = X.r(element)\n",
      "        valueshebanq = F.shebanq_ft_phrase_function.v(element)\n",
      "        print(\"xml_id={} value jj correction={} value shebanq={} otype={} element={}\".format(xml_id, jjphrasefunc, valueshebanq, otype, element))           "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "xml_id=n149427 value jj correction=Cmpl value shebanq=Loca otype=phrase element=628188\n",
        "xml_id=n157279 value jj correction=Cmpl value shebanq=Modi otype=phrase element=636040\n",
        "xml_id=n209203 value jj correction=Cmpl value shebanq=Adju otype=phrase element=637690\n",
        "xml_id=n497714 value jj correction=Adju value shebanq=Supp otype=phrase element=685929"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n504507 value jj correction=Objc value shebanq=Cmpl otype=phrase element=692722\n",
        "xml_id=n620677 value jj correction=Adju value shebanq=Supp otype=phrase element=716595"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n670313 value jj correction=Adju value shebanq=Supp otype=phrase element=719185\n",
        "xml_id=n673384 value jj correction=Objc value shebanq=Adju otype=phrase element=722256\n",
        "xml_id=n745089 value jj correction=Adju value shebanq=Supp otype=phrase element=732141"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n753242 value jj correction=Objc value shebanq=Subj otype=phrase element=740294\n",
        "xml_id=n753891 value jj correction=Cmpl value shebanq=Loca otype=phrase element=740943\n",
        "xml_id=n753900 value jj correction=Cmpl value shebanq=Loca otype=phrase element=740952\n",
        "xml_id=n931519 value jj correction=Objc value shebanq=Unkn otype=phrase element=765729"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n932314 value jj correction=Objc value shebanq=Unkn otype=phrase element=766524\n",
        "xml_id=n932843 value jj correction=Cmpl value shebanq=Modi otype=phrase element=767053\n",
        "xml_id=n1000148 value jj correction=Objc value shebanq=Unkn otype=phrase element=783184"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n1105969 value jj correction=Time value shebanq=Unkn otype=phrase element=801346"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "xml_id=n1171627 value jj correction=PreS value shebanq=PreO otype=phrase element=815739"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}