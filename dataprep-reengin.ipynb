{
 "metadata": {
  "name": "",
  "signature": "sha256:fa0a010fb5f3247463279b363ef13fd16c880d9141e38dff81de16ab70544d1d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "fabric = LafFabric()\n",
      "from etcbc.preprocess import prepare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.1.4\n",
        "http://laf-fabric.readthedocs.org/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('bhs3.txt.hdr', '--', 'dataprep',\n",
      "        {\n",
      "            \"xmlids\": {\n",
      "                \"node\": True,\n",
      "                \"edge\": True,\n",
      "            },\n",
      "            \"features\": {\n",
      "                \"shebanq\": {\n",
      "                    \"node\": [\n",
      "                        \"db.otype,monads\",\n",
      "                        \"ft.text,surface_consonants\",\n",
      "                        \"ft.phrase_function,locative\",\n",
      "                        \"sft.book,chapter,verse_label,verse\",\n",
      "                    ],\n",
      "                    \"edge\": [\n",
      "                    ],\n",
      "                },\n",
      "            },\n",
      "            'prepare': prepare,\n",
      "        },\n",
      "        compile_main=False, compile_annox=False,\n",
      "        verbose='DETAIL',\n",
      "    )\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s INFO: DATA COMPILED AT: 2014-04-05T09-12-34\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.12s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.23s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.33s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.87s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.97s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.09s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.52s DETAIL: load main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.83s DETAIL: load main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.63s DETAIL: load main: X. [e]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.52s DETAIL: load main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.55s DETAIL: load main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.70s DETAIL: load main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.72s DETAIL: load main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.95s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.75s DETAIL: load main: F.shebanq_ft_text [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.16s DETAIL: load main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.17s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.19s DETAIL: load main: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.13s DETAIL: load main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.37s LOGFILE=/Users/judith/laf-fabric-data/bhs3.txt.hdr/tasks/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.38s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.48s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.03s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = open('CorrectionsFJM.txt', encoding=\"utf8\")\n",
      "lines = [line for line in handle]\n",
      "handle.close()\n",
      "lines[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "'JES 41,19\\t[>FJM <Pr>]\\t[B <RBH <Lo>]\\t[BRWC TDHR W T>CWR <Ob>]\\t[JXDW <Mo>]\\t:CHANGESTO:\\t[B <RBH <Co>]\\n'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "code_def = {\n",
      "    '..' : '..',\n",
      "    'Aj' : 'Adju',\n",
      "    'Cj' : 'Conj',\n",
      "    'Co' : 'Cmpl',\n",
      "    'Lo' : 'Loca',\n",
      "    'Mo' : 'Modi',\n",
      "    'Ob' : 'Objc',\n",
      "    'PO' : 'PreO',\n",
      "    'Pr' : 'Pred',\n",
      "    'Ps' : 'PreS',\n",
      "    'Su' : 'Subj',\n",
      "    'Ti' : 'Time',\n",
      "    'sc' : 'Supp',\n",
      "}\n",
      "\n",
      "book_def = {\n",
      "    'GEN': 'Genesis',\n",
      "    'EXO': 'Exodus',\n",
      "    'LEV': 'Leviticus',\n",
      "    'NUM': 'Numbers',\n",
      "    'DEU': 'Deuteronomy',\n",
      "    'JOS': 'Joshua',\n",
      "    'JUD': 'Judges',\n",
      "    'ISAM': 'I_Samuel',\n",
      "    'IISA': 'II_Samuel',\n",
      "    'IKON': 'I_Kings',\n",
      "    'IIKON': 'II_Kings',\n",
      "    'JES': 'Isaiah',\n",
      "    'JER': 'Jeremiah',\n",
      "    'EZE': 'Ezekiel',\n",
      "    'HOS': 'Hosea',\n",
      "    'JOE': 'Joel',\n",
      "    'AMO': 'Amos',\n",
      "    'OBA': 'Obadiah',\n",
      "    'JON': 'Jonah',\n",
      "    'MICH': 'Micah',\n",
      "    'NAH': 'Nahum',\n",
      "    'HAB': 'Habakkuk',\n",
      "    'ZEP': 'Zephaniah',\n",
      "    'HAG': 'Haggai',\n",
      "    'ZEC': 'Zechariah',\n",
      "    'MAL': 'Malachi',\n",
      "    'PS': 'Psalms',\n",
      "    'IOB': 'Job',\n",
      "    'PRO': 'Proverbs',\n",
      "    'RUT': 'Ruth',\n",
      "    'CAN': 'Canticles',\n",
      "    'ECC': 'Ecclesiastes',\n",
      "    'LAM': 'Lamentations',\n",
      "    'EST': 'Esther',\n",
      "    'DAN': 'Daniel',\n",
      "    'EZR': 'Ezra',\n",
      "    'NEH': 'Nehemiah',\n",
      "    'I_c': 'I_Chronicles',\n",
      "    'Ii_': 'II_Chronicles',    \n",
      "}\n",
      "\n",
      "def compile_rules(lines):\n",
      "    rules = []\n",
      "    i = 0\n",
      "    for line in lines:\n",
      "        line = line.strip()\n",
      "        raw_all_fields = line.split('\\t')\n",
      "        passage = raw_all_fields[0]\n",
      "        p_comp = re.findall('^([A-Z]+)\\s*0*([0-9]+)\\s*,\\s*0*([0-9]+)\\s*$', passage)[0]\n",
      "        raw_fields = raw_all_fields[1:-2] + [raw_all_fields[-1]]\n",
      "        string_fields = [f.strip('[]') for f in raw_fields]\n",
      "        fields = [f.rsplit('<',1) for f in string_fields]\n",
      "        new_fields = [(re.sub('\\s*\\+', '', f[0].rstrip()), code_def[f[1].rstrip('>')]) for f in fields]\n",
      "        rules.append([(book_def[p_comp[0]], p_comp[1], p_comp[2]), new_fields[-1], tuple(new_fields[0:-1])])\n",
      "        \n",
      "        for(i, rule) in enumerate(rules):\n",
      "            (passage, target, context) = rule\n",
      "            (target_words, target_code) = target\n",
      "            hits = []\n",
      "            the_hit = -1\n",
      "            for(n, cw) in enumerate(context):\n",
      "                if cw[0] == target_words: hits.append(n)\n",
      "            if not hits:\n",
      "                msg(\"WARNING: Rule {} [{}]: Nothin fits {} in context {}\" .format(i+1, passage, target_word, context))\n",
      "            elif len(hits) > 1:\n",
      "                msg(\"WARNING: Rule {} [{}]: More than one phrase fit {} in context {}\". format(i+1, passage, target_words, context))\n",
      "                the_hit = hits[-1]\n",
      "            else: the_hit = hits[-1]\n",
      "            rule.append(the_hit)\n",
      "        return rules\n",
      "compile_rules(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "[[('Exodus', '15', '25'),\n",
        "  ('CM', 'Cmpl'),\n",
        "  (('CM', 'Loca'), ('FM', 'Pred'), ('LW', 'Cmpl'), ('XQ W MCPV', 'Objc')),\n",
        "  0]]"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}