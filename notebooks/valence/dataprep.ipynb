{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "fabric = LafFabric()\n",
      "from etcbc.preprocess import prepare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.0.3\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('bhs3.txt.hdr', '--', 'dataprep',\n",
      "        {\n",
      "            \"xmlids\": {\n",
      "                \"node\": False,\n",
      "                \"edge\": False,\n",
      "            },\n",
      "            \"features\": {\n",
      "                \"shebanq\": {\n",
      "                    \"node\": [\n",
      "                        \"db.otype\",\n",
      "                        \"ft.surface_consonants\",\n",
      "                        \"ft.phrase_function,locative\",\n",
      "                        \"sft.book,verse_label,verse\",\n",
      "                    ],\n",
      "                    \"edge\": [\n",
      "                    ],\n",
      "                },\n",
      "            },\n",
      "            'prepare': prepare,\n",
      "        },\n",
      "        compile_main=False, compile_annox=False,\n",
      "        verbose='DETAIL',\n",
      "    )\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.11s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.20s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.29s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.78s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.86s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.95s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.63s DETAIL: load main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.84s DETAIL: load main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.96s DETAIL: load main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.15s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.16s DETAIL: load main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.18s DETAIL: load main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.19s LOGFILE=/Users/judith/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.19s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.29s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.81s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Specification of steps ahead\n",
      "\n",
      "1. In the file, find out which of the phrases before :CHANGESTO: has to receive a modified phrase function. This is the target phrase.\n",
      "2. Match the target phrase with a phrase occurrence in the indicated passage in the database.\n",
      "3. Produce an annoting input file, tab separated, 2 columns: the oid of the target phrase, the modified phrase_function.\n",
      "   The name of this column should be shebanq:ft.phrase_function\n",
      "4. Use the module etcbc.annotating (and the method make_form to produce a file of annotations\n",
      "5. put the file of annotations in a new annox (in the annotations directory)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Implementing Flow Charts\n",
      "\n",
      "1. Pick one or two flow charts by Janet.\n",
      "2. translate them in a model.\n",
      "3. Use the model to analyse relevant occurrences of phrases with verbs\n",
      "4. Produce the output of the analysis.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inpassage = False\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() == 'JES 43,19':\n",
      "            inpassage = True\n",
      "        else:\n",
      "            if inpassage == True: break\n",
      "    elif inpassage:\n",
      "        if otype == 'word' or otype == 'phrase':\n",
      "            msg(\"{} ({})\".format(otype, n))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s phrase (737651)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s word (227161)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s phrase (737652)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s word (227162)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s phrase (737653)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s word (227163)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s phrase (737654)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s word (227164)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s phrase (737655)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s word (227165)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s phrase (737656)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.85s word (227166)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s phrase (737657)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227167)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s phrase (737658)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227168)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s phrase (737659)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227169)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s phrase (737660)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227170)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s phrase (737661)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227171)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227173)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227172)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s phrase (737662)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227174)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s phrase (737663)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227175)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227176)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s phrase (737664)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.86s word (227177)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_verse = None\n",
      "cur_phrase = [None, []]\n",
      "phrases = []\n",
      "words = []\n",
      "inpassage = False\n",
      "msg('Look for passage')\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() == 'JES 57,07':\n",
      "            inpassage = True\n",
      "        else:\n",
      "            if inpassage == True: break\n",
      "    elif inpassage:\n",
      "        if otype == 'word':\n",
      "            print('APPEND to {} <{}> : WORD {}'.format(cur_phrase[0], F.phrase_function.v(cur_phrase[0]), F.surface_consonants.v(n)))\n",
      "            cur_phrase[1].append(n)\n",
      "        elif otype == 'phrase':\n",
      "            if cur_phrase[0] != None:\n",
      "                phrases.append(cur_phrase)\n",
      "            cur_phrase = [n, []]\n",
      "if cur_phrase[0] != None:\n",
      "    phrases.append(cur_phrase)\n",
      "\n",
      "msg(\"End walk\")\n",
      "\n",
      "print(' '.join('[{} <{}>]'.format(' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0])) for x in phrases))\n",
      "\n",
      "print(phrases)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s Look for passage\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "APPEND to 740943 <Loca> : WORD <L\n",
        "APPEND to 740943 <Loca> : WORD HR\n",
        "APPEND to 740943 <Loca> : WORD GBH\n",
        "APPEND to 740943 <Loca> : WORD W\n",
        "APPEND to 740943 <Loca> : WORD NF>\n",
        "APPEND to 740944 <Pred> : WORD FMT\n",
        "APPEND to 740945 <Objc> : WORD MCKBK\n",
        "APPEND to 740946 <Modi> : WORD GM\n",
        "APPEND to 740947 <Loca> : WORD CM\n",
        "APPEND to 740948 <Pred> : WORD <LJT\n",
        "APPEND to 740949 <Pred> : WORD L\n",
        "APPEND to 740949 <Pred> : WORD ZBX\n",
        "APPEND to 740950 <Objc> : WORD ZBX\n",
        "[<L HR GBH W NF> <Loca>] [FMT <Pred>] [MCKBK <Objc>] [GM <Modi>] [CM <Loca>] [<LJT <Pred>] [L ZBX <Pred>] [ZBX <Objc>]\n",
        "[[740943, [231588, 231589, 231590, 231591, 231592]], [740944, [231593]], [740945, [231594]], [740946, [231595]], [740947, [231596]], [740948, [231597]], [740949, [231598, 231599]], [740950, [231600]]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = open('CorrectionsFJM.txt')\n",
      "\n",
      "oldlable = re.compile('<([^> ]*)>')\n",
      "changematch = re.compile('') \n",
      "rget = [] \n",
      "targetlist = []\n",
      "\n",
      "for line in handle: \n",
      "    #matches = oldlable.findall(line) \n",
      "    #if matches: \n",
      "        #for match in matches: \n",
      "         #   matchset.add(match) \n",
      "    target = line.split('\\t') \n",
      "    targetlist.append(target)\n",
      "    \n",
      "handle.close()\n",
      "    \n",
      "bad_chars = ']['\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "replacelist = []\n",
      "\n",
      "for element in targetlist: \n",
      "    target = element[-1]\n",
      "    newtarget = rgx.findall(target)\n",
      "    stringtar = ''.join(newtarget)\n",
      "    finaltarget = stringtar.rsplit('<', 1)\n",
      "    needs_to_be_replaced = finaltarget[0]\n",
      "    replacelist.append(needs_to_be_replaced)\n",
      "    \n",
      "targetindex = 0\n",
      "\n",
      "handle = open('CorrectionsFJM.txt')\n",
      "\n",
      "bad_chars = ']['\n",
      "plusw = '\\+$'\n",
      "\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "rgxw = re.compile('[%s]' % plusw)\n",
      "check = 0\n",
      "chunk = collections.defaultdict(list)\n",
      "positions = []\n",
      "\n",
      "for line in handle:\n",
      "    newline = line.split('\\t')\n",
      "    replacement = replacelist[targetindex]\n",
      "    for element in newline:\n",
      "        if rgxw.search(element):\n",
      "            newelement = element.rsplit(' +',1)\n",
      "            correction = ''.join(newelement)\n",
      "            newline = [w.replace(element, correction) for w in newline]\n",
      "        newelement = rgx.findall(element)\n",
      "        finalelement = ''.join(newelement)\n",
      "        result = finalelement.rsplit('<', 1)\n",
      "        if result[0] == replacement and check < 1:\n",
      "            check += 1\n",
      "            #print(result[0])\n",
      "            target = result[0]\n",
      "    checkline = newline[1:-2]\n",
      "    positions.append(newline[0])\n",
      "    checkline = ' '.join(checkline)\n",
      "    chunk[target].append(checkline)\n",
      "    check = 0\n",
      "    targetindex += 1\n",
      "\n",
      "handle.close()\n",
      "\n",
      "chunk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "defaultdict(<class 'list'>, {'B FWM +J ': ['[B FWMJ <PO>] [<NN <..>] [LBCW <..>]'], 'L +W ': ['[W <Cj>] [NFJM <Pr>] [LW <sc>] [CM <Co>] [MVH W CLXN W KS> W MNWRH <Ob>]'], 'MR>CTJ +W ': ['[W <Cj>] [>T KBJR H <ZJM <Ob>] [FMH <Pr>] [MR>CTJW <Co>]'], 'L <D ': ['[W <Cj>] [FMTJ <Pr>] [L <D <Co>] [ZR<W <Ob>]'], 'L >JC +J ': ['[L BLTJ FWM <Pr>] [L >JCJ <sc>] [CM W C>RJT <Ob>] [<L PNJ H >DMH <Co>]'], 'B  <RBH ': ['[>FJM <Pr>] [B  <RBH <Lo>] [BRWC TDHR W T>CWR <Ob>] [JXDW <Mo>]'], '>YL H MZBX ': ['[W <Cj>] [FMW <PO>] [>YL H MZBX <Aj>]'], 'KPJR ': ['[KPJR <Co>] [FMTHW <PO>]'], 'B  MRWM ': ['[L FWM <Pr>] [B  MRWM <Lo>]'], 'SBJB ': ['[W <Cj>] [FMT <Pr>] [>T H XYR <Ob>] [SBJB <Mo>]'], 'K Y>N BYRH ': ['[JXD <Mo>] [>FJMNW <PO>] [K Y>N BYRH <Aj>]'], 'CNJ YBRJM ': ['[FJMW <Pr>] [>TM <Ob>] [CNJ YBRJM <Aj>] [PTX H C<R <Co>] [<D H BQR <Ti>]'], 'L +J ': ['[>T NCP XCQJ <Ob>] [FM <Pr>] [LJ <sc>] [L XRDH <Co>]'], '<L HR GBH W NF> ': ['[<L HR GBH W NF> <Lo>] [FMT <Pr>] [MCKBK <Ob>]'], 'K  MDBR ': ['[W <Cj>] [FMTJH <PO>] [K  MDBR <Aj>]'], 'K  <PR ': ['[W <Cj>] [JFMM <PO>]'], 'L +K ': ['[JFM <Pr>] [JHWH <Su>] [LK <sc>] [ZR< MN H >CH H Z>T <Ob>] [TXT H C>LH <Co>]', '[W <Cj>] [XWYWT <Ob>] [TFJM <Pr>] [LK <sc>]'], 'YPYPH ': ['[YPYPH <Co>] [FMW <PO>]'], 'B  >RY ': ['[<D <Cj>] [JFJM <Pr>] [B  >RY <Lo>] [MCPV <Ob>]'], 'CM ': ['[CM <Lo>] [FM <Pr>] [LW <Co>] [XQ W MCPV <Ob>]', '[W <Cj>] [JFJMW <Pr>] [CM <Mo>] [RJX NJXWXJHM <Ob>]'], 'B  MDBR ': ['[>P <Mo>] [>FJM <Pr>] [B  MDBR <Lo>] [DRK <Ob>]'], '>XR H DLT W H MZWZH ': ['[W <Cj>] [>XR H DLT W H MZWZH <Lo>] [FMT <Pr>] [ZKRWNK <Ob>]'], 'CMMH ': ['[W <Cj>] [KL <YBJH <Ob>] [>FJM <Pr>] [CMMH <Co>]'], 'NPC +W ': ['[>M <Cj>] [TFJM <Pr>] [>CM <Ob>] [NPCW <Su>]'], 'MSPR XYWT JRWCLM ': ['[W <Cj>] [MSPR XYWT JRWCLM <Su>] [FMTM <Pr>] [MZBXWT <Ob>] [L  BCT <Co>]']})"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_verse = None\n",
      "cur_phrase = [None, []]\n",
      "phrases = []\n",
      "words = []\n",
      "inpassage = False\n",
      "msg('Look for passage')\n",
      "\n",
      "count = 1\n",
      "length = len(positions)\n",
      "\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if count < length:\n",
      "            if F.verse_label.v(n).strip() == positions[count]:\n",
      "                inpassage = True\n",
      "                count += 1\n",
      "            else:\n",
      "               inpassage = False\n",
      "    elif inpassage:\n",
      "        if otype == 'word':\n",
      "            cur_phrase[1].append(n)\n",
      "        elif otype == 'phrase':\n",
      "            if cur_phrase[0] != None:\n",
      "                phrases.append(cur_phrase)\n",
      "            cur_phrase = [n, []]\n",
      "\n",
      "\n",
      "print(' '.join('[{} <{}>]'.format(' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0])) for x in phrases))\n",
      "     \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 3m 57s Look for passage\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}