{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "fabric = LafFabric()\n",
      "from etcbc.preprocess import prepare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.0.3\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('bhs3.txt.hdr', '--', 'dataprep',\n",
      "        {\n",
      "            \"xmlids\": {\n",
      "                \"node\": False,\n",
      "                \"edge\": False,\n",
      "            },\n",
      "            \"features\": {\n",
      "                \"shebanq\": {\n",
      "                    \"node\": [\n",
      "                        \"db.otype\",\n",
      "                        \"ft.surface_consonants\",\n",
      "                        \"ft.phrase_function,locative\",\n",
      "                        \"sft.book,verse_label\",\n",
      "                    ],\n",
      "                    \"edge\": [\n",
      "                    ],\n",
      "                },\n",
      "            },\n",
      "            'prepare': prepare,\n",
      "        },\n",
      "        compile_main=False, compile_annox=False,\n",
      "        verbose='DETAIL',\n",
      "    )\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.12s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.21s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.30s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.79s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.88s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.97s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.63s DETAIL: load main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.83s DETAIL: load main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.95s DETAIL: load main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.15s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.16s DETAIL: load main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.18s LOGFILE=/Users/judith/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.18s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.28s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.79s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pf_map = {\n",
      "    '': 'Unkn',\n",
      "    'Pr': 'Pred',\n",
      "    'Cj': 'Conj',\n",
      "    'Co': 'Cmpl',\n",
      "    'Su': 'Subj',\n",
      "    'Ob': 'Objc',\n",
      "    'PC': 'PreC',\n",
      "    'Aj': 'Adju',\n",
      "    'PO': 'PreO',\n",
      "    'Re': 'Rela',\n",
      "    'Ng': 'Nega',\n",
      "    'Mo': 'Modi',\n",
      "    'Ti': 'Time',\n",
      "    'Lo': 'Loca',\n",
      "    'Ij': 'Intj',\n",
      "    'Qu': 'Ques',\n",
      "    'Vo': 'Voct',\n",
      "    'Fr': 'Frnt',\n",
      "    'Ps': 'PreS',\n",
      "    'sc': 'Supp',\n",
      "    'Qs': 'IrpS',\n",
      "    'Is': 'IntS',\n",
      "    'Qp': 'IrpP',\n",
      "    'Qo': 'IrpO',\n",
      "    'po': 'PtcO',\n",
      "    'Ex': 'Exst',\n",
      "    'Ns': 'NegS',\n",
      "    'Ms': 'ModS',\n",
      "    'Qc': 'IrpC',\n",
      "    'Es': 'ExsS',\n",
      "    'ps': 'PtSp',\n",
      "}\n",
      "\n",
      "pf_map\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "{'': 'Unkn',\n",
        " 'Aj': 'Adju',\n",
        " 'Cj': 'Conj',\n",
        " 'Co': 'Cmpl',\n",
        " 'Es': 'ExsS',\n",
        " 'Ex': 'Exst',\n",
        " 'Fr': 'Frnt',\n",
        " 'Ij': 'Intj',\n",
        " 'Is': 'IntS',\n",
        " 'Lo': 'Loca',\n",
        " 'Mo': 'Modi',\n",
        " 'Ms': 'ModS',\n",
        " 'Ng': 'Nega',\n",
        " 'Ns': 'NegS',\n",
        " 'Ob': 'Objc',\n",
        " 'PC': 'PreC',\n",
        " 'PO': 'PreO',\n",
        " 'Pr': 'Pred',\n",
        " 'Ps': 'PreS',\n",
        " 'Qc': 'IrpC',\n",
        " 'Qo': 'IrpO',\n",
        " 'Qp': 'IrpP',\n",
        " 'Qs': 'IrpS',\n",
        " 'Qu': 'Ques',\n",
        " 'Re': 'Rela',\n",
        " 'Su': 'Subj',\n",
        " 'Ti': 'Time',\n",
        " 'Vo': 'Voct',\n",
        " 'po': 'PtcO',\n",
        " 'ps': 'PtSp',\n",
        " 'sc': 'Supp'}"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = infile('CorrectionsFJM.txt')\n",
      "\n",
      "oldlable = re.compile('<([^> ]*)>')\n",
      "changematch = re.compile('') \n",
      "rget = [] \n",
      "targetlist = []\n",
      "\n",
      "for line in handle: \n",
      "    #matches = oldlable.findall(line) \n",
      "    #if matches: \n",
      "        #for match in matches: \n",
      "         #   matchset.add(match) \n",
      "    target = line.split('\\t') \n",
      "    targetlist.append(target)\n",
      "    \n",
      "\n",
      "    \n",
      "bad_chars = ']['\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "replacelist = []\n",
      "\n",
      "for element in targetlist: \n",
      "    target = element[-1]\n",
      "    newtarget = rgx.findall(target)\n",
      "    stringtar = ''.join(newtarget)\n",
      "    finaltarget = stringtar.rsplit('<', 1)\n",
      "    needs_to_be_replaced = finaltarget[0]\n",
      "    replacelist.append(needs_to_be_replaced)\n",
      "    \n",
      "targetindex = 0\n",
      "\n",
      "handle = infile('CorrectionsFJM.txt')\n",
      "\n",
      "bad_chars = ']['\n",
      "plusw = '\\+$'\n",
      "\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "rgxw = re.compile('[%s]' % plusw)\n",
      "check = 0\n",
      "chunk = collections.defaultdict(list)\n",
      "positions = []\n",
      "\n",
      "for line in handle:\n",
      "    newline = line.split('\\t')\n",
      "    replacement = replacelist[targetindex]\n",
      "    for element in newline:\n",
      "        if rgxw.search(element):\n",
      "            newelement = element.rsplit(' +',1)\n",
      "            correction = ''.join(newelement)\n",
      "            newline = [w.replace(element, correction) for w in newline]\n",
      "        newelement = rgx.findall(element)\n",
      "        finalelement = ''.join(newelement)\n",
      "        result = finalelement.rsplit('<', 1)\n",
      "        if result[0] == replacement and check < 1:\n",
      "            check += 1\n",
      "            #print(result[0])\n",
      "            target = result[0]\n",
      "    checkline = newline[1:-2]\n",
      "    checkline = ' '.join(checkline)\n",
      "    positions.append(checkline[0])\n",
      "    chunk[target].append(checkline)\n",
      "    check = 0\n",
      "    targetindex += 1\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "   \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "            \n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Specification of steps ahead\n",
      "\n",
      "1. In the file, find out which of the phrases before :CHANGESTO: has to receive a modified phrase function. This is the target phrase.\n",
      "2. Match the target phrase with a phrase occurrence in the indicated passage in the database.\n",
      "3. Produce an annoting input file, tab separated, 2 columns: the oid of the target phrase, the modified phrase_function.\n",
      "   The name of this column should be shebanq:ft.phrase_function\n",
      "4. Use the module etcbc.annotating (and the method make_form to produce a file of annotations\n",
      "5. put the file of annotations in a new annox (in the annotations directory)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Implementing Flow Charts\n",
      "\n",
      "1. Pick one or two flow charts by Janet.\n",
      "2. translate them in a model.\n",
      "3. Use the model to analyse relevant occurrences of phrases with verbs\n",
      "4. Produce the output of the analysis.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "inpassage = False\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() == 'JES 43,19':\n",
      "            inpassage = True\n",
      "        else:\n",
      "            if inpassage == True: break\n",
      "    elif inpassage:\n",
      "        if otype == 'word' or otype == 'phrase':\n",
      "            msg(\"{} ({})\".format(otype, n))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737651)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227161)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737652)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227162)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737653)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227163)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737654)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227164)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737655)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227165)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737656)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227166)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737657)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227167)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737658)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227168)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737659)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227169)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737660)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227170)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737661)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227171)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227173)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227172)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737662)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227174)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737663)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227175)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227176)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s phrase (737664)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s word (227177)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_verse = None\n",
      "cur_phrase = [None, []]\n",
      "phrases = []\n",
      "words = []\n",
      "inpassage = False\n",
      "msg('Look for passage')\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() == 'JES 57,07':\n",
      "            inpassage = True\n",
      "        else:\n",
      "            if inpassage == True: break\n",
      "    elif inpassage:\n",
      "        if otype == 'word':\n",
      "            print('APPEND to {} <{}> : WORD {}'.format(cur_phrase[0], F.phrase_function.v(cur_phrase[0]), F.surface_consonants.v(n)))\n",
      "            cur_phrase[1].append(n)\n",
      "        elif otype == 'phrase':\n",
      "            if cur_phrase[0] != None:\n",
      "                phrases.append(cur_phrase)\n",
      "            cur_phrase = [n, []]\n",
      "if cur_phrase[0] != None:\n",
      "    phrases.append(cur_phrase)\n",
      "\n",
      "msg(\"End walk\")\n",
      "\n",
      "print(' '.join('[{} <{}>]'.format(' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0])) for x in phrases))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s Look for passage\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    20s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "APPEND to 740943 <Loca> : WORD <L\n",
        "APPEND to 740943 <Loca> : WORD HR\n",
        "APPEND to 740943 <Loca> : WORD GBH\n",
        "APPEND to 740943 <Loca> : WORD W\n",
        "APPEND to 740943 <Loca> : WORD NF>\n",
        "APPEND to 740944 <Pred> : WORD FMT\n",
        "APPEND to 740945 <Objc> : WORD MCKBK\n",
        "APPEND to 740946 <Modi> : WORD GM\n",
        "APPEND to 740947 <Loca> : WORD CM\n",
        "APPEND to 740948 <Pred> : WORD <LJT\n",
        "APPEND to 740949 <Pred> : WORD L\n",
        "APPEND to 740949 <Pred> : WORD ZBX\n",
        "APPEND to 740950 <Objc> : WORD ZBX\n",
        "[<L HR GBH W NF> <Loca>] [FMT <Pred>] [MCKBK <Objc>] [GM <Modi>] [CM <Loca>] [<LJT <Pred>] [L ZBX <Pred>] [ZBX <Objc>]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = infile('CorrectionsFJM.txt')\n",
      "\n",
      "oldlable = re.compile('<([^> ]*)>')\n",
      "changematch = re.compile('') \n",
      "rget = [] \n",
      "targetlist = []\n",
      "\n",
      "for line in handle: \n",
      "    #matches = oldlable.findall(line) \n",
      "    #if matches: \n",
      "        #for match in matches: \n",
      "         #   matchset.add(match) \n",
      "    target = line.split('\\t') \n",
      "    targetlist.append(target)\n",
      "    \n",
      "\n",
      "    \n",
      "bad_chars = ']['\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "replacelist = []\n",
      "\n",
      "for element in targetlist: \n",
      "    target = element[-1]\n",
      "    newtarget = rgx.findall(target)\n",
      "    stringtar = ''.join(newtarget)\n",
      "    finaltarget = stringtar.rsplit('<', 1)\n",
      "    needs_to_be_replaced = finaltarget[0]\n",
      "    replacelist.append(needs_to_be_replaced)\n",
      "    \n",
      "targetindex = 0\n",
      "\n",
      "handle = infile('CorrectionsFJM.txt')\n",
      "\n",
      "bad_chars = ']['\n",
      "plusw = '\\+$'\n",
      "\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "rgxw = re.compile('[%s]' % plusw)\n",
      "check = 0\n",
      "chunk = collections.defaultdict(list)\n",
      "positions = []\n",
      "\n",
      "for line in handle:\n",
      "    newline = line.split('\\t')\n",
      "    replacement = replacelist[targetindex]\n",
      "    for element in newline:\n",
      "        if rgxw.search(element):\n",
      "            newelement = element.rsplit(' +',1)\n",
      "            correction = ''.join(newelement)\n",
      "            newline = [w.replace(element, correction) for w in newline]\n",
      "        newelement = rgx.findall(element)\n",
      "        finalelement = ''.join(newelement)\n",
      "        result = finalelement.rsplit('<', 1)\n",
      "        if result[0] == replacement and check < 1:\n",
      "            check += 1\n",
      "            #print(result[0])\n",
      "            target = result[0]\n",
      "    checkline = newline[1:-2]\n",
      "    positions.append(newline[0])\n",
      "    checkline = ' '.join(checkline)\n",
      "    chunk[target].append(checkline)\n",
      "    check = 0\n",
      "    targetindex += 1\n",
      "    \n",
      "positions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['\\ufeffEXO 15,25',\n",
        " 'EXO 40,08',\n",
        " 'LEV 06,03',\n",
        " 'JES 41,19',\n",
        " 'JES 42,04',\n",
        " 'JES 43,19',\n",
        " 'JES 57,07',\n",
        " 'JES 57,08',\n",
        " 'EZE 20,28',\n",
        " 'HAB 02,09',\n",
        " 'PS081,006',\n",
        " 'ISAM 02,20',\n",
        " 'IISA 14,07',\n",
        " 'IKON08,21',\n",
        " 'IKON20,34',\n",
        " 'IIKON04,10',\n",
        " 'JES 21,04',\n",
        " 'ISAM 19,13',\n",
        " 'IIKON10,08',\n",
        " 'IIKON13,07',\n",
        " 'JES 53,10',\n",
        " 'JER 11,13',\n",
        " 'EZE 17,05',\n",
        " 'EZE 19,05',\n",
        " 'HOS 02,05',\n",
        " 'MICH01,07',\n",
        " 'MICH02,12',\n",
        " 'IKON20,34',\n",
        " 'JES 28,25',\n",
        " 'IOB 24,15',\n",
        " 'PS089,030',\n",
        " 'IOB 34,13',\n",
        " 'IOB 38,09',\n",
        " '*ICHR17,21',\n",
        " '*JES 25,02',\n",
        " '*JES 60,15']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_verse = None\n",
      "cur_phrase = [None, []]\n",
      "phrases = []\n",
      "words = []\n",
      "inpassage = False\n",
      "\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() in positions:\n",
      "            inpassage = True\n",
      "        else:\n",
      "            inpassage = False\n",
      "    elif inpassage:\n",
      "        if otype == 'word':\n",
      "            cur_phrase[1].append(n)\n",
      "        elif otype == 'phrase':\n",
      "            if cur_phrase[0] != None:\n",
      "                phrases.append(cur_phrase)\n",
      "            cur_phrase = [n, []]\n",
      "    \n",
      "if cur_phrase[0] != None:\n",
      "    phrases.append(cur_phrase)\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[815744, [345453]]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}