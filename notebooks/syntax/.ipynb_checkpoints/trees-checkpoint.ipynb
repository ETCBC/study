{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img src=\"files/images/laf-fabric-small.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img src=\"files/images/DANS-small.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img src=\"files/images/TLA-small.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img src=\"files/images/VU-ETCBC-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Trees - the smooth path"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We show the embedding of nodes annotated as sentences, clauses, phrases, subphrases and words.\n",
      "We put them in a format (eventually) such that they can be read by TGREP.\n",
      "Then Rens Bod and Andreas van Cranenburgh can do interesting business with it.\n",
      "\n",
      "Method\n",
      "======\n",
      "\n",
      "We walk through all words and follow them upwards, along parents edges until there are no more outgoing edges.\n",
      "We then have the starting points for our sentences.\n",
      "\n",
      "We walk through the starting points, and for each starting point we assemble the tree hanging off that point.\n",
      "This we do by walking the parents edges in the opposite direction.\n",
      "\n",
      "We use the monad numbers (word numbers) to maintain word order.\n",
      "\n",
      "* parents links from words to phrases to clauses to sentences\n",
      "* word numbers\n",
      "\n",
      "More details will follow below, when we deal with them."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Starting LAF-Fabric"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "import laf\n",
      "from laf.notebook import Notebook\n",
      "processor = Notebook()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "This is LAF-Fabric 3.6.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Declaring the features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use the features in our data source for establishing the trees.\n",
      "This is what we need:\n",
      "\n",
      "db.otype\n",
      "--------\n",
      "The type of a node: word, phrase, sentence, etc\n",
      "\n",
      "parents\n",
      "-------\n",
      "This is a feature by which we can identify the edges that correspond to the *parents* relationship.\n",
      "*parents* goes from lower level to higher level (word => ... => sentence).\n",
      "\n",
      "**N.B.** There are two linguistic hierarchies interwoven in this database.\n",
      "Sometimes nodes have more than one parent!\n",
      "\n",
      "db.monads, minmonad, maxmonad\n",
      "-----------------------------\n",
      "Every word has a *monad* number, it is the sequence number of the word in the complete Hebrew text.\n",
      "Every object (sentence, phrase, word, etc) knows exactly which monads belong to it.\n",
      "For convenience, there are features to get the minimal and maximal monad numbers per object.\n",
      "(Objects may have gaps).\n",
      "\n",
      "It might not be obvious why we need *minmonad* and *maxmonad*.\n",
      "It is this: when we find the children of node (along the *parents* edges),\n",
      "we do not get the order of them.\n",
      "So we have to order them ourselves.\n",
      "That's the only reason for *minmonad* and *maxmonad*.\n",
      "See later on.\n",
      "\n",
      "ft.text_plain\n",
      "-------------\n",
      "The unvocalized text of a word.\n",
      "\n",
      "ft.part_of_speech\n",
      "-----------------\n",
      "The part of speech of a word.\n",
      "\n",
      "sft.verse-label\n",
      "---------------\n",
      "Passage information: book, chapter, verse all in one feature.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.init('bhs3.txt.hdr', '--', 'trees', {\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype,monads,minmonad,maxmonad\",\n",
      "                \"ft.text_plain,part_of_speech\",\n",
      "                \"ft.clause_constituent_relation,phrase_type\",\n",
      "                \"sft.verse_label\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "                \"parents.\",\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "})\n",
      "\n",
      "API = processor.API()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING source: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING annox: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING DATA: please wait ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s LOADING DATA: DONE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOGFILE=/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/trees/__log__trees.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN TASK=trees SOURCE=bhs3.txt.hdr\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s LOADING API: DONE\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we define the formatting of the trees.\n",
      "\n",
      "Relevant nodes\n",
      "--------------\n",
      "Not all nodes will be shown in the output.\n",
      "The nodes that are shown, have abbreviated names.\n",
      "Nodes with ``True`` will be shown, nodes with ``False`` will be suppressed.\n",
      "\n",
      "Suppressing a node leaves its children in place. Another way of looking at it, is: we replace a node by its children.\n",
      "\n",
      "Exception: when a node is visited twice, the second visit refers to the tree built by the first visit.\n",
      "In that case, we do not suppress the node.\n",
      "\n",
      "**N.B.** It turns out that the ``-atom`` nodes are never visited twice.\n",
      "\n",
      "pos_table\n",
      "---------\n",
      "We abbreviate the part-of-speech tags. \n",
      "We include the pos-info by inserting a unary node right above each word."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "F = API['F']\n",
      "NN = API['NN']\n",
      "C = API['C']\n",
      "Ci = API['Ci']\n",
      "msg = API['msg']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "\n",
      "relevant_nodes = [\n",
      "    (\"word\", '', True),\n",
      "    (\"subphrase\", 'SU', True),\n",
      "    (\"phrase_atom\", 'Pa', False),\n",
      "    (\"phrase\", 'P', True),\n",
      "    (\"clause_atom\", 'Ca', False),\n",
      "    (\"clause\", 'C', True),\n",
      "    (\"sentence_atom\", 'Sa', False),\n",
      "    (\"sentence\", 'S', True),\n",
      "]\n",
      "\n",
      "pos_table = {\n",
      " 'adjective': 'aj',\n",
      " 'adverb': 'av',\n",
      " 'article': 'dt',\n",
      " 'conjunction': 'cj',\n",
      " 'interjection': 'ij',\n",
      " 'interrogative': 'ir',\n",
      " 'negative': 'ng',\n",
      " 'noun': 'n',\n",
      " 'preposition': 'pp',\n",
      " 'pronoun': 'pr',\n",
      " 'verb': 'vb',\n",
      "}\n",
      "\n",
      "select_node = set()\n",
      "select_tag = collections.defaultdict(lambda: None)\n",
      "abbrev_node = collections.defaultdict(lambda: None)\n",
      "\n",
      "for (otype, abb, relevant) in relevant_nodes:\n",
      "    if relevant:\n",
      "        select_node.add(abb)\n",
      "    abbrev_node[otype] = abb if abb != None else otype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Currently it is not clear to mehow to use the *mother* edges for the syntax trees.\n",
      "\n",
      "The *phrases* are a bit undifferentiated, and the clauses to.\n",
      "\n",
      "We could add the *clause_constituent_relation* to the syntax trees, and also the *phrase_type* and *phrase_function*.\n",
      "\n",
      "The *clause_constituent_relation* is explored in the notebook *clause_constituent_relation.ipynb*, and the phrase features in the notebook *phrase_typology*."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Find the top nodes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We walk through the words.\n",
      "From each word we walk along the parent edges until we cannot get further.\n",
      "All end points are top nodes. \n",
      "We put the end nodes in a set.\n",
      "We join all sets of end nodes that we have found above each word.\n",
      "\n",
      "**N.B.** In this way we encounter the top nodes many times, but it does not matter,\n",
      "because we put them all in a set, without duplicates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_nodes = set()\n",
      "top_node_types = collections.defaultdict(lambda: 0)\n",
      "top_nodes = C.shebanq_parents__T('', set(NN(test=F.shebanq_db_otype.v, value='word')))\n",
      "\n",
      "msg(\"Top nodes found: {}\".format(len(top_nodes)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    20s Sort order of nodes back to original\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    21s Top nodes found: 71354\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Checking"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us see what the types are of all the top nodes we have found.\n",
      "\n",
      "We would like to see that they are all sentences.\n",
      "\n",
      "And are all sentences top nodes?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_node_types = collections.defaultdict(lambda: 0)\n",
      "\n",
      "for node in NN(test=lambda n: n in top_nodes, value=True):\n",
      "    tag = abbrev_node[F.shebanq_db_otype.v(node)]\n",
      "    top_node_types[tag] += 1\n",
      "\n",
      "for (otype, tag, relevant) in relevant_nodes:\n",
      "    if top_node_types[tag]:\n",
      "        msg(\"{:<2} {} x at the top\".format(tag, top_node_types[tag]))\n",
      "\n",
      "nt = 0        \n",
      "msg(\"Non top nodes of type S:\")\n",
      "for node in NN():\n",
      "    parents = C.shebanq_parents_[''][node]\n",
      "    if parents and F.shebanq_db_otype.v(node) == 'sentence':\n",
      "        msg(\"{} \".format(node), newline=False, withtime=False)\n",
      "        nt += 1\n",
      "msg(\"Non top nodes of type S found: {}\".format(nt))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    27s S  71354 x at the top\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    27s Non top nodes of type S:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    28s Non top nodes of type S found: 0\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Serializing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For each top node, we serialize its tree along the inverse parents edges.\n",
      "There are confluences, meaning that sometimes one node has two parents.\n",
      "We detect that, and the second time we reach a node, we output a token that references to the tree we constructed in the first visit to that node.\n",
      "\n",
      "We cannot write the string immediately, because after tree creation we want to renumber referenced trees and word occurrences.\n",
      "\n",
      "Output format\n",
      "-------------\n",
      "We output the trees in the order as their texts occur in the Hebrew bible.\n",
      "The output is a text file, and every line corresponds to a exactly one tree.\n",
      "\n",
      "Every line has three tab-separated fields.\n",
      "\n",
      "* passage label\n",
      "* tree structure with placeholders for the words\n",
      "* word sequence (linking words to place holders). This sequence corresponds to the order as found in the text."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees = outfile(\"trees.txt\")\n",
      "\n",
      "nodes_seen = set()\n",
      "words = []\n",
      "sequential = []\n",
      "\n",
      "def write_tree(node):\n",
      "    \n",
      "    if node in nodes_seen:\n",
      "        return\n",
      "    \n",
      "    nodes_seen.add(node)\n",
      "\n",
      "    otype = F.shebanq_db_otype.v(node)\n",
      "    tag = abbrev_node[otype]\n",
      "    relevant = tag in select_node\n",
      "\n",
      "    if tag == 'C':\n",
      "        crr = F.shebanq_ft_clause_constituent_relation.v(node)\n",
      "        if crr != 'none':\n",
      "            tag = crr\n",
      "    elif tag == 'P':\n",
      "        tag = F.shebanq_ft_phrase_type.v(node)\n",
      "    is_word = otype == 'word'\n",
      "    if is_word:\n",
      "        text = F.shebanq_ft_text_plain.v(node)\n",
      "        pos = pos_table[F.shebanq_ft_part_of_speech.v(node)]\n",
      "        monad = int(F.shebanq_db_monads.v(node))\n",
      "        sequential.append((\"W\", len(words)))\n",
      "        words.append((monad, text, pos))\n",
      "    else:\n",
      "        sequential.append((\"O\" if relevant else \"N\", tag))\n",
      "    \n",
      "    children = sorted(\n",
      "        Ci.shebanq_parents_[''][node],\n",
      "        key=lambda n: (int(F.shebanq_db_minmonad.v(n)), -int(F.shebanq_db_maxmonad.v(n)))\n",
      "    )\n",
      "    for child in children:\n",
      "        write_tree(child)\n",
      "    \n",
      "    if not is_word:\n",
      "        sequential.append((\"C\" if relevant else \"N\", tag))\n",
      "\n",
      "def do_sequential():\n",
      "    word_perm = {}\n",
      "    new_words = sorted(enumerate(words), key=lambda x: x[1][0])\n",
      "    word_rep = ''\n",
      "    for (nn, (on, (monad, text, pos))) in enumerate(new_words):\n",
      "        word_perm[on] = nn\n",
      "        word_rep += '{} '.format(text)\n",
      "                    \n",
      "    for (code, info) in sequential:\n",
      "        if code == 'O' or code == 'C':\n",
      "            if code == 'O':\n",
      "                trees.write('({}'.format(info))\n",
      "            else:\n",
      "                trees.write(')')\n",
      "        elif code == 'W':\n",
      "            nn = word_perm[info]\n",
      "            pos = words[info][2]\n",
      "            trees.write('({} {})'.format(pos, nn))\n",
      "    \n",
      "    trees.write(\"\\t{}\".format(word_rep))\n",
      "    \n",
      "msg(\"Writing trees ...\")\n",
      "verse_label = ''\n",
      "\n",
      "s = 0\n",
      "chunk = 10000\n",
      "sc = 0\n",
      "\n",
      "for node in NN(test=lambda n: n in top_nodes or F.shebanq_db_otype.v(n) == 'verse', value=True):\n",
      "    if F.shebanq_db_otype.v(node) == 'verse':\n",
      "        verse_label = F.shebanq_sft_verse_label.v(node)\n",
      "        continue\n",
      "    nodes_seen = set()\n",
      "    sequential = []\n",
      "    words = []\n",
      "    write_tree(node)\n",
      "    do_sequential()\n",
      "    trees.write(\"\\t{}\\n\".format(verse_label))\n",
      "    s += 1\n",
      "    sc += 1\n",
      "    if sc == chunk:\n",
      "        msg(\"{} trees written\".format(s))\n",
      "        sc = 0\n",
      "#    break\n",
      "    \n",
      "msg(\"{} trees written\".format(s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    42s Writing trees ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    45s 10000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    50s 20000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    52s 30000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s 40000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    57s 50000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    59s 60000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 01s 70000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 02s 71354 trees written\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.final()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 05s END TASK trees\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 05s Results directory:\n",
        "/Users/dirk/Scratch/laf-fabric-data/bhs3.txt.hdr/trees\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        ".DS_Store                              6148 Mon Feb 17 17:17:09 2014\n",
        ".trees.txt.swp                        90112 Thu Mar  6 14:34:15 2014\n",
        "__log__trees.txt                        650 Thu Mar  6 19:06:32 2014\n",
        "anomalies.txt                         16798 Fri Feb 21 17:51:22 2014\n",
        "anomalies2014-01-28.txt               13849 Tue Jan 28 21:40:04 2014\n",
        "trees.txt                           8381583 Thu Mar  6 19:06:32 2014\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are the first lines of the output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 25 {my_file('trees.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(S(C(PP(pp 0)(n 1))(VP(vb 2))(NP(n 3))(PP(SU(pp 4)(dt 5)(n 6))(cj 7)(SU(pp 8)(dt 9)(n 10)))))\t\u05d1 \u05e8\u05d0\u05e9\u05c1\u05d9\u05ea \u05d1\u05e8\u05d0 \u05d0\u05dc\u05d4\u05d9\u05dd \u05d0\u05ea \u05d4 \u05e9\u05c1\u05de\u05d9\u05dd \u05d5 \u05d0\u05ea \u05d4 \u05d0\u05e8\u05e5 \t GEN 01,01\r\n",
        "(S(C(CP(cj 0))(NP(dt 1)(n 2))(VP(vb 3))(NP(SU(n 4))(cj 5)(SU(n 6)))))\t\u05d5 \u05d4 \u05d0\u05e8\u05e5 \u05d4\u05d9\u05ea\u05d4 \u05ea\u05d4\u05d5 \u05d5 \u05d1\u05d4\u05d5 \t GEN 01,02\r\n",
        "(S(C(CP(cj 0))(NP(n 1))(PP(pp 2)(SU(n 3))(SU(n 4)))))\t\u05d5 \u05d7\u05e9\u05c1\u05da \u05e2\u05dc \u05e4\u05e0\u05d9 \u05ea\u05d4\u05d5\u05dd \t GEN 01,02\r\n",
        "(S(C(CP(cj 0))(NP(SU(n 1))(SU(n 2)))(VP(vb 3))(PP(pp 4)(SU(n 5))(SU(dt 6)(n 7)))))\t\u05d5 \u05e8\u05d5\u05d7 \u05d0\u05dc\u05d4\u05d9\u05dd \u05de\u05e8\u05d7\u05e4\u05ea \u05e2\u05dc \u05e4\u05e0\u05d9 \u05d4 \u05de\u05d9\u05dd \t GEN 01,02\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))))\t\u05d5 \u05d9\u05d0\u05de\u05e8 \u05d0\u05dc\u05d4\u05d9\u05dd \t GEN 01,03\r\n",
        "(S(C(VP(vb 0))(NP(n 1))))\t\u05d9\u05d4\u05d9 \u05d0\u05d5\u05e8 \t GEN 01,03\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))))\t\u05d5 \u05d9\u05d4\u05d9 \u05d0\u05d5\u05e8 \t GEN 01,03\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))(PP(pp 3)(dt 4)(n 5)))(Objc(CP(cj 6))(VP(vb 7))))\t\u05d5 \u05d9\u05e8\u05d0 \u05d0\u05dc\u05d4\u05d9\u05dd \u05d0\u05ea \u05d4 \u05d0\u05d5\u05e8 \u05db\u05d9 \u05d8\u05d5\u05d1 \t GEN 01,04\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))(PP(SU(n 3)(dt 4)(n 5))(cj 6)(SU(n 7)(dt 8)(n 9)))))\t\u05d5 \u05d9\u05d1\u05d3\u05dc \u05d0\u05dc\u05d4\u05d9\u05dd \u05d1\u05d9\u05df \u05d4 \u05d0\u05d5\u05e8 \u05d5 \u05d1\u05d9\u05df \u05d4 \u05d7\u05e9\u05c1\u05da \t GEN 01,04\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))(PP(pp 3)(dt 4)(n 5))(NP(n 6))))\t\u05d5 \u05d9\u05e7\u05e8\u05d0 \u05d0\u05dc\u05d4\u05d9\u05dd \u05dc  \u05d0\u05d5\u05e8 \u05d9\u05d5\u05dd \t GEN 01,05\r\n",
        "(S(C(CP(cj 0))(PP(pp 1)(dt 2)(n 3))(VP(vb 4))(NP(n 5))))\t\u05d5 \u05dc  \u05d7\u05e9\u05c1\u05da \u05e7\u05e8\u05d0 \u05dc\u05d9\u05dc\u05d4 \t GEN 01,05\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))))\t\u05d5 \u05d9\u05d4\u05d9 \u05e2\u05e8\u05d1 \t GEN 01,05\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))))\t\u05d5 \u05d9\u05d4\u05d9 \u05d1\u05e7\u05e8 \t GEN 01,05\r\n",
        "(S(C(NP(SU(n 0))(SU(n 1)))))\t\u05d9\u05d5\u05dd \u05d0\u05d7\u05d3 \t GEN 01,05\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))))\t\u05d5 \u05d9\u05d0\u05de\u05e8 \u05d0\u05dc\u05d4\u05d9\u05dd \t GEN 01,06\r\n",
        "(S(C(VP(vb 0))(NP(n 1))(PP(pp 2)(SU(n 3))(SU(dt 4)(n 5)))))\t\u05d9\u05d4\u05d9 \u05e8\u05e7\u05d9\u05e2 \u05d1 \u05ea\u05d5\u05da \u05d4 \u05de\u05d9\u05dd \t GEN 01,06\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(VP(vb 2))(PP(n 3)(n 4)(pp 5)(n 6))))\t\u05d5 \u05d9\u05d4\u05d9 \u05de\u05d1\u05d3\u05d9\u05dc \u05d1\u05d9\u05df \u05de\u05d9\u05dd \u05dc \u05de\u05d9\u05dd \t GEN 01,06\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))(PP(pp 3)(dt 4)(n 5))))\t\u05d5 \u05d9\u05e2\u05e9\u05c2 \u05d0\u05dc\u05d4\u05d9\u05dd \u05d0\u05ea \u05d4 \u05e8\u05e7\u05d9\u05e2 \t GEN 01,07\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(PP(n 2)(dt 3)(n 4))(CP(cj 11))(PP(n 12)(dt 13)(n 14)))(Attr(CP(cj 5))(PP(pp 6)(n 7)(pp 8)(dt 9)(n 10)))(Attr(CP(cj 15))(PP(pp 16)(pp 17)(pp 18)(dt 19)(n 20))))\t\u05d5 \u05d9\u05d1\u05d3\u05dc \u05d1\u05d9\u05df \u05d4 \u05de\u05d9\u05dd \u05d0\u05e9\u05c1\u05e8 \u05de \u05ea\u05d7\u05ea \u05dc  \u05e8\u05e7\u05d9\u05e2 \u05d5 \u05d1\u05d9\u05df \u05d4 \u05de\u05d9\u05dd \u05d0\u05e9\u05c1\u05e8 \u05de \u05e2\u05dc \u05dc  \u05e8\u05e7\u05d9\u05e2 \t GEN 01,07\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(AdvP(av 2))))\t\u05d5 \u05d9\u05d4\u05d9 \u05db\u05df \t GEN 01,07\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))(PP(pp 3)(dt 4)(n 5))(NP(n 6))))\t\u05d5 \u05d9\u05e7\u05e8\u05d0 \u05d0\u05dc\u05d4\u05d9\u05dd \u05dc  \u05e8\u05e7\u05d9\u05e2 \u05e9\u05c1\u05de\u05d9\u05dd \t GEN 01,08\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))))\t\u05d5 \u05d9\u05d4\u05d9 \u05e2\u05e8\u05d1 \t GEN 01,08\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))))\t\u05d5 \u05d9\u05d4\u05d9 \u05d1\u05e7\u05e8 \t GEN 01,08\r\n",
        "(S(C(NP(SU(n 0))(SU(aj 1)))))\t\u05d9\u05d5\u05dd \u05e9\u05c1\u05e0\u05d9 \t GEN 01,08\r\n",
        "(S(C(CP(cj 0))(VP(vb 1))(NP(n 2))))\t\u05d5 \u05d9\u05d0\u05de\u05e8 \u05d0\u05dc\u05d4\u05d9\u05dd \t GEN 01,09\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}