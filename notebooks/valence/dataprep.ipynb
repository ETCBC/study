{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "fabric = LafFabric()\n",
      "from etcbc.preprocess import prepare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.0.3\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('bhs3.txt.hdr', '--', 'dataprep',\n",
      "        {\n",
      "            \"xmlids\": {\n",
      "                \"node\": False,\n",
      "                \"edge\": False,\n",
      "            },\n",
      "            \"features\": {\n",
      "                \"shebanq\": {\n",
      "                    \"node\": [\n",
      "                        \"db.otype\",\n",
      "                        \"ft.surface_consonants\",\n",
      "                        \"ft.phrase_function,locative\",\n",
      "                        \"sft.book,verse_label\",\n",
      "                    ],\n",
      "                    \"edge\": [\n",
      "                    ],\n",
      "                },\n",
      "            },\n",
      "            'prepare': prepare,\n",
      "        },\n",
      "        compile_main=False, compile_annox=False,\n",
      "        verbose='DETAIL',\n",
      "    )\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.11s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.21s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.30s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.78s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.86s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.95s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.64s DETAIL: load main: F.shebanq_ft_surface_consonants [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.86s DETAIL: load main: F.shebanq_ft_phrase_function [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.98s DETAIL: load main: F.shebanq_ft_locative [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.18s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.20s DETAIL: load main: F.shebanq_sft_verse_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.22s LOGFILE=/Users/judith/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/dataprep/__log__dataprep.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.22s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.32s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.85s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dataprep\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pf_map = {\n",
      "    '': 'Unkn',\n",
      "    'Pr': 'Pred',\n",
      "    'Cj': 'Conj',\n",
      "    'Co': 'Cmpl',\n",
      "    'Su': 'Subj',\n",
      "    'Ob': 'Objc',\n",
      "    'PC': 'PreC',\n",
      "    'Aj': 'Adju',\n",
      "    'PO': 'PreO',\n",
      "    'Re': 'Rela',\n",
      "    'Ng': 'Nega',\n",
      "    'Mo': 'Modi',\n",
      "    'Ti': 'Time',\n",
      "    'Lo': 'Loca',\n",
      "    'Ij': 'Intj',\n",
      "    'Qu': 'Ques',\n",
      "    'Vo': 'Voct',\n",
      "    'Fr': 'Frnt',\n",
      "    'Ps': 'PreS',\n",
      "    'sc': 'Supp',\n",
      "    'Qs': 'IrpS',\n",
      "    'Is': 'IntS',\n",
      "    'Qp': 'IrpP',\n",
      "    'Qo': 'IrpO',\n",
      "    'po': 'PtcO',\n",
      "    'Ex': 'Exst',\n",
      "    'Ns': 'NegS',\n",
      "    'Ms': 'ModS',\n",
      "    'Qc': 'IrpC',\n",
      "    'Es': 'ExsS',\n",
      "    'ps': 'PtSp',\n",
      "}\n",
      "\n",
      "pf_map\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "{'': 'Unkn',\n",
        " 'Aj': 'Adju',\n",
        " 'Cj': 'Conj',\n",
        " 'Co': 'Cmpl',\n",
        " 'Es': 'ExsS',\n",
        " 'Ex': 'Exst',\n",
        " 'Fr': 'Frnt',\n",
        " 'Ij': 'Intj',\n",
        " 'Is': 'IntS',\n",
        " 'Lo': 'Loca',\n",
        " 'Mo': 'Modi',\n",
        " 'Ms': 'ModS',\n",
        " 'Ng': 'Nega',\n",
        " 'Ns': 'NegS',\n",
        " 'Ob': 'Objc',\n",
        " 'PC': 'PreC',\n",
        " 'PO': 'PreO',\n",
        " 'Pr': 'Pred',\n",
        " 'Ps': 'PreS',\n",
        " 'Qc': 'IrpC',\n",
        " 'Qo': 'IrpO',\n",
        " 'Qp': 'IrpP',\n",
        " 'Qs': 'IrpS',\n",
        " 'Qu': 'Ques',\n",
        " 'Re': 'Rela',\n",
        " 'Su': 'Subj',\n",
        " 'Ti': 'Time',\n",
        " 'Vo': 'Voct',\n",
        " 'po': 'PtcO',\n",
        " 'ps': 'PtSp',\n",
        " 'sc': 'Supp'}"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle = infile('CorrectionsFJM.txt')\n",
      "\n",
      "oldlable = re.compile('<([^> ]*)>')\n",
      "changematch = re.compile('') \n",
      "rget = [] \n",
      "targetlist = []\n",
      "\n",
      "for line in handle: \n",
      "    #matches = oldlable.findall(line) \n",
      "    #if matches: \n",
      "        #for match in matches: \n",
      "         #   matchset.add(match) \n",
      "    target = line.split('\\t') \n",
      "    targetlist.append(target)\n",
      "    \n",
      "\n",
      "    \n",
      "bad_chars = ']['\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "replacelist = []\n",
      "\n",
      "for element in targetlist: \n",
      "    target = element[-1]\n",
      "    newtarget = rgx.findall(target)\n",
      "    stringtar = ''.join(newtarget)\n",
      "    finaltarget = stringtar.rsplit('<', 1)\n",
      "    needs_to_be_replaced = finaltarget[0]\n",
      "    replacelist.append(needs_to_be_replaced)\n",
      "    \n",
      "targetindex = 0\n",
      "\n",
      "handle = infile('CorrectionsFJM.txt')\n",
      "\n",
      "bad_chars = ']['\n",
      "plusw = '\\+$'\n",
      "\n",
      "rgx = re.compile('[^%s]' % bad_chars)\n",
      "rgxw = re.compile('[%s]' % plusw)\n",
      "check = 0\n",
      "\n",
      "chunk = collections.defaultdict(list)\n",
      "\n",
      "for line in handle:\n",
      "    newline = line.split('\\t')\n",
      "    replacement = replacelist[targetindex]\n",
      "    for element in newline:\n",
      "        if rgxw.search(element):\n",
      "            newelement = element.rsplit(' +',1)\n",
      "            correction = ''.join(newelement)\n",
      "            newline = [w.replace(element, correction) for w in newline]\n",
      "        newelement = rgx.findall(element)\n",
      "        finalelement = ''.join(newelement)\n",
      "        result = finalelement.rsplit('<', 1)\n",
      "        if result[0] == replacement and check < 1:\n",
      "            check += 1\n",
      "            #print(result[0])\n",
      "            target = result[0]\n",
      "    checkline = newline[0: -2]\n",
      "    chunk[target].append(checkline)\n",
      "    check = 0\n",
      "    targetindex += 1\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "   \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['\\ufeffEXO 15,25', '[CM <Lo>]', '[FM <Pr>]', '[LW <Co>]', '[XQ W MCPV <Ob>]']\n",
        "['EXO 40,08', '[W <Cj>]', '[FMT <Pr>]', '[>T H XYR <Ob>]', '[SBJB <Mo>]']\n",
        "['LEV 06,03', '[W <Cj>]', '[FMW <PO>]', '[>YL H MZBX <Aj>]']\n",
        "['JES 41,19', '[>FJM <Pr>]', '[B  <RBH <Lo>]', '[BRWC TDHR W T>CWR <Ob>]', '[JXDW <Mo>]']\n",
        "['JES 42,04', '[<D <Cj>]', '[JFJM <Pr>]', '[B  >RY <Lo>]', '[MCPV <Ob>]']\n",
        "['JES 43,19', '[>P <Mo>]', '[>FJM <Pr>]', '[B  MDBR <Lo>]', '[DRK <Ob>]']\n",
        "['JES 57,07', '[<L HR GBH W NF> <Lo>]', '[FMT <Pr>]', '[MCKBK <Ob>]']\n",
        "['JES 57,08', '[W <Cj>]', '[>XR H DLT W H MZWZH <Lo>]', '[FMT <Pr>]', '[ZKRWNK <Ob>]']\n",
        "['EZE 20,28', '[W <Cj>]', '[JFJMW <Pr>]', '[CM <Mo>]', '[RJX NJXWXJHM <Ob>]']\n",
        "['HAB 02,09', '[L FWM <Pr>]', '[B  MRWM <Lo>]']\n",
        "['PS081,006', '[<DWT B JHWSP <Ob>]', '[FMW <PO>]    :CHANGESTO:']\n",
        "['ISAM 02,20', '[JFM <Pr>]', '[JHWH <Su>]', '[LK <sc>]', '[ZR< MN H >CH H Z>T <Ob>]', '[TXT H C>LH <Co>]']\n",
        "['IISA 14,07', '[L BLTJ FWM <Pr>]', '[L >JCJ <sc>]', '[CM W C>RJT <Ob>]', '[<L PNJ H >DMH <Co>]']\n",
        "['IKON08,21', '[W <Cj>]', '[>FM <Pr>]', '[CM <Co>]', '[MQWM L  >RWN <Ob>]']\n",
        "['IKON20,34', '[W <Cj>]', '[XWYWT <Ob>]', '[TFJM <Pr>]', '[LK <sc>]']\n",
        "['IIKON04,10', '[W <Cj>]', '[NFJM <Pr>]', '[LW <sc>]', '[CM <Co>]', '[MVH W CLXN W KS> W MNWRH <Ob>]']\n",
        "['JES 21,04', '[>T NCP XCQJ <Ob>]', '[FM <Pr>]', '[LJ <sc>]', '[L XRDH <Co>]']\n",
        "['ISAM 19,13', '[W <Cj>]', '[>T KBJR H <ZJM <Ob>]', '[FMH <Pr>]', '[MR>CTJW <Co>]']\n",
        "['IIKON10,08', '[FJMW <Pr>]', '[>TM <Ob>]', '[CNJ YBRJM <Aj>]', '[PTX H C<R <Co>]', '[<D H BQR <Ti>]']\n",
        "['IIKON13,07', '[W <Cj>]', '[JFMM <PO>]']\n",
        "['JES 53,10', '[>M <Cj>]', '[TFJM <Pr>]', '[>CM <Ob>]', '[NPCW <Su>]']\n",
        "['JER 11,13', '[W <Cj>]', '[MSPR XYWT JRWCLM <Su>]', '[FMTM <Pr>]', '[MZBXWT <Ob>]', '[L  BCT <Co>]']\n",
        "['EZE 17,05', '[YPYPH <Co>]', '[FMW <PO>]']\n",
        "['EZE 19,05', '[KPJR <Co>]', '[FMTHW <PO>]']\n",
        "['HOS 02,05', '[W <Cj>]', '[FMTJH <PO>]', '[K  MDBR <Aj>]']\n",
        "['MICH01,07', '[W <Cj>]', '[KL <YBJH <Ob>]', '[>FJM <Pr>]', '[CMMH <Co>]']\n",
        "['MICH02,12', '[JXD <Mo>]', '[>FJMNW <PO>]', '[K Y>N BYRH <Aj>]']\n",
        "['IKON20,34', '[K >CR <Cj>]', '[FM <Pr>]', '[>BJ <Su>]', '[B CMRWN <Co>]', ':CHANGESTO:']\n",
        "['JES 28,25', '[W <Cj>]', '[FM <Pr>]', '[XVH <Ob>]', '[FWRH <Ob>]', ':CHANGESTO:', '[W <Cj>]', '[FM <Pr>]']\n",
        "['IOB 24,15', '[W <Cj>]', '[STR <..>]', '[PNJM <..>]', '[JFJM <Pr>]', ':CHANGESTO:', '[W <Cj>]']\n",
        "['PS089,030', '[W <Cj>]', '[FMTJ <Pr>]', '[L <D <Co>]', '[ZR<W <Ob>]']\n",
        "['IOB 34,13', '[W <Cj>]', '[MJ <..>]', '[FM <Pr>]', '[TBL <..>]', '[KLH <..>]', ':CHANGESTO:', '[W <Cj>]', '[MJ <Su>]']\n",
        "['IOB 38,09', '[B FWMJ <PO>]', '[<NN <..>]', '[LBCW <..>]']\n",
        "['*ICHR17,21', '[L FWM <Pr>]', '[LK <..>]', '[CM <..>]', '[GDLWT <..>]']\n",
        "['*JES 25,02', '[KJ <Cj>]', '[FMT <Pr>]', '[M <JR <Aj>]', '[L  GL <Co>]', '[QRJH BYWRH <Ob>]', ':CHANGESTO:', '[KJ <Cj>]', '[FMT <Pr>]', '[M <JR <Co]', '[L  GL <Co>] Ellp']\n",
        "['*JES 60,15', ' [W <Cj>]', '[FMTJK <PO>]', '[L G>WN <WLM MFWF DWR W DWR <Co>]', ':CHANGESTO:', '[W <Cj>]', '[FMTJK <PO>]', '[L G>WN <WLM <Co>] Ellp']\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Specification of steps ahead\n",
      "\n",
      "1. In the file, find out which of the phrases before :CHANGESTO: has to receive a modified phrase function. This is the target phrase.\n",
      "2. Match the target phrase with a phrase occurrence in the indicated passage in the database.\n",
      "3. Produce an annoting input file, tab separated, 2 columns: the oid of the target phrase, the modified phrase_function.\n",
      "   The name of this column should be shebanq:ft.phrase_function\n",
      "4. Use the module etcbc.annotating (and the method make_form to produce a file of annotations\n",
      "5. put the file of annotations in a new annox (in the annotations directory)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Implementing Flow Charts\n",
      "\n",
      "1. Pick one or two flow charts by Janet.\n",
      "2. translate them in a model.\n",
      "3. Use the model to analyse relevant occurrences of phrases with verbs\n",
      "4. Produce the output of the analysis.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "inpassage = False\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() == 'JES 43,19':\n",
      "            inpassage = True\n",
      "        else:\n",
      "            if inpassage == True: break\n",
      "    elif inpassage:\n",
      "        if otype == 'word' or otype == 'phrase':\n",
      "            msg(\"{} ({})\".format(otype, n))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737651)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227161)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737652)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227162)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737653)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227163)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737654)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227164)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737655)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227165)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737656)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227166)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737657)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227167)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737658)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227168)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737659)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227169)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737660)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s word (227170)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.37s phrase (737661)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s word (227171)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s word (227173)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s word (227172)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s phrase (737662)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s word (227174)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s phrase (737663)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s word (227175)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s word (227176)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s phrase (737664)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.38s word (227177)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_verse = None\n",
      "cur_phrase = [None, []]\n",
      "phrases = []\n",
      "words = []\n",
      "inpassage = False\n",
      "msg('Look for passage')\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        if F.verse_label.v(n).strip() == 'JES 57,07':\n",
      "            inpassage = True\n",
      "        else:\n",
      "            if inpassage == True: break\n",
      "    elif inpassage:\n",
      "        if otype == 'word':\n",
      "            print('APPEND to {} <{}> : WORD {}'.format(cur_phrase[0], F.phrase_function.v(cur_phrase[0]), F.surface_consonants.v(n)))\n",
      "            cur_phrase[1].append(n)\n",
      "        elif otype == 'phrase':\n",
      "            if cur_phrase[0] != None:\n",
      "                phrases.append(cur_phrase)\n",
      "            cur_phrase = [n, []]\n",
      "if cur_phrase[0] != None:\n",
      "    phrases.append(cur_phrase)\n",
      "\n",
      "msg(\"End walk\")\n",
      "\n",
      "print(' '.join('[{} <{}>]'.format(' '.join([F.surface_consonants.v(y) for y in x[1]]), F.phrase_function.v(x[0])) for x in phrases))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1h 11m 47s Look for passage\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1h 11m 47s End walk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "APPEND to 740943 <Loca> : WORD <L\n",
        "APPEND to 740943 <Loca> : WORD HR\n",
        "APPEND to 740943 <Loca> : WORD GBH\n",
        "APPEND to 740943 <Loca> : WORD W\n",
        "APPEND to 740943 <Loca> : WORD NF>\n",
        "APPEND to 740944 <Pred> : WORD FMT\n",
        "APPEND to 740945 <Objc> : WORD MCKBK\n",
        "APPEND to 740946 <Modi> : WORD GM\n",
        "APPEND to 740947 <Loca> : WORD CM\n",
        "APPEND to 740948 <Pred> : WORD <LJT\n",
        "APPEND to 740949 <Pred> : WORD L\n",
        "APPEND to 740949 <Pred> : WORD ZBX\n",
        "APPEND to 740950 <Objc> : WORD ZBX\n",
        "[<L HR GBH W NF> <Loca>] [FMT <Pred>] [MCKBK <Objc>] [GM <Modi>] [CM <Loca>] [<LJT <Pred>] [L ZBX <Pred>] [ZBX <Objc>]\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}