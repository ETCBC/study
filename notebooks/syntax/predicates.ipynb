{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "import laf\n",
      "\n",
      "from laf.notebook import Notebook\n",
      "from etcbc import preprocess\n",
      "\n",
      "processor = Notebook()\n",
      "\n",
      "def show(n):\n",
      "    i = 0\n",
      "    for node in NN(test=F.shebanq_db_otype.v, value='phrase'):\n",
      "        i += 1\n",
      "        if i > n:\n",
      "            break\n",
      "        print(\"{:>3} {}\".format(\n",
      "            i,\n",
      "            ''.join(\n",
      "                [\"{}{}\".format(\n",
      "                        F.shebanq_ft_text.v(t),\n",
      "                        F.shebanq_ft_suffix.v(t)\n",
      "                    ) for t in phrase_words[node]\n",
      "                ])\n",
      "        ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "This is LAF-Fabric 3.7.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.init('bhs3.txt.hdr', '--', 'predicates', {\n",
      "    \"primary\": False,\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype\",\n",
      "                \"ft.text,suffix\",\n",
      "                \"ft.phrase_function\",\n",
      "                \"ft.surface_consonants\",\n",
      "                \"sft.book,chapter,verse,verse_label\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "})\n",
      "\n",
      "API = processor.API()\n",
      "F = API['F']\n",
      "BF = API['BF']\n",
      "NN = API['NN']\n",
      "C = API['C']\n",
      "Ci = API['Ci']\n",
      "infile = API['infile']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "msg = API['msg']\n",
      "\n",
      "preprocess.check(API)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING source: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s COMPILING annox: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING DATA: please wait ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.70s LOADING DATA: DONE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOGFILE=/Users/judith/bhs3.txt.hdr/predicates/__log__predicates.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN TASK=predicates SOURCE=bhs3.txt.hdr\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.14s LOADING API: DONE\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_words = collections.defaultdict(list)\n",
      "cur_phrase = None\n",
      "\n",
      "msg(\"start walking through partially-ordered node set\")\n",
      "for node in NN(test=F.shebanq_db_otype.v, values=['phrase', 'word']):\n",
      "    if F.shebanq_db_otype.v(node) == 'phrase':\n",
      "        cur_phrase = node\n",
      "    else:\n",
      "        phrase_words[cur_phrase].append(node)\n",
      "\n",
      "msg(\"end walking through partially-ordered node set\")\n",
      "show(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.51s start walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.16s end walking through partially-ordered node set\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  1 \u05d1\u05b0\u05bc\u05e8\u05b5\u05d0\u05e9\u05b4\u05c1\u0596\u05d9\u05ea \n",
        "  2 \u05d1\u05b8\u05bc\u05e8\u05b8\u05a3\u05d0 \n",
        "  3 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0591\u05d9\u05dd \n",
        "  4 \u05d0\u05b5\u05a5\u05ea \u05d4\u05b7\u05e9\u05b8\u05bc\u05c1\u05de\u05b7\u0596\u05d9\u05b4\u05dd \u05d5\u05b0\u05d0\u05b5\u05a5\u05ea \u05d4\u05b8\u05d0\u05b8\u05bd\u05e8\u05b6\u05e5\u05c3\n",
        "  5 \u05d5\u05b0\n",
        "  6 \u05d4\u05b8\u05d0\u05b8\u0597\u05e8\u05b6\u05e5 \n",
        "  7 \u05d4\u05b8\u05d9\u05b0\u05ea\u05b8\u05a5\u05d4 \n",
        "  8 \u05ea\u05b9\u05a8\u05d4\u05d5\u05bc\u0599 \u05d5\u05b8\u05d1\u05b9\u0594\u05d4\u05d5\u05bc \n",
        "  9 \u05d5\u05b0\n",
        " 10 \u05d7\u05b9\u0596\u05e9\u05b6\u05c1\u05da\u05b0 \n",
        " 11 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a3\u05d9 \u05ea\u05b0\u05d4\u05b9\u0591\u05d5\u05dd \n",
        " 12 \u05d5\u05b0\n",
        " 13 \u05e8\u05a3\u05d5\u05bc\u05d7\u05b7 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0594\u05d9\u05dd \n",
        " 14 \u05de\u05b0\u05e8\u05b7\u05d7\u05b6\u0596\u05e4\u05b6\u05ea \n",
        " 15 \u05e2\u05b7\u05dc\u05be\u05e4\u05b0\u05bc\u05e0\u05b5\u05a5\u05d9 \u05d4\u05b7\u05de\u05b8\u05bc\u05bd\u05d9\u05b4\u05dd\u05c3\n",
        " 16 \u05d5\u05b7\n",
        " 17 \u05d9\u05b9\u05bc\u05a5\u05d0\u05de\u05b6\u05e8 \n",
        " 18 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u0596\u05d9\u05dd \n",
        " 19 \u05d9\u05b0\u05d4\u05b4\u05a3\u05d9 \n",
        " 20 \u05d0\u05b9\u0591\u05d5\u05e8 \n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out_handle = outfile(\"output.txt\")\n",
      "\n",
      "def predicates():\n",
      "    for key in phrase_words:\n",
      "        if F.shebanq_ft_phrase_function.v(key) == \"Pred\":\n",
      "            words = phrase_words[key]\n",
      "            consonant_reps = [F.shebanq_ft_surface_consonants.v(word) for word in words]\n",
      "            text = ' '.join(consonant_reps)\n",
      "            out_handle.write(\"Predicate: {}\\n\".format(text))\n",
      "\n",
      "predicates()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def verses_frequency():\n",
      "    \n",
      "    verses = collections.defaultdict(list)\n",
      "    cur_verse = None\n",
      "    count = 0\n",
      "\n",
      "    for node in NN(test=F.shebanq_db_otype.v, values=['book', 'chapter','verse', 'phrase']):\n",
      "        if F.shebanq_db_otype.v(node) == \"book\":\n",
      "            the_book = F.shebanq_sft_book.v(node)\n",
      "        elif F.shebanq_db_otype.v(node) == \"chapter\":\n",
      "            the_chapter = F.shebanq_sft_chapter.v(node) \n",
      "        elif F.shebanq_db_otype.v(node) == 'verse':\n",
      "            the_verse = F.shebanq_sft_verse.v(node)   \n",
      "            cur_verse = node\n",
      "        else:\n",
      "            if F.shebanq_db_otype.v(node) == 'phrase':\n",
      "                passage = the_book + ' ' + the_chapter + ' ' + the_verse\n",
      "                verses[passage].append(node)\n",
      "    \n",
      "    for keys, values in verses.items():\n",
      "        length = len(values)\n",
      "        for element in values:\n",
      "            if F.shebanq_ft_phrase_function.v(element) == 'Pred':\n",
      "                count = count + 1\n",
      "                frequency = count / length\n",
      "        \n",
      "        count = 0  \n",
      "        \n",
      "verses_frequency()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chapters_frequency():\n",
      "\n",
      "    chapter = collections.defaultdict(list)\n",
      "\n",
      "    for node in NN(test=F.shebanq_db_otype.v, values=['book', 'chapter', 'phrase']):\n",
      "        if F.shebanq_db_otype.v(node) == \"book\":\n",
      "            the_book = F.shebanq_sft_book.v(node)\n",
      "        elif F.shebanq_db_otype.v(node) == \"chapter\":\n",
      "            the_chapter = F.shebanq_sft_chapter.v(node) \n",
      "        else:\n",
      "            if F.shebanq_db_otype.v(node) == 'phrase':\n",
      "                passage = the_book + ' ' + the_chapter\n",
      "                chapter[passage].append(node)\n",
      "            \n",
      "    count = 0\n",
      "\n",
      "    for keys, values in chapter.items():\n",
      "        length = len(values)\n",
      "        for element in values:\n",
      "            if F.shebanq_ft_phrase_function.v(element) == 'Subj':\n",
      "                count = count + 1\n",
      "                frequency = count / length\n",
      "        print(keys, \"Phrases: \", length, \"Subjects: \", count, \"Frequency: \", frequency)\n",
      "        count = 0 \n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}